{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('../dataset/train.csv')\n",
    "test=pd.read_csv('../dataset/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>image7042.jpg</td>\n",
       "      <td>Food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>image3327.jpg</td>\n",
       "      <td>misc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>image10335.jpg</td>\n",
       "      <td>Attire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>image8019.jpg</td>\n",
       "      <td>Food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>image2128.jpg</td>\n",
       "      <td>Attire</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Image   Class\n",
       "0   image7042.jpg    Food\n",
       "1   image3327.jpg    misc\n",
       "2  image10335.jpg  Attire\n",
       "3   image8019.jpg    Food\n",
       "4   image2128.jpg  Attire"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>image6245.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>image10409.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>image8692.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>image10517.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>image2580.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Image\n",
       "0   image6245.jpg\n",
       "1  image10409.jpg\n",
       "2   image8692.jpg\n",
       "3  image10517.jpg\n",
       "4   image2580.jpg"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2455c076828>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(train['Class'].value_counts()/len(train)).plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.vgg16(pretrained=True, progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freezing other layers of the model\n",
    "for p in model.parameters():\n",
    "    p.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.classifier._modules['6'] = torch.nn.Linear(4096, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "optimizer = optim.SGD(model.classifier.parameters(), lr=0.001, momentum=0.9)#lr 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "# Define train transforms\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5],  # 3 channels (RGB) for colored images\n",
    "                         [0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# Define test transforms\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5],  # 3 channels (RGB) for colored images\n",
    "                         [0.5, 0.5, 0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "\n",
    "data_dir = '../dataset'\n",
    "train_data = datasets.ImageFolder('../dataset/train_images/', transform=train_transforms)\n",
    "test_data = datasets.ImageFolder('../dataset/test_images/', transform=test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "# calculate size of train and validation sets\n",
    "train_size = int(0.8 * len(train_data))\n",
    "valid_size = len(train_data) - train_size\n",
    "partial_train_ds, valid_ds = random_split(train_data, [train_size, valid_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# replace XX and YY with batch_size and number of workers, respectively\n",
    "train_loader = DataLoader(partial_train_ds, batch_size=32, num_workers=2)\n",
    "valid_loader = DataLoader(valid_ds, batch_size=32, num_workers=2)\n",
    "test_loader = DataLoader(test_data, batch_size=32, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10.. Training loss: 0.020550919201668877.. Validation Loss: 7.832991616994964e-05\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-71-234d9c86978b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;31m# forward pass: feed inputs to the model to get outputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[1;31m# calculate the training batch loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programs files\\python\\python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\torchvision\\models\\vgg.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mavgpool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programs files\\python\\python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programs files\\python\\python36\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programs files\\python\\python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programs files\\python\\python36\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2d_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programs files\\python\\python36\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mconv2d_forward\u001b[1;34m(self, input, weight)\u001b[0m\n\u001b[0;32m    340\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m    341\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[1;32m--> 342\u001b[1;33m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_epochs = 10 # this is a hyperparameter you'll need to define\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    ##################\n",
    "    ### TRAIN LOOP ###\n",
    "    ##################\n",
    "    # set the model to train mode\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for data, target in train_loader:\n",
    "        # clear the old gradients from optimized variables\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass: feed inputs to the model to get outputs\n",
    "        output = model(data)\n",
    "        # calculate the training batch loss\n",
    "        loss = criterion(output, target)\n",
    "        # backward: perform gradient descent of the loss w.r. to the model params\n",
    "        loss.backward()\n",
    "        # update the model parameters by performing a single optimization step\n",
    "        optimizer.step()\n",
    "        # accumulate the training loss\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    #######################\n",
    "    ### VALIDATION LOOP ###\n",
    "    #######################\n",
    "    # set the model to eval mode\n",
    "    model.eval()\n",
    "    valid_loss = 0\n",
    "    # turn off gradients for validation\n",
    "    with torch.no_grad():\n",
    "        for data, target in valid_loader:\n",
    "            # forward pass\n",
    "            output = model(data)\n",
    "            # validation batch loss\n",
    "            loss = criterion(output, target) \n",
    "            # accumulate the valid_loss\n",
    "            valid_loss += loss.item()\n",
    "            \n",
    "    #########################\n",
    "    ## PRINT EPOCH RESULTS ##\n",
    "    #########################\n",
    "    train_loss /= len(train_loader)\n",
    "    valid_loss /= len(valid_loader)\n",
    "    print(f'Epoch: {epoch+1}/{n_epochs}.. Training loss: {train_loss}.. Validation Loss: {valid_loss}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
