{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset/train.csv')\n",
    "test = pd.read_csv('dataset/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>name_of_drug</th>\n",
       "      <th>use_case_for_drug</th>\n",
       "      <th>review_by_patient</th>\n",
       "      <th>effectiveness_rating</th>\n",
       "      <th>drug_approved_by_UIC</th>\n",
       "      <th>number_of_times_prescribed</th>\n",
       "      <th>base_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>206461</td>\n",
       "      <td>Valsartan</td>\n",
       "      <td>Left Ventricular Dysfunction</td>\n",
       "      <td>\"It has no side effect, I take it in combinati...</td>\n",
       "      <td>9</td>\n",
       "      <td>20-May-12</td>\n",
       "      <td>27</td>\n",
       "      <td>8.022969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>95260</td>\n",
       "      <td>Guanfacine</td>\n",
       "      <td>ADHD</td>\n",
       "      <td>\"My son is halfway through his fourth week of ...</td>\n",
       "      <td>8</td>\n",
       "      <td>27-Apr-10</td>\n",
       "      <td>192</td>\n",
       "      <td>7.858458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>92703</td>\n",
       "      <td>Lybrel</td>\n",
       "      <td>Birth Control</td>\n",
       "      <td>\"I used to take another oral contraceptive, wh...</td>\n",
       "      <td>5</td>\n",
       "      <td>14-Dec-09</td>\n",
       "      <td>17</td>\n",
       "      <td>6.341969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35696</td>\n",
       "      <td>Buprenorphine / naloxone</td>\n",
       "      <td>Opiate Dependence</td>\n",
       "      <td>\"Suboxone has completely turned my life around...</td>\n",
       "      <td>9</td>\n",
       "      <td>27-Nov-16</td>\n",
       "      <td>37</td>\n",
       "      <td>6.590176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>155963</td>\n",
       "      <td>Cialis</td>\n",
       "      <td>Benign Prostatic Hyperplasia</td>\n",
       "      <td>\"2nd day on 5mg started to work with rock hard...</td>\n",
       "      <td>2</td>\n",
       "      <td>28-Nov-15</td>\n",
       "      <td>43</td>\n",
       "      <td>6.144782</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_id              name_of_drug             use_case_for_drug  \\\n",
       "0      206461                 Valsartan  Left Ventricular Dysfunction   \n",
       "1       95260                Guanfacine                          ADHD   \n",
       "2       92703                    Lybrel                 Birth Control   \n",
       "3       35696  Buprenorphine / naloxone             Opiate Dependence   \n",
       "4      155963                    Cialis  Benign Prostatic Hyperplasia   \n",
       "\n",
       "                                   review_by_patient  effectiveness_rating  \\\n",
       "0  \"It has no side effect, I take it in combinati...                     9   \n",
       "1  \"My son is halfway through his fourth week of ...                     8   \n",
       "2  \"I used to take another oral contraceptive, wh...                     5   \n",
       "3  \"Suboxone has completely turned my life around...                     9   \n",
       "4  \"2nd day on 5mg started to work with rock hard...                     2   \n",
       "\n",
       "  drug_approved_by_UIC  number_of_times_prescribed  base_score  \n",
       "0            20-May-12                          27    8.022969  \n",
       "1            27-Apr-10                         192    7.858458  \n",
       "2            14-Dec-09                          17    6.341969  \n",
       "3            27-Nov-16                          37    6.590176  \n",
       "4            28-Nov-15                          43    6.144782  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>name_of_drug</th>\n",
       "      <th>use_case_for_drug</th>\n",
       "      <th>review_by_patient</th>\n",
       "      <th>effectiveness_rating</th>\n",
       "      <th>drug_approved_by_UIC</th>\n",
       "      <th>number_of_times_prescribed</th>\n",
       "      <th>base_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>206461</td>\n",
       "      <td>Valsartan</td>\n",
       "      <td>Left Ventricular Dysfunction</td>\n",
       "      <td>\"It has no side effect, I take it in combinati...</td>\n",
       "      <td>9</td>\n",
       "      <td>20-May-12</td>\n",
       "      <td>27</td>\n",
       "      <td>8.022969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>95260</td>\n",
       "      <td>Guanfacine</td>\n",
       "      <td>ADHD</td>\n",
       "      <td>\"My son is halfway through his fourth week of ...</td>\n",
       "      <td>8</td>\n",
       "      <td>27-Apr-10</td>\n",
       "      <td>192</td>\n",
       "      <td>7.858458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>92703</td>\n",
       "      <td>Lybrel</td>\n",
       "      <td>Birth Control</td>\n",
       "      <td>\"I used to take another oral contraceptive, wh...</td>\n",
       "      <td>5</td>\n",
       "      <td>14-Dec-09</td>\n",
       "      <td>17</td>\n",
       "      <td>6.341969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35696</td>\n",
       "      <td>Buprenorphine / naloxone</td>\n",
       "      <td>Opiate Dependence</td>\n",
       "      <td>\"Suboxone has completely turned my life around...</td>\n",
       "      <td>9</td>\n",
       "      <td>27-Nov-16</td>\n",
       "      <td>37</td>\n",
       "      <td>6.590176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>155963</td>\n",
       "      <td>Cialis</td>\n",
       "      <td>Benign Prostatic Hyperplasia</td>\n",
       "      <td>\"2nd day on 5mg started to work with rock hard...</td>\n",
       "      <td>2</td>\n",
       "      <td>28-Nov-15</td>\n",
       "      <td>43</td>\n",
       "      <td>6.144782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32160</th>\n",
       "      <td>183202</td>\n",
       "      <td>Cymbalta</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>\"I have been taking Cymbalta for 15 months now...</td>\n",
       "      <td>9</td>\n",
       "      <td>10-Jun-13</td>\n",
       "      <td>89</td>\n",
       "      <td>6.963020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32161</th>\n",
       "      <td>109111</td>\n",
       "      <td>Nexplanon</td>\n",
       "      <td>Birth Control</td>\n",
       "      <td>\"I have had the Nexplanon since Dec. 27, 2016 ...</td>\n",
       "      <td>6</td>\n",
       "      <td>6-Apr-17</td>\n",
       "      <td>0</td>\n",
       "      <td>0.899076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32162</th>\n",
       "      <td>121154</td>\n",
       "      <td>Venlafaxine</td>\n",
       "      <td>Panic Disorde</td>\n",
       "      <td>\"Had panic attacks and social anxiety starting...</td>\n",
       "      <td>9</td>\n",
       "      <td>10-Nov-16</td>\n",
       "      <td>25</td>\n",
       "      <td>6.241812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32163</th>\n",
       "      <td>45410</td>\n",
       "      <td>Fluoxetine</td>\n",
       "      <td>Obsessive Compulsive Disorde</td>\n",
       "      <td>\"I have been off Prozac for about 4 weeks now....</td>\n",
       "      <td>8</td>\n",
       "      <td>21-Jan-15</td>\n",
       "      <td>22</td>\n",
       "      <td>7.940428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32164</th>\n",
       "      <td>187382</td>\n",
       "      <td>Orencia</td>\n",
       "      <td>Rheumatoid Arthritis</td>\n",
       "      <td>\"Limited improvement after 4 months, developed...</td>\n",
       "      <td>2</td>\n",
       "      <td>15-Mar-14</td>\n",
       "      <td>35</td>\n",
       "      <td>8.205393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32165 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       patient_id              name_of_drug             use_case_for_drug  \\\n",
       "0          206461                 Valsartan  Left Ventricular Dysfunction   \n",
       "1           95260                Guanfacine                          ADHD   \n",
       "2           92703                    Lybrel                 Birth Control   \n",
       "3           35696  Buprenorphine / naloxone             Opiate Dependence   \n",
       "4          155963                    Cialis  Benign Prostatic Hyperplasia   \n",
       "...           ...                       ...                           ...   \n",
       "32160      183202                  Cymbalta                       Anxiety   \n",
       "32161      109111                 Nexplanon                 Birth Control   \n",
       "32162      121154               Venlafaxine                 Panic Disorde   \n",
       "32163       45410                Fluoxetine  Obsessive Compulsive Disorde   \n",
       "32164      187382                   Orencia          Rheumatoid Arthritis   \n",
       "\n",
       "                                       review_by_patient  \\\n",
       "0      \"It has no side effect, I take it in combinati...   \n",
       "1      \"My son is halfway through his fourth week of ...   \n",
       "2      \"I used to take another oral contraceptive, wh...   \n",
       "3      \"Suboxone has completely turned my life around...   \n",
       "4      \"2nd day on 5mg started to work with rock hard...   \n",
       "...                                                  ...   \n",
       "32160  \"I have been taking Cymbalta for 15 months now...   \n",
       "32161  \"I have had the Nexplanon since Dec. 27, 2016 ...   \n",
       "32162  \"Had panic attacks and social anxiety starting...   \n",
       "32163  \"I have been off Prozac for about 4 weeks now....   \n",
       "32164  \"Limited improvement after 4 months, developed...   \n",
       "\n",
       "       effectiveness_rating drug_approved_by_UIC  number_of_times_prescribed  \\\n",
       "0                         9            20-May-12                          27   \n",
       "1                         8            27-Apr-10                         192   \n",
       "2                         5            14-Dec-09                          17   \n",
       "3                         9            27-Nov-16                          37   \n",
       "4                         2            28-Nov-15                          43   \n",
       "...                     ...                  ...                         ...   \n",
       "32160                     9            10-Jun-13                          89   \n",
       "32161                     6             6-Apr-17                           0   \n",
       "32162                     9            10-Nov-16                          25   \n",
       "32163                     8            21-Jan-15                          22   \n",
       "32164                     2            15-Mar-14                          35   \n",
       "\n",
       "       base_score  \n",
       "0        8.022969  \n",
       "1        7.858458  \n",
       "2        6.341969  \n",
       "3        6.590176  \n",
       "4        6.144782  \n",
       "...           ...  \n",
       "32160    6.963020  \n",
       "32161    0.899076  \n",
       "32162    6.241812  \n",
       "32163    7.940428  \n",
       "32164    8.205393  \n",
       "\n",
       "[32165 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_df = pd.get_dummies(df, columns=['name_of_drug', 'use_case_for_drug'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>review_by_patient</th>\n",
       "      <th>effectiveness_rating</th>\n",
       "      <th>drug_approved_by_UIC</th>\n",
       "      <th>number_of_times_prescribed</th>\n",
       "      <th>base_score</th>\n",
       "      <th>name_of_drug_Abacavir / dolutegravir / lamivudine</th>\n",
       "      <th>name_of_drug_Abatacept</th>\n",
       "      <th>name_of_drug_Abilify</th>\n",
       "      <th>name_of_drug_Abilify Discmelt</th>\n",
       "      <th>...</th>\n",
       "      <th>use_case_for_drug_min / pioglitazone)</th>\n",
       "      <th>use_case_for_drug_min / rosiglitazone)</th>\n",
       "      <th>use_case_for_drug_min / saxagliptin)</th>\n",
       "      <th>use_case_for_drug_min / sitagliptin)</th>\n",
       "      <th>use_case_for_drug_min)</th>\n",
       "      <th>use_case_for_drug_moterol / mometasone)</th>\n",
       "      <th>use_case_for_drug_moterol)</th>\n",
       "      <th>use_case_for_drug_mulation) (phenylephrine)</th>\n",
       "      <th>use_case_for_drug_von Willebrand's Disease</th>\n",
       "      <th>use_case_for_drug_zen Shoulde</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>206461</td>\n",
       "      <td>\"It has no side effect, I take it in combinati...</td>\n",
       "      <td>9</td>\n",
       "      <td>20-May-12</td>\n",
       "      <td>27</td>\n",
       "      <td>8.022969</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>95260</td>\n",
       "      <td>\"My son is halfway through his fourth week of ...</td>\n",
       "      <td>8</td>\n",
       "      <td>27-Apr-10</td>\n",
       "      <td>192</td>\n",
       "      <td>7.858458</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>92703</td>\n",
       "      <td>\"I used to take another oral contraceptive, wh...</td>\n",
       "      <td>5</td>\n",
       "      <td>14-Dec-09</td>\n",
       "      <td>17</td>\n",
       "      <td>6.341969</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35696</td>\n",
       "      <td>\"Suboxone has completely turned my life around...</td>\n",
       "      <td>9</td>\n",
       "      <td>27-Nov-16</td>\n",
       "      <td>37</td>\n",
       "      <td>6.590176</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>155963</td>\n",
       "      <td>\"2nd day on 5mg started to work with rock hard...</td>\n",
       "      <td>2</td>\n",
       "      <td>28-Nov-15</td>\n",
       "      <td>43</td>\n",
       "      <td>6.144782</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2862 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_id                                  review_by_patient  \\\n",
       "0      206461  \"It has no side effect, I take it in combinati...   \n",
       "1       95260  \"My son is halfway through his fourth week of ...   \n",
       "2       92703  \"I used to take another oral contraceptive, wh...   \n",
       "3       35696  \"Suboxone has completely turned my life around...   \n",
       "4      155963  \"2nd day on 5mg started to work with rock hard...   \n",
       "\n",
       "   effectiveness_rating drug_approved_by_UIC  number_of_times_prescribed  \\\n",
       "0                     9            20-May-12                          27   \n",
       "1                     8            27-Apr-10                         192   \n",
       "2                     5            14-Dec-09                          17   \n",
       "3                     9            27-Nov-16                          37   \n",
       "4                     2            28-Nov-15                          43   \n",
       "\n",
       "   base_score  name_of_drug_Abacavir / dolutegravir / lamivudine  \\\n",
       "0    8.022969                                                  0   \n",
       "1    7.858458                                                  0   \n",
       "2    6.341969                                                  0   \n",
       "3    6.590176                                                  0   \n",
       "4    6.144782                                                  0   \n",
       "\n",
       "   name_of_drug_Abatacept  name_of_drug_Abilify  \\\n",
       "0                       0                     0   \n",
       "1                       0                     0   \n",
       "2                       0                     0   \n",
       "3                       0                     0   \n",
       "4                       0                     0   \n",
       "\n",
       "   name_of_drug_Abilify Discmelt  ...  use_case_for_drug_min / pioglitazone)  \\\n",
       "0                              0  ...                                      0   \n",
       "1                              0  ...                                      0   \n",
       "2                              0  ...                                      0   \n",
       "3                              0  ...                                      0   \n",
       "4                              0  ...                                      0   \n",
       "\n",
       "   use_case_for_drug_min / rosiglitazone)  \\\n",
       "0                                       0   \n",
       "1                                       0   \n",
       "2                                       0   \n",
       "3                                       0   \n",
       "4                                       0   \n",
       "\n",
       "   use_case_for_drug_min / saxagliptin)  use_case_for_drug_min / sitagliptin)  \\\n",
       "0                                     0                                     0   \n",
       "1                                     0                                     0   \n",
       "2                                     0                                     0   \n",
       "3                                     0                                     0   \n",
       "4                                     0                                     0   \n",
       "\n",
       "   use_case_for_drug_min)  use_case_for_drug_moterol / mometasone)  \\\n",
       "0                       0                                        0   \n",
       "1                       0                                        0   \n",
       "2                       0                                        0   \n",
       "3                       0                                        0   \n",
       "4                       0                                        0   \n",
       "\n",
       "   use_case_for_drug_moterol)  use_case_for_drug_mulation) (phenylephrine)  \\\n",
       "0                           0                                            0   \n",
       "1                           0                                            0   \n",
       "2                           0                                            0   \n",
       "3                           0                                            0   \n",
       "4                           0                                            0   \n",
       "\n",
       "   use_case_for_drug_von Willebrand's Disease  use_case_for_drug_zen Shoulde  \n",
       "0                                           0                              0  \n",
       "1                                           0                              0  \n",
       "2                                           0                              0  \n",
       "3                                           0                              0  \n",
       "4                                           0                              0  \n",
       "\n",
       "[5 rows x 2862 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>name_of_drug</th>\n",
       "      <th>review_by_patient</th>\n",
       "      <th>drug_approved_by_UIC</th>\n",
       "      <th>number_of_times_prescribed</th>\n",
       "      <th>use_case_for_drug</th>\n",
       "      <th>effectiveness_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>163740</td>\n",
       "      <td>Mirtazapine</td>\n",
       "      <td>\"I&amp;#039;ve tried a few antidepressants over th...</td>\n",
       "      <td>28-Feb-12</td>\n",
       "      <td>22</td>\n",
       "      <td>Depression</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39293</td>\n",
       "      <td>Contrave</td>\n",
       "      <td>\"Contrave combines drugs that were used for al...</td>\n",
       "      <td>5-Mar-17</td>\n",
       "      <td>35</td>\n",
       "      <td>Weight Loss</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>208087</td>\n",
       "      <td>Zyclara</td>\n",
       "      <td>\"4 days in on first 2 weeks.  Using on arms an...</td>\n",
       "      <td>3-Jul-14</td>\n",
       "      <td>13</td>\n",
       "      <td>Keratosis</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23295</td>\n",
       "      <td>Methadone</td>\n",
       "      <td>\"Ive been on Methadone for over ten years and ...</td>\n",
       "      <td>18-Oct-16</td>\n",
       "      <td>21</td>\n",
       "      <td>Opiate Withdrawal</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>97013</td>\n",
       "      <td>Ambien</td>\n",
       "      <td>\"Ditto on rebound sleepless when discontinued....</td>\n",
       "      <td>13-Jan-15</td>\n",
       "      <td>44</td>\n",
       "      <td>Insomnia</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_id name_of_drug                                  review_by_patient  \\\n",
       "0      163740  Mirtazapine  \"I&#039;ve tried a few antidepressants over th...   \n",
       "1       39293     Contrave  \"Contrave combines drugs that were used for al...   \n",
       "2      208087      Zyclara  \"4 days in on first 2 weeks.  Using on arms an...   \n",
       "3       23295    Methadone  \"Ive been on Methadone for over ten years and ...   \n",
       "4       97013       Ambien  \"Ditto on rebound sleepless when discontinued....   \n",
       "\n",
       "  drug_approved_by_UIC  number_of_times_prescribed  use_case_for_drug  \\\n",
       "0            28-Feb-12                          22         Depression   \n",
       "1             5-Mar-17                          35        Weight Loss   \n",
       "2             3-Jul-14                          13          Keratosis   \n",
       "3            18-Oct-16                          21  Opiate Withdrawal   \n",
       "4            13-Jan-15                          44           Insomnia   \n",
       "\n",
       "   effectiveness_rating  \n",
       "0                    10  \n",
       "1                     9  \n",
       "2                     4  \n",
       "3                     7  \n",
       "4                     2  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "la = LabelEncoder()\n",
    "la2 = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>name_of_drug</th>\n",
       "      <th>use_case_for_drug</th>\n",
       "      <th>review_by_patient</th>\n",
       "      <th>effectiveness_rating</th>\n",
       "      <th>drug_approved_by_UIC</th>\n",
       "      <th>number_of_times_prescribed</th>\n",
       "      <th>base_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>206461</td>\n",
       "      <td>Valsartan</td>\n",
       "      <td>Left Ventricular Dysfunction</td>\n",
       "      <td>\"It has no side effect, I take it in combinati...</td>\n",
       "      <td>9</td>\n",
       "      <td>20-May-12</td>\n",
       "      <td>27</td>\n",
       "      <td>8.022969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>95260</td>\n",
       "      <td>Guanfacine</td>\n",
       "      <td>ADHD</td>\n",
       "      <td>\"My son is halfway through his fourth week of ...</td>\n",
       "      <td>8</td>\n",
       "      <td>27-Apr-10</td>\n",
       "      <td>192</td>\n",
       "      <td>7.858458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>92703</td>\n",
       "      <td>Lybrel</td>\n",
       "      <td>Birth Control</td>\n",
       "      <td>\"I used to take another oral contraceptive, wh...</td>\n",
       "      <td>5</td>\n",
       "      <td>14-Dec-09</td>\n",
       "      <td>17</td>\n",
       "      <td>6.341969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35696</td>\n",
       "      <td>Buprenorphine / naloxone</td>\n",
       "      <td>Opiate Dependence</td>\n",
       "      <td>\"Suboxone has completely turned my life around...</td>\n",
       "      <td>9</td>\n",
       "      <td>27-Nov-16</td>\n",
       "      <td>37</td>\n",
       "      <td>6.590176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>155963</td>\n",
       "      <td>Cialis</td>\n",
       "      <td>Benign Prostatic Hyperplasia</td>\n",
       "      <td>\"2nd day on 5mg started to work with rock hard...</td>\n",
       "      <td>2</td>\n",
       "      <td>28-Nov-15</td>\n",
       "      <td>43</td>\n",
       "      <td>6.144782</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_id              name_of_drug             use_case_for_drug  \\\n",
       "0      206461                 Valsartan  Left Ventricular Dysfunction   \n",
       "1       95260                Guanfacine                          ADHD   \n",
       "2       92703                    Lybrel                 Birth Control   \n",
       "3       35696  Buprenorphine / naloxone             Opiate Dependence   \n",
       "4      155963                    Cialis  Benign Prostatic Hyperplasia   \n",
       "\n",
       "                                   review_by_patient  effectiveness_rating  \\\n",
       "0  \"It has no side effect, I take it in combinati...                     9   \n",
       "1  \"My son is halfway through his fourth week of ...                     8   \n",
       "2  \"I used to take another oral contraceptive, wh...                     5   \n",
       "3  \"Suboxone has completely turned my life around...                     9   \n",
       "4  \"2nd day on 5mg started to work with rock hard...                     2   \n",
       "\n",
       "  drug_approved_by_UIC  number_of_times_prescribed  base_score  \n",
       "0            20-May-12                          27    8.022969  \n",
       "1            27-Apr-10                         192    7.858458  \n",
       "2            14-Dec-09                          17    6.341969  \n",
       "3            27-Nov-16                          37    6.590176  \n",
       "4            28-Nov-15                          43    6.144782  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = df.append(test)\n",
    "total.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>name_of_drug</th>\n",
       "      <th>use_case_for_drug</th>\n",
       "      <th>review_by_patient</th>\n",
       "      <th>effectiveness_rating</th>\n",
       "      <th>drug_approved_by_UIC</th>\n",
       "      <th>number_of_times_prescribed</th>\n",
       "      <th>base_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10755</th>\n",
       "      <td>151266</td>\n",
       "      <td>Chantix</td>\n",
       "      <td>Smoking Cessation</td>\n",
       "      <td>\"I took chantix a little over a month. It made...</td>\n",
       "      <td>1</td>\n",
       "      <td>11-Nov-17</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10756</th>\n",
       "      <td>139347</td>\n",
       "      <td>Armodafinil</td>\n",
       "      <td>Narcolepsy</td>\n",
       "      <td>\"This medicine kept me from sleeping the whole...</td>\n",
       "      <td>1</td>\n",
       "      <td>30-Sep-14</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10757</th>\n",
       "      <td>159999</td>\n",
       "      <td>Tamoxifen</td>\n",
       "      <td>Breast Cancer, Prevention</td>\n",
       "      <td>\"I have taken Tamoxifen for 5 years. Side effe...</td>\n",
       "      <td>10</td>\n",
       "      <td>13-Sep-14</td>\n",
       "      <td>43</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10758</th>\n",
       "      <td>130945</td>\n",
       "      <td>Levonorgestrel</td>\n",
       "      <td>Birth Control</td>\n",
       "      <td>\"I&amp;#039;m married, 34 years old and I have no ...</td>\n",
       "      <td>8</td>\n",
       "      <td>15-Nov-10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10759</th>\n",
       "      <td>113712</td>\n",
       "      <td>Arthrotec</td>\n",
       "      <td>Sciatica</td>\n",
       "      <td>\"It works!!!\"</td>\n",
       "      <td>9</td>\n",
       "      <td>13-Sep-09</td>\n",
       "      <td>46</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       patient_id    name_of_drug          use_case_for_drug  \\\n",
       "10755      151266         Chantix          Smoking Cessation   \n",
       "10756      139347     Armodafinil                 Narcolepsy   \n",
       "10757      159999       Tamoxifen  Breast Cancer, Prevention   \n",
       "10758      130945  Levonorgestrel              Birth Control   \n",
       "10759      113712       Arthrotec                   Sciatica   \n",
       "\n",
       "                                       review_by_patient  \\\n",
       "10755  \"I took chantix a little over a month. It made...   \n",
       "10756  \"This medicine kept me from sleeping the whole...   \n",
       "10757  \"I have taken Tamoxifen for 5 years. Side effe...   \n",
       "10758  \"I&#039;m married, 34 years old and I have no ...   \n",
       "10759                                      \"It works!!!\"   \n",
       "\n",
       "       effectiveness_rating drug_approved_by_UIC  number_of_times_prescribed  \\\n",
       "10755                     1            11-Nov-17                           2   \n",
       "10756                     1            30-Sep-14                          18   \n",
       "10757                    10            13-Sep-14                          43   \n",
       "10758                     8            15-Nov-10                           7   \n",
       "10759                     9            13-Sep-09                          46   \n",
       "\n",
       "       base_score  \n",
       "10755         NaN  \n",
       "10756         NaN  \n",
       "10757         NaN  \n",
       "10758         NaN  \n",
       "10759         NaN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "total['enc_ucd'] = la.fit_transform(total['use_case_for_drug'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "total['enc_nod'] = la2.fit_transform(total['name_of_drug'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>name_of_drug</th>\n",
       "      <th>use_case_for_drug</th>\n",
       "      <th>review_by_patient</th>\n",
       "      <th>effectiveness_rating</th>\n",
       "      <th>drug_approved_by_UIC</th>\n",
       "      <th>number_of_times_prescribed</th>\n",
       "      <th>base_score</th>\n",
       "      <th>enc_ucd</th>\n",
       "      <th>enc_nod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>206461</td>\n",
       "      <td>Valsartan</td>\n",
       "      <td>Left Ventricular Dysfunction</td>\n",
       "      <td>\"It has no side effect, I take it in combinati...</td>\n",
       "      <td>9</td>\n",
       "      <td>20-May-12</td>\n",
       "      <td>27</td>\n",
       "      <td>8.022969</td>\n",
       "      <td>351</td>\n",
       "      <td>2222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>95260</td>\n",
       "      <td>Guanfacine</td>\n",
       "      <td>ADHD</td>\n",
       "      <td>\"My son is halfway through his fourth week of ...</td>\n",
       "      <td>8</td>\n",
       "      <td>27-Apr-10</td>\n",
       "      <td>192</td>\n",
       "      <td>7.858458</td>\n",
       "      <td>42</td>\n",
       "      <td>980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>92703</td>\n",
       "      <td>Lybrel</td>\n",
       "      <td>Birth Control</td>\n",
       "      <td>\"I used to take another oral contraceptive, wh...</td>\n",
       "      <td>5</td>\n",
       "      <td>14-Dec-09</td>\n",
       "      <td>17</td>\n",
       "      <td>6.341969</td>\n",
       "      <td>114</td>\n",
       "      <td>1285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35696</td>\n",
       "      <td>Buprenorphine / naloxone</td>\n",
       "      <td>Opiate Dependence</td>\n",
       "      <td>\"Suboxone has completely turned my life around...</td>\n",
       "      <td>9</td>\n",
       "      <td>27-Nov-16</td>\n",
       "      <td>37</td>\n",
       "      <td>6.590176</td>\n",
       "      <td>432</td>\n",
       "      <td>352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>155963</td>\n",
       "      <td>Cialis</td>\n",
       "      <td>Benign Prostatic Hyperplasia</td>\n",
       "      <td>\"2nd day on 5mg started to work with rock hard...</td>\n",
       "      <td>2</td>\n",
       "      <td>28-Nov-15</td>\n",
       "      <td>43</td>\n",
       "      <td>6.144782</td>\n",
       "      <td>109</td>\n",
       "      <td>461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_id              name_of_drug             use_case_for_drug  \\\n",
       "0      206461                 Valsartan  Left Ventricular Dysfunction   \n",
       "1       95260                Guanfacine                          ADHD   \n",
       "2       92703                    Lybrel                 Birth Control   \n",
       "3       35696  Buprenorphine / naloxone             Opiate Dependence   \n",
       "4      155963                    Cialis  Benign Prostatic Hyperplasia   \n",
       "\n",
       "                                   review_by_patient  effectiveness_rating  \\\n",
       "0  \"It has no side effect, I take it in combinati...                     9   \n",
       "1  \"My son is halfway through his fourth week of ...                     8   \n",
       "2  \"I used to take another oral contraceptive, wh...                     5   \n",
       "3  \"Suboxone has completely turned my life around...                     9   \n",
       "4  \"2nd day on 5mg started to work with rock hard...                     2   \n",
       "\n",
       "  drug_approved_by_UIC  number_of_times_prescribed  base_score  enc_ucd  \\\n",
       "0            20-May-12                          27    8.022969      351   \n",
       "1            27-Apr-10                         192    7.858458       42   \n",
       "2            14-Dec-09                          17    6.341969      114   \n",
       "3            27-Nov-16                          37    6.590176      432   \n",
       "4            28-Nov-15                          43    6.144782      109   \n",
       "\n",
       "   enc_nod  \n",
       "0     2222  \n",
       "1      980  \n",
       "2     1285  \n",
       "3      352  \n",
       "4      461  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = total[~total['base_score'].isna()].reset_index(drop=True)\n",
    "test = total[total['base_score'].isna()].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x12f29965d68>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot((train['base_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train[['enc_nod', 'enc_ucd', \n",
    "                                                           'effectiveness_rating',\n",
    "                                                           'number_of_times_prescribed']], train['base_score'], test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import catboost\n",
    "import lightgbm\n",
    "import xgboost\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor()\n",
    "cat = catboost.CatBoostRegressor()\n",
    "lgt = lightgbm.LGBMRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_std = std.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.067415\n",
      "0:\tlearn: 1.5342286\ttotal: 213ms\tremaining: 3m 33s\n",
      "1:\tlearn: 1.4882034\ttotal: 222ms\tremaining: 1m 50s\n",
      "2:\tlearn: 1.4415214\ttotal: 232ms\tremaining: 1m 17s\n",
      "3:\tlearn: 1.4030594\ttotal: 241ms\tremaining: 60s\n",
      "4:\tlearn: 1.3632376\ttotal: 249ms\tremaining: 49.5s\n",
      "5:\tlearn: 1.3268999\ttotal: 256ms\tremaining: 42.5s\n",
      "6:\tlearn: 1.2918879\ttotal: 264ms\tremaining: 37.4s\n",
      "7:\tlearn: 1.2573266\ttotal: 273ms\tremaining: 33.8s\n",
      "8:\tlearn: 1.2292561\ttotal: 282ms\tremaining: 31.1s\n",
      "9:\tlearn: 1.2040361\ttotal: 288ms\tremaining: 28.5s\n",
      "10:\tlearn: 1.1758053\ttotal: 292ms\tremaining: 26.2s\n",
      "11:\tlearn: 1.1529553\ttotal: 296ms\tremaining: 24.4s\n",
      "12:\tlearn: 1.1327003\ttotal: 303ms\tremaining: 23s\n",
      "13:\tlearn: 1.1110639\ttotal: 307ms\tremaining: 21.6s\n",
      "14:\tlearn: 1.0939904\ttotal: 313ms\tremaining: 20.6s\n",
      "15:\tlearn: 1.0773496\ttotal: 320ms\tremaining: 19.7s\n",
      "16:\tlearn: 1.0610984\ttotal: 328ms\tremaining: 18.9s\n",
      "17:\tlearn: 1.0464867\ttotal: 336ms\tremaining: 18.3s\n",
      "18:\tlearn: 1.0335474\ttotal: 343ms\tremaining: 17.7s\n",
      "19:\tlearn: 1.0215884\ttotal: 351ms\tremaining: 17.2s\n",
      "20:\tlearn: 1.0102419\ttotal: 359ms\tremaining: 16.7s\n",
      "21:\tlearn: 1.0006333\ttotal: 367ms\tremaining: 16.3s\n",
      "22:\tlearn: 0.9897315\ttotal: 375ms\tremaining: 15.9s\n",
      "23:\tlearn: 0.9806329\ttotal: 384ms\tremaining: 15.6s\n",
      "24:\tlearn: 0.9732911\ttotal: 392ms\tremaining: 15.3s\n",
      "25:\tlearn: 0.9648419\ttotal: 397ms\tremaining: 14.9s\n",
      "26:\tlearn: 0.9519055\ttotal: 402ms\tremaining: 14.5s\n",
      "27:\tlearn: 0.9462248\ttotal: 411ms\tremaining: 14.3s\n",
      "28:\tlearn: 0.9390123\ttotal: 415ms\tremaining: 13.9s\n",
      "29:\tlearn: 0.9352806\ttotal: 420ms\tremaining: 13.6s\n",
      "30:\tlearn: 0.9279188\ttotal: 426ms\tremaining: 13.3s\n",
      "31:\tlearn: 0.9200241\ttotal: 432ms\tremaining: 13.1s\n",
      "32:\tlearn: 0.9165144\ttotal: 438ms\tremaining: 12.8s\n",
      "33:\tlearn: 0.9115845\ttotal: 443ms\tremaining: 12.6s\n",
      "34:\tlearn: 0.9091559\ttotal: 451ms\tremaining: 12.4s\n",
      "35:\tlearn: 0.8941750\ttotal: 460ms\tremaining: 12.3s\n",
      "36:\tlearn: 0.8900072\ttotal: 467ms\tremaining: 12.2s\n",
      "37:\tlearn: 0.8878968\ttotal: 476ms\tremaining: 12s\n",
      "38:\tlearn: 0.8756052\ttotal: 484ms\tremaining: 11.9s\n",
      "39:\tlearn: 0.8723086\ttotal: 491ms\tremaining: 11.8s\n",
      "40:\tlearn: 0.8639906\ttotal: 499ms\tremaining: 11.7s\n",
      "41:\tlearn: 0.8554413\ttotal: 507ms\tremaining: 11.6s\n",
      "42:\tlearn: 0.8532790\ttotal: 515ms\tremaining: 11.5s\n",
      "43:\tlearn: 0.8472032\ttotal: 523ms\tremaining: 11.4s\n",
      "44:\tlearn: 0.8451821\ttotal: 530ms\tremaining: 11.3s\n",
      "45:\tlearn: 0.8363495\ttotal: 538ms\tremaining: 11.2s\n",
      "46:\tlearn: 0.8348573\ttotal: 545ms\tremaining: 11.1s\n",
      "47:\tlearn: 0.8300183\ttotal: 553ms\tremaining: 11s\n",
      "48:\tlearn: 0.8185345\ttotal: 571ms\tremaining: 11.1s\n",
      "49:\tlearn: 0.8104070\ttotal: 575ms\tremaining: 10.9s\n",
      "50:\tlearn: 0.8037461\ttotal: 579ms\tremaining: 10.8s\n",
      "51:\tlearn: 0.7964877\ttotal: 584ms\tremaining: 10.7s\n",
      "52:\tlearn: 0.7917036\ttotal: 590ms\tremaining: 10.5s\n",
      "53:\tlearn: 0.7876562\ttotal: 598ms\tremaining: 10.5s\n",
      "54:\tlearn: 0.7833755\ttotal: 603ms\tremaining: 10.4s\n",
      "55:\tlearn: 0.7735268\ttotal: 610ms\tremaining: 10.3s\n",
      "56:\tlearn: 0.7683535\ttotal: 618ms\tremaining: 10.2s\n",
      "57:\tlearn: 0.7660576\ttotal: 626ms\tremaining: 10.2s\n",
      "58:\tlearn: 0.7546946\ttotal: 634ms\tremaining: 10.1s\n",
      "59:\tlearn: 0.7444770\ttotal: 641ms\tremaining: 10s\n",
      "60:\tlearn: 0.7358412\ttotal: 650ms\tremaining: 10s\n",
      "61:\tlearn: 0.7338501\ttotal: 657ms\tremaining: 9.94s\n",
      "62:\tlearn: 0.7327290\ttotal: 665ms\tremaining: 9.89s\n",
      "63:\tlearn: 0.7263041\ttotal: 673ms\tremaining: 9.84s\n",
      "64:\tlearn: 0.7254003\ttotal: 680ms\tremaining: 9.79s\n",
      "65:\tlearn: 0.7244193\ttotal: 688ms\tremaining: 9.73s\n",
      "66:\tlearn: 0.7211988\ttotal: 696ms\tremaining: 9.69s\n",
      "67:\tlearn: 0.7185068\ttotal: 703ms\tremaining: 9.64s\n",
      "68:\tlearn: 0.7174435\ttotal: 711ms\tremaining: 9.6s\n",
      "69:\tlearn: 0.7119542\ttotal: 719ms\tremaining: 9.56s\n",
      "70:\tlearn: 0.7094338\ttotal: 727ms\tremaining: 9.52s\n",
      "71:\tlearn: 0.7067815\ttotal: 734ms\tremaining: 9.46s\n",
      "72:\tlearn: 0.7043191\ttotal: 739ms\tremaining: 9.38s\n",
      "73:\tlearn: 0.7002687\ttotal: 744ms\tremaining: 9.31s\n",
      "74:\tlearn: 0.6913928\ttotal: 748ms\tremaining: 9.23s\n",
      "75:\tlearn: 0.6882647\ttotal: 752ms\tremaining: 9.15s\n",
      "76:\tlearn: 0.6874329\ttotal: 760ms\tremaining: 9.11s\n",
      "77:\tlearn: 0.6816048\ttotal: 764ms\tremaining: 9.03s\n",
      "78:\tlearn: 0.6778128\ttotal: 769ms\tremaining: 8.96s\n",
      "79:\tlearn: 0.6769282\ttotal: 772ms\tremaining: 8.88s\n",
      "80:\tlearn: 0.6684268\ttotal: 777ms\tremaining: 8.81s\n",
      "81:\tlearn: 0.6662009\ttotal: 782ms\tremaining: 8.75s\n",
      "82:\tlearn: 0.6596212\ttotal: 788ms\tremaining: 8.71s\n",
      "83:\tlearn: 0.6573828\ttotal: 795ms\tremaining: 8.66s\n",
      "84:\tlearn: 0.6568191\ttotal: 802ms\tremaining: 8.63s\n",
      "85:\tlearn: 0.6551494\ttotal: 811ms\tremaining: 8.61s\n",
      "86:\tlearn: 0.6528319\ttotal: 820ms\tremaining: 8.6s\n",
      "87:\tlearn: 0.6447617\ttotal: 828ms\tremaining: 8.58s\n",
      "88:\tlearn: 0.6392988\ttotal: 835ms\tremaining: 8.55s\n",
      "89:\tlearn: 0.6387753\ttotal: 843ms\tremaining: 8.52s\n",
      "90:\tlearn: 0.6342410\ttotal: 850ms\tremaining: 8.49s\n",
      "91:\tlearn: 0.6326530\ttotal: 858ms\tremaining: 8.46s\n",
      "92:\tlearn: 0.6260574\ttotal: 866ms\tremaining: 8.44s\n",
      "93:\tlearn: 0.6247592\ttotal: 873ms\tremaining: 8.42s\n",
      "94:\tlearn: 0.6177477\ttotal: 881ms\tremaining: 8.39s\n",
      "95:\tlearn: 0.6127467\ttotal: 891ms\tremaining: 8.38s\n",
      "96:\tlearn: 0.6077775\ttotal: 896ms\tremaining: 8.34s\n",
      "97:\tlearn: 0.6061251\ttotal: 901ms\tremaining: 8.29s\n",
      "98:\tlearn: 0.6036730\ttotal: 905ms\tremaining: 8.24s\n",
      "99:\tlearn: 0.6015168\ttotal: 911ms\tremaining: 8.2s\n",
      "100:\tlearn: 0.5967827\ttotal: 914ms\tremaining: 8.14s\n",
      "101:\tlearn: 0.5939001\ttotal: 918ms\tremaining: 8.08s\n",
      "102:\tlearn: 0.5877043\ttotal: 922ms\tremaining: 8.03s\n",
      "103:\tlearn: 0.5840237\ttotal: 926ms\tremaining: 7.98s\n",
      "104:\tlearn: 0.5792949\ttotal: 930ms\tremaining: 7.92s\n",
      "105:\tlearn: 0.5774097\ttotal: 934ms\tremaining: 7.88s\n",
      "106:\tlearn: 0.5750101\ttotal: 939ms\tremaining: 7.84s\n",
      "107:\tlearn: 0.5724887\ttotal: 946ms\tremaining: 7.81s\n",
      "108:\tlearn: 0.5717791\ttotal: 955ms\tremaining: 7.8s\n",
      "109:\tlearn: 0.5662760\ttotal: 962ms\tremaining: 7.79s\n",
      "110:\tlearn: 0.5622690\ttotal: 970ms\tremaining: 7.77s\n",
      "111:\tlearn: 0.5581224\ttotal: 978ms\tremaining: 7.75s\n",
      "112:\tlearn: 0.5571170\ttotal: 985ms\tremaining: 7.74s\n",
      "113:\tlearn: 0.5526562\ttotal: 992ms\tremaining: 7.71s\n",
      "114:\tlearn: 0.5482079\ttotal: 999ms\tremaining: 7.69s\n",
      "115:\tlearn: 0.5447513\ttotal: 1.01s\tremaining: 7.68s\n",
      "116:\tlearn: 0.5433980\ttotal: 1.02s\tremaining: 7.67s\n",
      "117:\tlearn: 0.5414928\ttotal: 1.02s\tremaining: 7.66s\n",
      "118:\tlearn: 0.5374067\ttotal: 1.03s\tremaining: 7.64s\n",
      "119:\tlearn: 0.5369690\ttotal: 1.04s\tremaining: 7.62s\n",
      "120:\tlearn: 0.5334649\ttotal: 1.05s\tremaining: 7.6s\n",
      "121:\tlearn: 0.5290242\ttotal: 1.05s\tremaining: 7.56s\n",
      "122:\tlearn: 0.5260026\ttotal: 1.05s\tremaining: 7.53s\n",
      "123:\tlearn: 0.5250142\ttotal: 1.06s\tremaining: 7.49s\n",
      "124:\tlearn: 0.5208682\ttotal: 1.06s\tremaining: 7.44s\n",
      "125:\tlearn: 0.5179801\ttotal: 1.07s\tremaining: 7.4s\n",
      "126:\tlearn: 0.5168509\ttotal: 1.07s\tremaining: 7.37s\n",
      "127:\tlearn: 0.5158579\ttotal: 1.08s\tremaining: 7.33s\n",
      "128:\tlearn: 0.5133765\ttotal: 1.08s\tremaining: 7.32s\n",
      "129:\tlearn: 0.5091275\ttotal: 1.09s\tremaining: 7.3s\n",
      "130:\tlearn: 0.5054699\ttotal: 1.1s\tremaining: 7.29s\n",
      "131:\tlearn: 0.5051363\ttotal: 1.1s\tremaining: 7.27s\n",
      "132:\tlearn: 0.5030830\ttotal: 1.11s\tremaining: 7.25s\n",
      "133:\tlearn: 0.5017912\ttotal: 1.12s\tremaining: 7.22s\n",
      "134:\tlearn: 0.5012374\ttotal: 1.13s\tremaining: 7.22s\n",
      "135:\tlearn: 0.4996903\ttotal: 1.13s\tremaining: 7.19s\n",
      "136:\tlearn: 0.4982776\ttotal: 1.14s\tremaining: 7.17s\n",
      "137:\tlearn: 0.4946422\ttotal: 1.14s\tremaining: 7.13s\n",
      "138:\tlearn: 0.4937998\ttotal: 1.15s\tremaining: 7.1s\n",
      "139:\tlearn: 0.4923448\ttotal: 1.15s\tremaining: 7.07s\n",
      "140:\tlearn: 0.4902537\ttotal: 1.16s\tremaining: 7.05s\n",
      "141:\tlearn: 0.4875761\ttotal: 1.16s\tremaining: 7.02s\n",
      "142:\tlearn: 0.4848308\ttotal: 1.17s\tremaining: 6.99s\n",
      "143:\tlearn: 0.4833692\ttotal: 1.17s\tremaining: 6.96s\n",
      "144:\tlearn: 0.4828882\ttotal: 1.17s\tremaining: 6.93s\n",
      "145:\tlearn: 0.4805167\ttotal: 1.18s\tremaining: 6.91s\n",
      "146:\tlearn: 0.4773401\ttotal: 1.19s\tremaining: 6.89s\n",
      "147:\tlearn: 0.4753589\ttotal: 1.19s\tremaining: 6.86s\n",
      "148:\tlearn: 0.4728865\ttotal: 1.2s\tremaining: 6.85s\n",
      "149:\tlearn: 0.4721750\ttotal: 1.21s\tremaining: 6.83s\n",
      "150:\tlearn: 0.4700404\ttotal: 1.22s\tremaining: 6.83s\n",
      "151:\tlearn: 0.4678386\ttotal: 1.23s\tremaining: 6.84s\n",
      "152:\tlearn: 0.4670524\ttotal: 1.23s\tremaining: 6.82s\n",
      "153:\tlearn: 0.4648877\ttotal: 1.24s\tremaining: 6.82s\n",
      "154:\tlearn: 0.4630622\ttotal: 1.25s\tremaining: 6.81s\n",
      "155:\tlearn: 0.4628267\ttotal: 1.25s\tremaining: 6.79s\n",
      "156:\tlearn: 0.4610075\ttotal: 1.26s\tremaining: 6.78s\n",
      "157:\tlearn: 0.4578200\ttotal: 1.27s\tremaining: 6.76s\n",
      "158:\tlearn: 0.4561256\ttotal: 1.28s\tremaining: 6.75s\n",
      "159:\tlearn: 0.4542040\ttotal: 1.28s\tremaining: 6.73s\n",
      "160:\tlearn: 0.4521371\ttotal: 1.29s\tremaining: 6.72s\n",
      "161:\tlearn: 0.4483723\ttotal: 1.3s\tremaining: 6.71s\n",
      "162:\tlearn: 0.4450052\ttotal: 1.3s\tremaining: 6.7s\n",
      "163:\tlearn: 0.4432992\ttotal: 1.32s\tremaining: 6.71s\n",
      "164:\tlearn: 0.4417674\ttotal: 1.32s\tremaining: 6.71s\n",
      "165:\tlearn: 0.4399562\ttotal: 1.33s\tremaining: 6.7s\n",
      "166:\tlearn: 0.4369446\ttotal: 1.34s\tremaining: 6.69s\n",
      "167:\tlearn: 0.4360169\ttotal: 1.35s\tremaining: 6.71s\n",
      "168:\tlearn: 0.4343083\ttotal: 1.36s\tremaining: 6.7s\n",
      "169:\tlearn: 0.4316502\ttotal: 1.37s\tremaining: 6.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170:\tlearn: 0.4300880\ttotal: 1.38s\tremaining: 6.69s\n",
      "171:\tlearn: 0.4295008\ttotal: 1.38s\tremaining: 6.67s\n",
      "172:\tlearn: 0.4281178\ttotal: 1.39s\tremaining: 6.64s\n",
      "173:\tlearn: 0.4257534\ttotal: 1.39s\tremaining: 6.62s\n",
      "174:\tlearn: 0.4229534\ttotal: 1.4s\tremaining: 6.59s\n",
      "175:\tlearn: 0.4223400\ttotal: 1.4s\tremaining: 6.56s\n",
      "176:\tlearn: 0.4207645\ttotal: 1.41s\tremaining: 6.54s\n",
      "177:\tlearn: 0.4188357\ttotal: 1.42s\tremaining: 6.54s\n",
      "178:\tlearn: 0.4177594\ttotal: 1.42s\tremaining: 6.53s\n",
      "179:\tlearn: 0.4171373\ttotal: 1.43s\tremaining: 6.53s\n",
      "180:\tlearn: 0.4150716\ttotal: 1.44s\tremaining: 6.51s\n",
      "181:\tlearn: 0.4133305\ttotal: 1.45s\tremaining: 6.51s\n",
      "182:\tlearn: 0.4129914\ttotal: 1.46s\tremaining: 6.5s\n",
      "183:\tlearn: 0.4105377\ttotal: 1.46s\tremaining: 6.49s\n",
      "184:\tlearn: 0.4103240\ttotal: 1.47s\tremaining: 6.48s\n",
      "185:\tlearn: 0.4077892\ttotal: 1.48s\tremaining: 6.47s\n",
      "186:\tlearn: 0.4064823\ttotal: 1.49s\tremaining: 6.46s\n",
      "187:\tlearn: 0.4052534\ttotal: 1.49s\tremaining: 6.45s\n",
      "188:\tlearn: 0.4029197\ttotal: 1.5s\tremaining: 6.45s\n",
      "189:\tlearn: 0.4026151\ttotal: 1.51s\tremaining: 6.44s\n",
      "190:\tlearn: 0.4006535\ttotal: 1.52s\tremaining: 6.43s\n",
      "191:\tlearn: 0.3995448\ttotal: 1.52s\tremaining: 6.42s\n",
      "192:\tlearn: 0.3990452\ttotal: 1.53s\tremaining: 6.42s\n",
      "193:\tlearn: 0.3968606\ttotal: 1.54s\tremaining: 6.4s\n",
      "194:\tlearn: 0.3964223\ttotal: 1.55s\tremaining: 6.4s\n",
      "195:\tlearn: 0.3962212\ttotal: 1.57s\tremaining: 6.43s\n",
      "196:\tlearn: 0.3943368\ttotal: 1.57s\tremaining: 6.42s\n",
      "197:\tlearn: 0.3931721\ttotal: 1.58s\tremaining: 6.4s\n",
      "198:\tlearn: 0.3919139\ttotal: 1.58s\tremaining: 6.37s\n",
      "199:\tlearn: 0.3909186\ttotal: 1.59s\tremaining: 6.35s\n",
      "200:\tlearn: 0.3893725\ttotal: 1.59s\tremaining: 6.33s\n",
      "201:\tlearn: 0.3875915\ttotal: 1.6s\tremaining: 6.31s\n",
      "202:\tlearn: 0.3864406\ttotal: 1.6s\tremaining: 6.3s\n",
      "203:\tlearn: 0.3855078\ttotal: 1.61s\tremaining: 6.29s\n",
      "204:\tlearn: 0.3851190\ttotal: 1.62s\tremaining: 6.28s\n",
      "205:\tlearn: 0.3837885\ttotal: 1.63s\tremaining: 6.27s\n",
      "206:\tlearn: 0.3818040\ttotal: 1.64s\tremaining: 6.26s\n",
      "207:\tlearn: 0.3800081\ttotal: 1.64s\tremaining: 6.26s\n",
      "208:\tlearn: 0.3780388\ttotal: 1.65s\tremaining: 6.25s\n",
      "209:\tlearn: 0.3777702\ttotal: 1.66s\tremaining: 6.23s\n",
      "210:\tlearn: 0.3759771\ttotal: 1.66s\tremaining: 6.22s\n",
      "211:\tlearn: 0.3749379\ttotal: 1.67s\tremaining: 6.21s\n",
      "212:\tlearn: 0.3732629\ttotal: 1.67s\tremaining: 6.18s\n",
      "213:\tlearn: 0.3717714\ttotal: 1.68s\tremaining: 6.16s\n",
      "214:\tlearn: 0.3704534\ttotal: 1.68s\tremaining: 6.14s\n",
      "215:\tlearn: 0.3690204\ttotal: 1.69s\tremaining: 6.12s\n",
      "216:\tlearn: 0.3675924\ttotal: 1.69s\tremaining: 6.1s\n",
      "217:\tlearn: 0.3659811\ttotal: 1.69s\tremaining: 6.08s\n",
      "218:\tlearn: 0.3644188\ttotal: 1.7s\tremaining: 6.07s\n",
      "219:\tlearn: 0.3635658\ttotal: 1.71s\tremaining: 6.06s\n",
      "220:\tlearn: 0.3621360\ttotal: 1.72s\tremaining: 6.05s\n",
      "221:\tlearn: 0.3605464\ttotal: 1.72s\tremaining: 6.03s\n",
      "222:\tlearn: 0.3596220\ttotal: 1.73s\tremaining: 6.01s\n",
      "223:\tlearn: 0.3592642\ttotal: 1.73s\tremaining: 6s\n",
      "224:\tlearn: 0.3578256\ttotal: 1.74s\tremaining: 5.99s\n",
      "225:\tlearn: 0.3575661\ttotal: 1.75s\tremaining: 5.98s\n",
      "226:\tlearn: 0.3566998\ttotal: 1.75s\tremaining: 5.98s\n",
      "227:\tlearn: 0.3552896\ttotal: 1.76s\tremaining: 5.97s\n",
      "228:\tlearn: 0.3538591\ttotal: 1.77s\tremaining: 5.96s\n",
      "229:\tlearn: 0.3526367\ttotal: 1.78s\tremaining: 5.95s\n",
      "230:\tlearn: 0.3511587\ttotal: 1.78s\tremaining: 5.94s\n",
      "231:\tlearn: 0.3499143\ttotal: 1.79s\tremaining: 5.93s\n",
      "232:\tlearn: 0.3484550\ttotal: 1.8s\tremaining: 5.92s\n",
      "233:\tlearn: 0.3479930\ttotal: 1.8s\tremaining: 5.91s\n",
      "234:\tlearn: 0.3474803\ttotal: 1.81s\tremaining: 5.91s\n",
      "235:\tlearn: 0.3462533\ttotal: 1.82s\tremaining: 5.9s\n",
      "236:\tlearn: 0.3451768\ttotal: 1.83s\tremaining: 5.89s\n",
      "237:\tlearn: 0.3449933\ttotal: 1.84s\tremaining: 5.89s\n",
      "238:\tlearn: 0.3441764\ttotal: 1.85s\tremaining: 5.88s\n",
      "239:\tlearn: 0.3437476\ttotal: 1.85s\tremaining: 5.87s\n",
      "240:\tlearn: 0.3424751\ttotal: 1.86s\tremaining: 5.87s\n",
      "241:\tlearn: 0.3410635\ttotal: 1.87s\tremaining: 5.86s\n",
      "242:\tlearn: 0.3402792\ttotal: 1.88s\tremaining: 5.85s\n",
      "243:\tlearn: 0.3397922\ttotal: 1.89s\tremaining: 5.85s\n",
      "244:\tlearn: 0.3393560\ttotal: 1.9s\tremaining: 5.87s\n",
      "245:\tlearn: 0.3378795\ttotal: 1.91s\tremaining: 5.85s\n",
      "246:\tlearn: 0.3367550\ttotal: 1.91s\tremaining: 5.84s\n",
      "247:\tlearn: 0.3354369\ttotal: 1.92s\tremaining: 5.82s\n",
      "248:\tlearn: 0.3344952\ttotal: 1.93s\tremaining: 5.81s\n",
      "249:\tlearn: 0.3333368\ttotal: 1.94s\tremaining: 5.81s\n",
      "250:\tlearn: 0.3321241\ttotal: 1.94s\tremaining: 5.8s\n",
      "251:\tlearn: 0.3312130\ttotal: 1.95s\tremaining: 5.79s\n",
      "252:\tlearn: 0.3303660\ttotal: 1.96s\tremaining: 5.78s\n",
      "253:\tlearn: 0.3291534\ttotal: 1.97s\tremaining: 5.78s\n",
      "254:\tlearn: 0.3279875\ttotal: 1.98s\tremaining: 5.77s\n",
      "255:\tlearn: 0.3267853\ttotal: 1.98s\tremaining: 5.77s\n",
      "256:\tlearn: 0.3255345\ttotal: 1.99s\tremaining: 5.76s\n",
      "257:\tlearn: 0.3246802\ttotal: 2s\tremaining: 5.75s\n",
      "258:\tlearn: 0.3244480\ttotal: 2.01s\tremaining: 5.74s\n",
      "259:\tlearn: 0.3232427\ttotal: 2.02s\tremaining: 5.74s\n",
      "260:\tlearn: 0.3230031\ttotal: 2.02s\tremaining: 5.72s\n",
      "261:\tlearn: 0.3227603\ttotal: 2.03s\tremaining: 5.71s\n",
      "262:\tlearn: 0.3222681\ttotal: 2.04s\tremaining: 5.7s\n",
      "263:\tlearn: 0.3212627\ttotal: 2.04s\tremaining: 5.7s\n",
      "264:\tlearn: 0.3201232\ttotal: 2.05s\tremaining: 5.69s\n",
      "265:\tlearn: 0.3190658\ttotal: 2.06s\tremaining: 5.68s\n",
      "266:\tlearn: 0.3189159\ttotal: 2.07s\tremaining: 5.68s\n",
      "267:\tlearn: 0.3179139\ttotal: 2.07s\tremaining: 5.66s\n",
      "268:\tlearn: 0.3168377\ttotal: 2.08s\tremaining: 5.65s\n",
      "269:\tlearn: 0.3166331\ttotal: 2.08s\tremaining: 5.63s\n",
      "270:\tlearn: 0.3156225\ttotal: 2.09s\tremaining: 5.62s\n",
      "271:\tlearn: 0.3151646\ttotal: 2.09s\tremaining: 5.61s\n",
      "272:\tlearn: 0.3148685\ttotal: 2.1s\tremaining: 5.59s\n",
      "273:\tlearn: 0.3139626\ttotal: 2.11s\tremaining: 5.58s\n",
      "274:\tlearn: 0.3135380\ttotal: 2.11s\tremaining: 5.58s\n",
      "275:\tlearn: 0.3126920\ttotal: 2.12s\tremaining: 5.57s\n",
      "276:\tlearn: 0.3117265\ttotal: 2.13s\tremaining: 5.56s\n",
      "277:\tlearn: 0.3107653\ttotal: 2.14s\tremaining: 5.55s\n",
      "278:\tlearn: 0.3099310\ttotal: 2.15s\tremaining: 5.55s\n",
      "279:\tlearn: 0.3097347\ttotal: 2.15s\tremaining: 5.54s\n",
      "280:\tlearn: 0.3088664\ttotal: 2.16s\tremaining: 5.53s\n",
      "281:\tlearn: 0.3082194\ttotal: 2.17s\tremaining: 5.53s\n",
      "282:\tlearn: 0.3073630\ttotal: 2.18s\tremaining: 5.52s\n",
      "283:\tlearn: 0.3066683\ttotal: 2.19s\tremaining: 5.51s\n",
      "284:\tlearn: 0.3065079\ttotal: 2.19s\tremaining: 5.51s\n",
      "285:\tlearn: 0.3056232\ttotal: 2.2s\tremaining: 5.5s\n",
      "286:\tlearn: 0.3053265\ttotal: 2.21s\tremaining: 5.49s\n",
      "287:\tlearn: 0.3049598\ttotal: 2.22s\tremaining: 5.48s\n",
      "288:\tlearn: 0.3047347\ttotal: 2.23s\tremaining: 5.48s\n",
      "289:\tlearn: 0.3045533\ttotal: 2.23s\tremaining: 5.47s\n",
      "290:\tlearn: 0.3037840\ttotal: 2.24s\tremaining: 5.46s\n",
      "291:\tlearn: 0.3027589\ttotal: 2.24s\tremaining: 5.44s\n",
      "292:\tlearn: 0.3025612\ttotal: 2.25s\tremaining: 5.43s\n",
      "293:\tlearn: 0.3017984\ttotal: 2.26s\tremaining: 5.42s\n",
      "294:\tlearn: 0.3011179\ttotal: 2.26s\tremaining: 5.41s\n",
      "295:\tlearn: 0.3009722\ttotal: 2.27s\tremaining: 5.39s\n",
      "296:\tlearn: 0.3000171\ttotal: 2.27s\tremaining: 5.38s\n",
      "297:\tlearn: 0.2993786\ttotal: 2.28s\tremaining: 5.37s\n",
      "298:\tlearn: 0.2985659\ttotal: 2.29s\tremaining: 5.36s\n",
      "299:\tlearn: 0.2980197\ttotal: 2.29s\tremaining: 5.35s\n",
      "300:\tlearn: 0.2967916\ttotal: 2.3s\tremaining: 5.35s\n",
      "301:\tlearn: 0.2956344\ttotal: 2.31s\tremaining: 5.34s\n",
      "302:\tlearn: 0.2945778\ttotal: 2.32s\tremaining: 5.33s\n",
      "303:\tlearn: 0.2942705\ttotal: 2.33s\tremaining: 5.33s\n",
      "304:\tlearn: 0.2939606\ttotal: 2.33s\tremaining: 5.32s\n",
      "305:\tlearn: 0.2936162\ttotal: 2.34s\tremaining: 5.31s\n",
      "306:\tlearn: 0.2926760\ttotal: 2.35s\tremaining: 5.31s\n",
      "307:\tlearn: 0.2917455\ttotal: 2.36s\tremaining: 5.3s\n",
      "308:\tlearn: 0.2916072\ttotal: 2.37s\tremaining: 5.29s\n",
      "309:\tlearn: 0.2910191\ttotal: 2.37s\tremaining: 5.28s\n",
      "310:\tlearn: 0.2901355\ttotal: 2.38s\tremaining: 5.28s\n",
      "311:\tlearn: 0.2894453\ttotal: 2.39s\tremaining: 5.28s\n",
      "312:\tlearn: 0.2886172\ttotal: 2.4s\tremaining: 5.26s\n",
      "313:\tlearn: 0.2882986\ttotal: 2.4s\tremaining: 5.25s\n",
      "314:\tlearn: 0.2871607\ttotal: 2.41s\tremaining: 5.24s\n",
      "315:\tlearn: 0.2863876\ttotal: 2.42s\tremaining: 5.23s\n",
      "316:\tlearn: 0.2857416\ttotal: 2.42s\tremaining: 5.23s\n",
      "317:\tlearn: 0.2847046\ttotal: 2.43s\tremaining: 5.22s\n",
      "318:\tlearn: 0.2844678\ttotal: 2.44s\tremaining: 5.21s\n",
      "319:\tlearn: 0.2833852\ttotal: 2.45s\tremaining: 5.2s\n",
      "320:\tlearn: 0.2828654\ttotal: 2.46s\tremaining: 5.2s\n",
      "321:\tlearn: 0.2823016\ttotal: 2.46s\tremaining: 5.19s\n",
      "322:\tlearn: 0.2810848\ttotal: 2.47s\tremaining: 5.18s\n",
      "323:\tlearn: 0.2801693\ttotal: 2.48s\tremaining: 5.18s\n",
      "324:\tlearn: 0.2796477\ttotal: 2.49s\tremaining: 5.17s\n",
      "325:\tlearn: 0.2791871\ttotal: 2.5s\tremaining: 5.17s\n",
      "326:\tlearn: 0.2789425\ttotal: 2.51s\tremaining: 5.16s\n",
      "327:\tlearn: 0.2782427\ttotal: 2.51s\tremaining: 5.15s\n",
      "328:\tlearn: 0.2779601\ttotal: 2.52s\tremaining: 5.14s\n",
      "329:\tlearn: 0.2776659\ttotal: 2.53s\tremaining: 5.14s\n",
      "330:\tlearn: 0.2767513\ttotal: 2.54s\tremaining: 5.13s\n",
      "331:\tlearn: 0.2757797\ttotal: 2.54s\tremaining: 5.12s\n",
      "332:\tlearn: 0.2750558\ttotal: 2.55s\tremaining: 5.11s\n",
      "333:\tlearn: 0.2748777\ttotal: 2.56s\tremaining: 5.11s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "334:\tlearn: 0.2740517\ttotal: 2.57s\tremaining: 5.1s\n",
      "335:\tlearn: 0.2739025\ttotal: 2.58s\tremaining: 5.09s\n",
      "336:\tlearn: 0.2734116\ttotal: 2.58s\tremaining: 5.07s\n",
      "337:\tlearn: 0.2730089\ttotal: 2.58s\tremaining: 5.06s\n",
      "338:\tlearn: 0.2722461\ttotal: 2.59s\tremaining: 5.04s\n",
      "339:\tlearn: 0.2721227\ttotal: 2.59s\tremaining: 5.03s\n",
      "340:\tlearn: 0.2711574\ttotal: 2.6s\tremaining: 5.02s\n",
      "341:\tlearn: 0.2706013\ttotal: 2.6s\tremaining: 5.01s\n",
      "342:\tlearn: 0.2697500\ttotal: 2.61s\tremaining: 5s\n",
      "343:\tlearn: 0.2689522\ttotal: 2.62s\tremaining: 4.99s\n",
      "344:\tlearn: 0.2683501\ttotal: 2.62s\tremaining: 4.98s\n",
      "345:\tlearn: 0.2673131\ttotal: 2.63s\tremaining: 4.97s\n",
      "346:\tlearn: 0.2667011\ttotal: 2.64s\tremaining: 4.96s\n",
      "347:\tlearn: 0.2665401\ttotal: 2.64s\tremaining: 4.95s\n",
      "348:\tlearn: 0.2656472\ttotal: 2.65s\tremaining: 4.95s\n",
      "349:\tlearn: 0.2652484\ttotal: 2.66s\tremaining: 4.94s\n",
      "350:\tlearn: 0.2645574\ttotal: 2.67s\tremaining: 4.93s\n",
      "351:\tlearn: 0.2639399\ttotal: 2.68s\tremaining: 4.93s\n",
      "352:\tlearn: 0.2635165\ttotal: 2.68s\tremaining: 4.92s\n",
      "353:\tlearn: 0.2628496\ttotal: 2.69s\tremaining: 4.91s\n",
      "354:\tlearn: 0.2620221\ttotal: 2.7s\tremaining: 4.91s\n",
      "355:\tlearn: 0.2612508\ttotal: 2.71s\tremaining: 4.89s\n",
      "356:\tlearn: 0.2610695\ttotal: 2.71s\tremaining: 4.89s\n",
      "357:\tlearn: 0.2609199\ttotal: 2.72s\tremaining: 4.88s\n",
      "358:\tlearn: 0.2601211\ttotal: 2.73s\tremaining: 4.87s\n",
      "359:\tlearn: 0.2599579\ttotal: 2.74s\tremaining: 4.87s\n",
      "360:\tlearn: 0.2598076\ttotal: 2.74s\tremaining: 4.86s\n",
      "361:\tlearn: 0.2592174\ttotal: 2.75s\tremaining: 4.85s\n",
      "362:\tlearn: 0.2588161\ttotal: 2.75s\tremaining: 4.83s\n",
      "363:\tlearn: 0.2582175\ttotal: 2.76s\tremaining: 4.82s\n",
      "364:\tlearn: 0.2574064\ttotal: 2.76s\tremaining: 4.81s\n",
      "365:\tlearn: 0.2568574\ttotal: 2.77s\tremaining: 4.8s\n",
      "366:\tlearn: 0.2559608\ttotal: 2.78s\tremaining: 4.79s\n",
      "367:\tlearn: 0.2551262\ttotal: 2.79s\tremaining: 4.79s\n",
      "368:\tlearn: 0.2544196\ttotal: 2.79s\tremaining: 4.78s\n",
      "369:\tlearn: 0.2540147\ttotal: 2.8s\tremaining: 4.77s\n",
      "370:\tlearn: 0.2535803\ttotal: 2.81s\tremaining: 4.76s\n",
      "371:\tlearn: 0.2533366\ttotal: 2.82s\tremaining: 4.76s\n",
      "372:\tlearn: 0.2526969\ttotal: 2.83s\tremaining: 4.75s\n",
      "373:\tlearn: 0.2520558\ttotal: 2.83s\tremaining: 4.74s\n",
      "374:\tlearn: 0.2516057\ttotal: 2.84s\tremaining: 4.74s\n",
      "375:\tlearn: 0.2510456\ttotal: 2.85s\tremaining: 4.73s\n",
      "376:\tlearn: 0.2502909\ttotal: 2.86s\tremaining: 4.72s\n",
      "377:\tlearn: 0.2500635\ttotal: 2.86s\tremaining: 4.71s\n",
      "378:\tlearn: 0.2495658\ttotal: 2.87s\tremaining: 4.71s\n",
      "379:\tlearn: 0.2490759\ttotal: 2.88s\tremaining: 4.7s\n",
      "380:\tlearn: 0.2484241\ttotal: 2.89s\tremaining: 4.69s\n",
      "381:\tlearn: 0.2482082\ttotal: 2.89s\tremaining: 4.68s\n",
      "382:\tlearn: 0.2475839\ttotal: 2.9s\tremaining: 4.68s\n",
      "383:\tlearn: 0.2471507\ttotal: 2.91s\tremaining: 4.67s\n",
      "384:\tlearn: 0.2464433\ttotal: 2.92s\tremaining: 4.66s\n",
      "385:\tlearn: 0.2458531\ttotal: 2.92s\tremaining: 4.65s\n",
      "386:\tlearn: 0.2453556\ttotal: 2.93s\tremaining: 4.64s\n",
      "387:\tlearn: 0.2444587\ttotal: 2.94s\tremaining: 4.63s\n",
      "388:\tlearn: 0.2438126\ttotal: 2.94s\tremaining: 4.62s\n",
      "389:\tlearn: 0.2430007\ttotal: 2.95s\tremaining: 4.61s\n",
      "390:\tlearn: 0.2428775\ttotal: 2.95s\tremaining: 4.6s\n",
      "391:\tlearn: 0.2427490\ttotal: 2.96s\tremaining: 4.58s\n",
      "392:\tlearn: 0.2426087\ttotal: 2.96s\tremaining: 4.57s\n",
      "393:\tlearn: 0.2419167\ttotal: 2.97s\tremaining: 4.56s\n",
      "394:\tlearn: 0.2418906\ttotal: 2.97s\tremaining: 4.55s\n",
      "395:\tlearn: 0.2413343\ttotal: 2.98s\tremaining: 4.54s\n",
      "396:\tlearn: 0.2409090\ttotal: 2.99s\tremaining: 4.54s\n",
      "397:\tlearn: 0.2405010\ttotal: 3s\tremaining: 4.53s\n",
      "398:\tlearn: 0.2401459\ttotal: 3s\tremaining: 4.52s\n",
      "399:\tlearn: 0.2400451\ttotal: 3.01s\tremaining: 4.52s\n",
      "400:\tlearn: 0.2395199\ttotal: 3.02s\tremaining: 4.51s\n",
      "401:\tlearn: 0.2390716\ttotal: 3.02s\tremaining: 4.5s\n",
      "402:\tlearn: 0.2385141\ttotal: 3.03s\tremaining: 4.49s\n",
      "403:\tlearn: 0.2378708\ttotal: 3.04s\tremaining: 4.49s\n",
      "404:\tlearn: 0.2371439\ttotal: 3.04s\tremaining: 4.47s\n",
      "405:\tlearn: 0.2364290\ttotal: 3.05s\tremaining: 4.46s\n",
      "406:\tlearn: 0.2358883\ttotal: 3.06s\tremaining: 4.45s\n",
      "407:\tlearn: 0.2356209\ttotal: 3.06s\tremaining: 4.44s\n",
      "408:\tlearn: 0.2354734\ttotal: 3.07s\tremaining: 4.43s\n",
      "409:\tlearn: 0.2353671\ttotal: 3.07s\tremaining: 4.42s\n",
      "410:\tlearn: 0.2348653\ttotal: 3.08s\tremaining: 4.41s\n",
      "411:\tlearn: 0.2341903\ttotal: 3.09s\tremaining: 4.41s\n",
      "412:\tlearn: 0.2336348\ttotal: 3.09s\tremaining: 4.39s\n",
      "413:\tlearn: 0.2331116\ttotal: 3.1s\tremaining: 4.39s\n",
      "414:\tlearn: 0.2324890\ttotal: 3.1s\tremaining: 4.38s\n",
      "415:\tlearn: 0.2323986\ttotal: 3.11s\tremaining: 4.37s\n",
      "416:\tlearn: 0.2322193\ttotal: 3.12s\tremaining: 4.36s\n",
      "417:\tlearn: 0.2317482\ttotal: 3.12s\tremaining: 4.35s\n",
      "418:\tlearn: 0.2313778\ttotal: 3.13s\tremaining: 4.34s\n",
      "419:\tlearn: 0.2312449\ttotal: 3.13s\tremaining: 4.33s\n",
      "420:\tlearn: 0.2306546\ttotal: 3.14s\tremaining: 4.32s\n",
      "421:\tlearn: 0.2301904\ttotal: 3.15s\tremaining: 4.32s\n",
      "422:\tlearn: 0.2297585\ttotal: 3.16s\tremaining: 4.31s\n",
      "423:\tlearn: 0.2291797\ttotal: 3.17s\tremaining: 4.3s\n",
      "424:\tlearn: 0.2290675\ttotal: 3.18s\tremaining: 4.3s\n",
      "425:\tlearn: 0.2290440\ttotal: 3.18s\tremaining: 4.29s\n",
      "426:\tlearn: 0.2284480\ttotal: 3.19s\tremaining: 4.28s\n",
      "427:\tlearn: 0.2278080\ttotal: 3.2s\tremaining: 4.27s\n",
      "428:\tlearn: 0.2274305\ttotal: 3.2s\tremaining: 4.26s\n",
      "429:\tlearn: 0.2271293\ttotal: 3.21s\tremaining: 4.26s\n",
      "430:\tlearn: 0.2270018\ttotal: 3.22s\tremaining: 4.25s\n",
      "431:\tlearn: 0.2268620\ttotal: 3.23s\tremaining: 4.24s\n",
      "432:\tlearn: 0.2265679\ttotal: 3.23s\tremaining: 4.23s\n",
      "433:\tlearn: 0.2265453\ttotal: 3.24s\tremaining: 4.22s\n",
      "434:\tlearn: 0.2260515\ttotal: 3.24s\tremaining: 4.21s\n",
      "435:\tlearn: 0.2256329\ttotal: 3.26s\tremaining: 4.22s\n",
      "436:\tlearn: 0.2250517\ttotal: 3.27s\tremaining: 4.21s\n",
      "437:\tlearn: 0.2246317\ttotal: 3.27s\tremaining: 4.2s\n",
      "438:\tlearn: 0.2240984\ttotal: 3.28s\tremaining: 4.2s\n",
      "439:\tlearn: 0.2236692\ttotal: 3.29s\tremaining: 4.19s\n",
      "440:\tlearn: 0.2230957\ttotal: 3.3s\tremaining: 4.18s\n",
      "441:\tlearn: 0.2225038\ttotal: 3.31s\tremaining: 4.17s\n",
      "442:\tlearn: 0.2219394\ttotal: 3.31s\tremaining: 4.17s\n",
      "443:\tlearn: 0.2215012\ttotal: 3.32s\tremaining: 4.16s\n",
      "444:\tlearn: 0.2210305\ttotal: 3.33s\tremaining: 4.15s\n",
      "445:\tlearn: 0.2207139\ttotal: 3.33s\tremaining: 4.14s\n",
      "446:\tlearn: 0.2201898\ttotal: 3.34s\tremaining: 4.13s\n",
      "447:\tlearn: 0.2196194\ttotal: 3.35s\tremaining: 4.13s\n",
      "448:\tlearn: 0.2190861\ttotal: 3.36s\tremaining: 4.12s\n",
      "449:\tlearn: 0.2186007\ttotal: 3.36s\tremaining: 4.11s\n",
      "450:\tlearn: 0.2180944\ttotal: 3.37s\tremaining: 4.1s\n",
      "451:\tlearn: 0.2177356\ttotal: 3.38s\tremaining: 4.09s\n",
      "452:\tlearn: 0.2172795\ttotal: 3.38s\tremaining: 4.09s\n",
      "453:\tlearn: 0.2170965\ttotal: 3.39s\tremaining: 4.08s\n",
      "454:\tlearn: 0.2170739\ttotal: 3.4s\tremaining: 4.07s\n",
      "455:\tlearn: 0.2167628\ttotal: 3.41s\tremaining: 4.07s\n",
      "456:\tlearn: 0.2166148\ttotal: 3.42s\tremaining: 4.06s\n",
      "457:\tlearn: 0.2164507\ttotal: 3.43s\tremaining: 4.06s\n",
      "458:\tlearn: 0.2161087\ttotal: 3.44s\tremaining: 4.06s\n",
      "459:\tlearn: 0.2159218\ttotal: 3.45s\tremaining: 4.05s\n",
      "460:\tlearn: 0.2159039\ttotal: 3.46s\tremaining: 4.04s\n",
      "461:\tlearn: 0.2154983\ttotal: 3.47s\tremaining: 4.04s\n",
      "462:\tlearn: 0.2152329\ttotal: 3.47s\tremaining: 4.03s\n",
      "463:\tlearn: 0.2148426\ttotal: 3.48s\tremaining: 4.02s\n",
      "464:\tlearn: 0.2144747\ttotal: 3.49s\tremaining: 4.01s\n",
      "465:\tlearn: 0.2144574\ttotal: 3.49s\tremaining: 4s\n",
      "466:\tlearn: 0.2141495\ttotal: 3.5s\tremaining: 3.99s\n",
      "467:\tlearn: 0.2139015\ttotal: 3.5s\tremaining: 3.98s\n",
      "468:\tlearn: 0.2138849\ttotal: 3.51s\tremaining: 3.98s\n",
      "469:\tlearn: 0.2136036\ttotal: 3.52s\tremaining: 3.97s\n",
      "470:\tlearn: 0.2135875\ttotal: 3.53s\tremaining: 3.96s\n",
      "471:\tlearn: 0.2132873\ttotal: 3.54s\tremaining: 3.96s\n",
      "472:\tlearn: 0.2131541\ttotal: 3.54s\tremaining: 3.95s\n",
      "473:\tlearn: 0.2128215\ttotal: 3.55s\tremaining: 3.94s\n",
      "474:\tlearn: 0.2125286\ttotal: 3.55s\tremaining: 3.93s\n",
      "475:\tlearn: 0.2123368\ttotal: 3.56s\tremaining: 3.92s\n",
      "476:\tlearn: 0.2121870\ttotal: 3.57s\tremaining: 3.91s\n",
      "477:\tlearn: 0.2116064\ttotal: 3.57s\tremaining: 3.9s\n",
      "478:\tlearn: 0.2109984\ttotal: 3.58s\tremaining: 3.89s\n",
      "479:\tlearn: 0.2105746\ttotal: 3.58s\tremaining: 3.88s\n",
      "480:\tlearn: 0.2101755\ttotal: 3.59s\tremaining: 3.87s\n",
      "481:\tlearn: 0.2099099\ttotal: 3.6s\tremaining: 3.86s\n",
      "482:\tlearn: 0.2095172\ttotal: 3.6s\tremaining: 3.85s\n",
      "483:\tlearn: 0.2090436\ttotal: 3.61s\tremaining: 3.85s\n",
      "484:\tlearn: 0.2088238\ttotal: 3.61s\tremaining: 3.83s\n",
      "485:\tlearn: 0.2084721\ttotal: 3.62s\tremaining: 3.82s\n",
      "486:\tlearn: 0.2080954\ttotal: 3.62s\tremaining: 3.81s\n",
      "487:\tlearn: 0.2076204\ttotal: 3.63s\tremaining: 3.81s\n",
      "488:\tlearn: 0.2070927\ttotal: 3.63s\tremaining: 3.8s\n",
      "489:\tlearn: 0.2066529\ttotal: 3.64s\tremaining: 3.79s\n",
      "490:\tlearn: 0.2060241\ttotal: 3.65s\tremaining: 3.78s\n",
      "491:\tlearn: 0.2056703\ttotal: 3.66s\tremaining: 3.78s\n",
      "492:\tlearn: 0.2052078\ttotal: 3.66s\tremaining: 3.77s\n",
      "493:\tlearn: 0.2046941\ttotal: 3.67s\tremaining: 3.76s\n",
      "494:\tlearn: 0.2041293\ttotal: 3.68s\tremaining: 3.75s\n",
      "495:\tlearn: 0.2036615\ttotal: 3.69s\tremaining: 3.75s\n",
      "496:\tlearn: 0.2032483\ttotal: 3.69s\tremaining: 3.74s\n",
      "497:\tlearn: 0.2028946\ttotal: 3.7s\tremaining: 3.73s\n",
      "498:\tlearn: 0.2028784\ttotal: 3.71s\tremaining: 3.72s\n",
      "499:\tlearn: 0.2024753\ttotal: 3.72s\tremaining: 3.72s\n",
      "500:\tlearn: 0.2020536\ttotal: 3.72s\tremaining: 3.71s\n",
      "501:\tlearn: 0.2016227\ttotal: 3.73s\tremaining: 3.7s\n",
      "502:\tlearn: 0.2012310\ttotal: 3.73s\tremaining: 3.69s\n",
      "503:\tlearn: 0.2009565\ttotal: 3.74s\tremaining: 3.68s\n",
      "504:\tlearn: 0.2004918\ttotal: 3.75s\tremaining: 3.67s\n",
      "505:\tlearn: 0.2003697\ttotal: 3.75s\tremaining: 3.66s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "506:\tlearn: 0.1999287\ttotal: 3.76s\tremaining: 3.66s\n",
      "507:\tlearn: 0.1995568\ttotal: 3.76s\tremaining: 3.65s\n",
      "508:\tlearn: 0.1995410\ttotal: 3.77s\tremaining: 3.64s\n",
      "509:\tlearn: 0.1995257\ttotal: 3.78s\tremaining: 3.63s\n",
      "510:\tlearn: 0.1992113\ttotal: 3.78s\tremaining: 3.62s\n",
      "511:\tlearn: 0.1987415\ttotal: 3.79s\tremaining: 3.61s\n",
      "512:\tlearn: 0.1983918\ttotal: 3.79s\tremaining: 3.6s\n",
      "513:\tlearn: 0.1981505\ttotal: 3.8s\tremaining: 3.59s\n",
      "514:\tlearn: 0.1977646\ttotal: 3.81s\tremaining: 3.58s\n",
      "515:\tlearn: 0.1975868\ttotal: 3.81s\tremaining: 3.58s\n",
      "516:\tlearn: 0.1975720\ttotal: 3.82s\tremaining: 3.57s\n",
      "517:\tlearn: 0.1975577\ttotal: 3.83s\tremaining: 3.56s\n",
      "518:\tlearn: 0.1973752\ttotal: 3.83s\tremaining: 3.55s\n",
      "519:\tlearn: 0.1972076\ttotal: 3.84s\tremaining: 3.55s\n",
      "520:\tlearn: 0.1970117\ttotal: 3.85s\tremaining: 3.54s\n",
      "521:\tlearn: 0.1964858\ttotal: 3.86s\tremaining: 3.53s\n",
      "522:\tlearn: 0.1963258\ttotal: 3.86s\tremaining: 3.52s\n",
      "523:\tlearn: 0.1962220\ttotal: 3.87s\tremaining: 3.52s\n",
      "524:\tlearn: 0.1959104\ttotal: 3.88s\tremaining: 3.51s\n",
      "525:\tlearn: 0.1955067\ttotal: 3.88s\tremaining: 3.5s\n",
      "526:\tlearn: 0.1952653\ttotal: 3.89s\tremaining: 3.49s\n",
      "527:\tlearn: 0.1948712\ttotal: 3.89s\tremaining: 3.48s\n",
      "528:\tlearn: 0.1945140\ttotal: 3.9s\tremaining: 3.48s\n",
      "529:\tlearn: 0.1942438\ttotal: 3.91s\tremaining: 3.47s\n",
      "530:\tlearn: 0.1941172\ttotal: 3.92s\tremaining: 3.46s\n",
      "531:\tlearn: 0.1938464\ttotal: 3.93s\tremaining: 3.45s\n",
      "532:\tlearn: 0.1937317\ttotal: 3.93s\tremaining: 3.44s\n",
      "533:\tlearn: 0.1936298\ttotal: 3.94s\tremaining: 3.44s\n",
      "534:\tlearn: 0.1932715\ttotal: 3.94s\tremaining: 3.43s\n",
      "535:\tlearn: 0.1931946\ttotal: 3.95s\tremaining: 3.42s\n",
      "536:\tlearn: 0.1929063\ttotal: 3.96s\tremaining: 3.41s\n",
      "537:\tlearn: 0.1928293\ttotal: 3.96s\tremaining: 3.4s\n",
      "538:\tlearn: 0.1924820\ttotal: 3.97s\tremaining: 3.39s\n",
      "539:\tlearn: 0.1922176\ttotal: 3.97s\tremaining: 3.38s\n",
      "540:\tlearn: 0.1918182\ttotal: 3.98s\tremaining: 3.38s\n",
      "541:\tlearn: 0.1914579\ttotal: 3.99s\tremaining: 3.37s\n",
      "542:\tlearn: 0.1911864\ttotal: 4s\tremaining: 3.36s\n",
      "543:\tlearn: 0.1908660\ttotal: 4s\tremaining: 3.35s\n",
      "544:\tlearn: 0.1907225\ttotal: 4.01s\tremaining: 3.35s\n",
      "545:\tlearn: 0.1902473\ttotal: 4.01s\tremaining: 3.34s\n",
      "546:\tlearn: 0.1899586\ttotal: 4.02s\tremaining: 3.33s\n",
      "547:\tlearn: 0.1898868\ttotal: 4.03s\tremaining: 3.32s\n",
      "548:\tlearn: 0.1896583\ttotal: 4.04s\tremaining: 3.32s\n",
      "549:\tlearn: 0.1895901\ttotal: 4.04s\tremaining: 3.31s\n",
      "550:\tlearn: 0.1892248\ttotal: 4.05s\tremaining: 3.3s\n",
      "551:\tlearn: 0.1891589\ttotal: 4.06s\tremaining: 3.29s\n",
      "552:\tlearn: 0.1887108\ttotal: 4.06s\tremaining: 3.28s\n",
      "553:\tlearn: 0.1882778\ttotal: 4.07s\tremaining: 3.28s\n",
      "554:\tlearn: 0.1880646\ttotal: 4.08s\tremaining: 3.27s\n",
      "555:\tlearn: 0.1877649\ttotal: 4.09s\tremaining: 3.26s\n",
      "556:\tlearn: 0.1875655\ttotal: 4.09s\tremaining: 3.25s\n",
      "557:\tlearn: 0.1870547\ttotal: 4.1s\tremaining: 3.25s\n",
      "558:\tlearn: 0.1866418\ttotal: 4.11s\tremaining: 3.24s\n",
      "559:\tlearn: 0.1864119\ttotal: 4.11s\tremaining: 3.23s\n",
      "560:\tlearn: 0.1861773\ttotal: 4.12s\tremaining: 3.22s\n",
      "561:\tlearn: 0.1860886\ttotal: 4.13s\tremaining: 3.22s\n",
      "562:\tlearn: 0.1857353\ttotal: 4.14s\tremaining: 3.21s\n",
      "563:\tlearn: 0.1854753\ttotal: 4.14s\tremaining: 3.2s\n",
      "564:\tlearn: 0.1851405\ttotal: 4.15s\tremaining: 3.19s\n",
      "565:\tlearn: 0.1848334\ttotal: 4.15s\tremaining: 3.19s\n",
      "566:\tlearn: 0.1844464\ttotal: 4.16s\tremaining: 3.18s\n",
      "567:\tlearn: 0.1840464\ttotal: 4.16s\tremaining: 3.17s\n",
      "568:\tlearn: 0.1836977\ttotal: 4.17s\tremaining: 3.16s\n",
      "569:\tlearn: 0.1833386\ttotal: 4.18s\tremaining: 3.15s\n",
      "570:\tlearn: 0.1830700\ttotal: 4.18s\tremaining: 3.14s\n",
      "571:\tlearn: 0.1828712\ttotal: 4.19s\tremaining: 3.14s\n",
      "572:\tlearn: 0.1825240\ttotal: 4.2s\tremaining: 3.13s\n",
      "573:\tlearn: 0.1822734\ttotal: 4.21s\tremaining: 3.13s\n",
      "574:\tlearn: 0.1820398\ttotal: 4.22s\tremaining: 3.12s\n",
      "575:\tlearn: 0.1818917\ttotal: 4.22s\tremaining: 3.11s\n",
      "576:\tlearn: 0.1814972\ttotal: 4.23s\tremaining: 3.1s\n",
      "577:\tlearn: 0.1813770\ttotal: 4.24s\tremaining: 3.09s\n",
      "578:\tlearn: 0.1812716\ttotal: 4.24s\tremaining: 3.08s\n",
      "579:\tlearn: 0.1810671\ttotal: 4.25s\tremaining: 3.08s\n",
      "580:\tlearn: 0.1807456\ttotal: 4.25s\tremaining: 3.07s\n",
      "581:\tlearn: 0.1805760\ttotal: 4.28s\tremaining: 3.07s\n",
      "582:\tlearn: 0.1803914\ttotal: 4.28s\tremaining: 3.06s\n",
      "583:\tlearn: 0.1799791\ttotal: 4.29s\tremaining: 3.05s\n",
      "584:\tlearn: 0.1798491\ttotal: 4.29s\tremaining: 3.05s\n",
      "585:\tlearn: 0.1792870\ttotal: 4.3s\tremaining: 3.04s\n",
      "586:\tlearn: 0.1789955\ttotal: 4.31s\tremaining: 3.03s\n",
      "587:\tlearn: 0.1786489\ttotal: 4.32s\tremaining: 3.02s\n",
      "588:\tlearn: 0.1783077\ttotal: 4.32s\tremaining: 3.02s\n",
      "589:\tlearn: 0.1782243\ttotal: 4.33s\tremaining: 3.01s\n",
      "590:\tlearn: 0.1780910\ttotal: 4.34s\tremaining: 3s\n",
      "591:\tlearn: 0.1780141\ttotal: 4.35s\tremaining: 3s\n",
      "592:\tlearn: 0.1775180\ttotal: 4.36s\tremaining: 2.99s\n",
      "593:\tlearn: 0.1772488\ttotal: 4.36s\tremaining: 2.98s\n",
      "594:\tlearn: 0.1769294\ttotal: 4.37s\tremaining: 2.97s\n",
      "595:\tlearn: 0.1766437\ttotal: 4.37s\tremaining: 2.96s\n",
      "596:\tlearn: 0.1763343\ttotal: 4.38s\tremaining: 2.96s\n",
      "597:\tlearn: 0.1760406\ttotal: 4.39s\tremaining: 2.95s\n",
      "598:\tlearn: 0.1757805\ttotal: 4.39s\tremaining: 2.94s\n",
      "599:\tlearn: 0.1754681\ttotal: 4.4s\tremaining: 2.93s\n",
      "600:\tlearn: 0.1751928\ttotal: 4.41s\tremaining: 2.92s\n",
      "601:\tlearn: 0.1750984\ttotal: 4.41s\tremaining: 2.92s\n",
      "602:\tlearn: 0.1748947\ttotal: 4.42s\tremaining: 2.91s\n",
      "603:\tlearn: 0.1745642\ttotal: 4.43s\tremaining: 2.9s\n",
      "604:\tlearn: 0.1742962\ttotal: 4.44s\tremaining: 2.9s\n",
      "605:\tlearn: 0.1738244\ttotal: 4.44s\tremaining: 2.89s\n",
      "606:\tlearn: 0.1736219\ttotal: 4.45s\tremaining: 2.88s\n",
      "607:\tlearn: 0.1734395\ttotal: 4.45s\tremaining: 2.87s\n",
      "608:\tlearn: 0.1732517\ttotal: 4.46s\tremaining: 2.86s\n",
      "609:\tlearn: 0.1729492\ttotal: 4.46s\tremaining: 2.85s\n",
      "610:\tlearn: 0.1726954\ttotal: 4.47s\tremaining: 2.85s\n",
      "611:\tlearn: 0.1724255\ttotal: 4.48s\tremaining: 2.84s\n",
      "612:\tlearn: 0.1722416\ttotal: 4.48s\tremaining: 2.83s\n",
      "613:\tlearn: 0.1720037\ttotal: 4.49s\tremaining: 2.82s\n",
      "614:\tlearn: 0.1715023\ttotal: 4.49s\tremaining: 2.81s\n",
      "615:\tlearn: 0.1712315\ttotal: 4.5s\tremaining: 2.81s\n",
      "616:\tlearn: 0.1711527\ttotal: 4.51s\tremaining: 2.8s\n",
      "617:\tlearn: 0.1710083\ttotal: 4.51s\tremaining: 2.79s\n",
      "618:\tlearn: 0.1708098\ttotal: 4.53s\tremaining: 2.79s\n",
      "619:\tlearn: 0.1706839\ttotal: 4.53s\tremaining: 2.78s\n",
      "620:\tlearn: 0.1705240\ttotal: 4.54s\tremaining: 2.77s\n",
      "621:\tlearn: 0.1702859\ttotal: 4.55s\tremaining: 2.76s\n",
      "622:\tlearn: 0.1701947\ttotal: 4.55s\tremaining: 2.75s\n",
      "623:\tlearn: 0.1697706\ttotal: 4.56s\tremaining: 2.75s\n",
      "624:\tlearn: 0.1694950\ttotal: 4.56s\tremaining: 2.74s\n",
      "625:\tlearn: 0.1693839\ttotal: 4.57s\tremaining: 2.73s\n",
      "626:\tlearn: 0.1689597\ttotal: 4.58s\tremaining: 2.72s\n",
      "627:\tlearn: 0.1685333\ttotal: 4.58s\tremaining: 2.72s\n",
      "628:\tlearn: 0.1682647\ttotal: 4.59s\tremaining: 2.71s\n",
      "629:\tlearn: 0.1680409\ttotal: 4.6s\tremaining: 2.7s\n",
      "630:\tlearn: 0.1679667\ttotal: 4.61s\tremaining: 2.69s\n",
      "631:\tlearn: 0.1677951\ttotal: 4.62s\tremaining: 2.69s\n",
      "632:\tlearn: 0.1677216\ttotal: 4.62s\tremaining: 2.68s\n",
      "633:\tlearn: 0.1675747\ttotal: 4.63s\tremaining: 2.67s\n",
      "634:\tlearn: 0.1673111\ttotal: 4.64s\tremaining: 2.66s\n",
      "635:\tlearn: 0.1670734\ttotal: 4.64s\tremaining: 2.66s\n",
      "636:\tlearn: 0.1667700\ttotal: 4.65s\tremaining: 2.65s\n",
      "637:\tlearn: 0.1664375\ttotal: 4.65s\tremaining: 2.64s\n",
      "638:\tlearn: 0.1661577\ttotal: 4.66s\tremaining: 2.63s\n",
      "639:\tlearn: 0.1660466\ttotal: 4.67s\tremaining: 2.62s\n",
      "640:\tlearn: 0.1659771\ttotal: 4.67s\tremaining: 2.62s\n",
      "641:\tlearn: 0.1659187\ttotal: 4.68s\tremaining: 2.61s\n",
      "642:\tlearn: 0.1656121\ttotal: 4.68s\tremaining: 2.6s\n",
      "643:\tlearn: 0.1654369\ttotal: 4.69s\tremaining: 2.59s\n",
      "644:\tlearn: 0.1651864\ttotal: 4.7s\tremaining: 2.58s\n",
      "645:\tlearn: 0.1650221\ttotal: 4.7s\tremaining: 2.58s\n",
      "646:\tlearn: 0.1648682\ttotal: 4.71s\tremaining: 2.57s\n",
      "647:\tlearn: 0.1646849\ttotal: 4.71s\tremaining: 2.56s\n",
      "648:\tlearn: 0.1644421\ttotal: 4.72s\tremaining: 2.55s\n",
      "649:\tlearn: 0.1643773\ttotal: 4.73s\tremaining: 2.54s\n",
      "650:\tlearn: 0.1642789\ttotal: 4.73s\tremaining: 2.54s\n",
      "651:\tlearn: 0.1641323\ttotal: 4.74s\tremaining: 2.53s\n",
      "652:\tlearn: 0.1640555\ttotal: 4.75s\tremaining: 2.52s\n",
      "653:\tlearn: 0.1639584\ttotal: 4.76s\tremaining: 2.52s\n",
      "654:\tlearn: 0.1636528\ttotal: 4.76s\tremaining: 2.51s\n",
      "655:\tlearn: 0.1632623\ttotal: 4.77s\tremaining: 2.5s\n",
      "656:\tlearn: 0.1629814\ttotal: 4.78s\tremaining: 2.49s\n",
      "657:\tlearn: 0.1627201\ttotal: 4.78s\tremaining: 2.48s\n",
      "658:\tlearn: 0.1624509\ttotal: 4.79s\tremaining: 2.48s\n",
      "659:\tlearn: 0.1621083\ttotal: 4.8s\tremaining: 2.47s\n",
      "660:\tlearn: 0.1618702\ttotal: 4.81s\tremaining: 2.46s\n",
      "661:\tlearn: 0.1616224\ttotal: 4.81s\tremaining: 2.46s\n",
      "662:\tlearn: 0.1612931\ttotal: 4.82s\tremaining: 2.45s\n",
      "663:\tlearn: 0.1610810\ttotal: 4.83s\tremaining: 2.44s\n",
      "664:\tlearn: 0.1608909\ttotal: 4.83s\tremaining: 2.43s\n",
      "665:\tlearn: 0.1605847\ttotal: 4.84s\tremaining: 2.43s\n",
      "666:\tlearn: 0.1603253\ttotal: 4.86s\tremaining: 2.42s\n",
      "667:\tlearn: 0.1600898\ttotal: 4.86s\tremaining: 2.42s\n",
      "668:\tlearn: 0.1598067\ttotal: 4.87s\tremaining: 2.41s\n",
      "669:\tlearn: 0.1595241\ttotal: 4.88s\tremaining: 2.4s\n",
      "670:\tlearn: 0.1594704\ttotal: 4.88s\tremaining: 2.39s\n",
      "671:\tlearn: 0.1593283\ttotal: 4.89s\tremaining: 2.39s\n",
      "672:\tlearn: 0.1590635\ttotal: 4.9s\tremaining: 2.38s\n",
      "673:\tlearn: 0.1589039\ttotal: 4.9s\tremaining: 2.37s\n",
      "674:\tlearn: 0.1587200\ttotal: 4.91s\tremaining: 2.36s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "675:\tlearn: 0.1585325\ttotal: 4.92s\tremaining: 2.36s\n",
      "676:\tlearn: 0.1582649\ttotal: 4.93s\tremaining: 2.35s\n",
      "677:\tlearn: 0.1580935\ttotal: 4.93s\tremaining: 2.34s\n",
      "678:\tlearn: 0.1578326\ttotal: 4.94s\tremaining: 2.33s\n",
      "679:\tlearn: 0.1575827\ttotal: 4.95s\tremaining: 2.33s\n",
      "680:\tlearn: 0.1575233\ttotal: 4.95s\tremaining: 2.32s\n",
      "681:\tlearn: 0.1574259\ttotal: 4.96s\tremaining: 2.31s\n",
      "682:\tlearn: 0.1573486\ttotal: 4.96s\tremaining: 2.3s\n",
      "683:\tlearn: 0.1571147\ttotal: 4.97s\tremaining: 2.3s\n",
      "684:\tlearn: 0.1568825\ttotal: 4.98s\tremaining: 2.29s\n",
      "685:\tlearn: 0.1566460\ttotal: 4.99s\tremaining: 2.28s\n",
      "686:\tlearn: 0.1564949\ttotal: 4.99s\tremaining: 2.27s\n",
      "687:\tlearn: 0.1564376\ttotal: 5s\tremaining: 2.27s\n",
      "688:\tlearn: 0.1561755\ttotal: 5.01s\tremaining: 2.26s\n",
      "689:\tlearn: 0.1559459\ttotal: 5.01s\tremaining: 2.25s\n",
      "690:\tlearn: 0.1558288\ttotal: 5.02s\tremaining: 2.24s\n",
      "691:\tlearn: 0.1556711\ttotal: 5.03s\tremaining: 2.24s\n",
      "692:\tlearn: 0.1554577\ttotal: 5.03s\tremaining: 2.23s\n",
      "693:\tlearn: 0.1553785\ttotal: 5.04s\tremaining: 2.22s\n",
      "694:\tlearn: 0.1552819\ttotal: 5.05s\tremaining: 2.22s\n",
      "695:\tlearn: 0.1550720\ttotal: 5.06s\tremaining: 2.21s\n",
      "696:\tlearn: 0.1548411\ttotal: 5.06s\tremaining: 2.2s\n",
      "697:\tlearn: 0.1546639\ttotal: 5.07s\tremaining: 2.19s\n",
      "698:\tlearn: 0.1543751\ttotal: 5.08s\tremaining: 2.19s\n",
      "699:\tlearn: 0.1541094\ttotal: 5.08s\tremaining: 2.18s\n",
      "700:\tlearn: 0.1538435\ttotal: 5.09s\tremaining: 2.17s\n",
      "701:\tlearn: 0.1536296\ttotal: 5.1s\tremaining: 2.17s\n",
      "702:\tlearn: 0.1533871\ttotal: 5.11s\tremaining: 2.16s\n",
      "703:\tlearn: 0.1530745\ttotal: 5.12s\tremaining: 2.15s\n",
      "704:\tlearn: 0.1528686\ttotal: 5.12s\tremaining: 2.14s\n",
      "705:\tlearn: 0.1526454\ttotal: 5.13s\tremaining: 2.14s\n",
      "706:\tlearn: 0.1524067\ttotal: 5.14s\tremaining: 2.13s\n",
      "707:\tlearn: 0.1523159\ttotal: 5.15s\tremaining: 2.12s\n",
      "708:\tlearn: 0.1521425\ttotal: 5.15s\tremaining: 2.12s\n",
      "709:\tlearn: 0.1518720\ttotal: 5.16s\tremaining: 2.11s\n",
      "710:\tlearn: 0.1516940\ttotal: 5.17s\tremaining: 2.1s\n",
      "711:\tlearn: 0.1515144\ttotal: 5.18s\tremaining: 2.09s\n",
      "712:\tlearn: 0.1512103\ttotal: 5.18s\tremaining: 2.09s\n",
      "713:\tlearn: 0.1509557\ttotal: 5.19s\tremaining: 2.08s\n",
      "714:\tlearn: 0.1508712\ttotal: 5.2s\tremaining: 2.07s\n",
      "715:\tlearn: 0.1506289\ttotal: 5.21s\tremaining: 2.06s\n",
      "716:\tlearn: 0.1505497\ttotal: 5.22s\tremaining: 2.06s\n",
      "717:\tlearn: 0.1504794\ttotal: 5.22s\tremaining: 2.05s\n",
      "718:\tlearn: 0.1502564\ttotal: 5.23s\tremaining: 2.04s\n",
      "719:\tlearn: 0.1500444\ttotal: 5.24s\tremaining: 2.04s\n",
      "720:\tlearn: 0.1498811\ttotal: 5.25s\tremaining: 2.03s\n",
      "721:\tlearn: 0.1497181\ttotal: 5.25s\tremaining: 2.02s\n",
      "722:\tlearn: 0.1496696\ttotal: 5.26s\tremaining: 2.02s\n",
      "723:\tlearn: 0.1494225\ttotal: 5.27s\tremaining: 2.01s\n",
      "724:\tlearn: 0.1491996\ttotal: 5.27s\tremaining: 2s\n",
      "725:\tlearn: 0.1489791\ttotal: 5.28s\tremaining: 1.99s\n",
      "726:\tlearn: 0.1489167\ttotal: 5.29s\tremaining: 1.99s\n",
      "727:\tlearn: 0.1488431\ttotal: 5.3s\tremaining: 1.98s\n",
      "728:\tlearn: 0.1487751\ttotal: 5.3s\tremaining: 1.97s\n",
      "729:\tlearn: 0.1487279\ttotal: 5.31s\tremaining: 1.96s\n",
      "730:\tlearn: 0.1486576\ttotal: 5.32s\tremaining: 1.96s\n",
      "731:\tlearn: 0.1485863\ttotal: 5.32s\tremaining: 1.95s\n",
      "732:\tlearn: 0.1485268\ttotal: 5.33s\tremaining: 1.94s\n",
      "733:\tlearn: 0.1484848\ttotal: 5.34s\tremaining: 1.93s\n",
      "734:\tlearn: 0.1484163\ttotal: 5.34s\tremaining: 1.93s\n",
      "735:\tlearn: 0.1481923\ttotal: 5.35s\tremaining: 1.92s\n",
      "736:\tlearn: 0.1480527\ttotal: 5.36s\tremaining: 1.91s\n",
      "737:\tlearn: 0.1478558\ttotal: 5.37s\tremaining: 1.91s\n",
      "738:\tlearn: 0.1476127\ttotal: 5.37s\tremaining: 1.9s\n",
      "739:\tlearn: 0.1474762\ttotal: 5.38s\tremaining: 1.89s\n",
      "740:\tlearn: 0.1473377\ttotal: 5.39s\tremaining: 1.88s\n",
      "741:\tlearn: 0.1473019\ttotal: 5.39s\tremaining: 1.88s\n",
      "742:\tlearn: 0.1471704\ttotal: 5.4s\tremaining: 1.87s\n",
      "743:\tlearn: 0.1471162\ttotal: 5.41s\tremaining: 1.86s\n",
      "744:\tlearn: 0.1470774\ttotal: 5.42s\tremaining: 1.85s\n",
      "745:\tlearn: 0.1468510\ttotal: 5.42s\tremaining: 1.85s\n",
      "746:\tlearn: 0.1466342\ttotal: 5.44s\tremaining: 1.84s\n",
      "747:\tlearn: 0.1464939\ttotal: 5.44s\tremaining: 1.83s\n",
      "748:\tlearn: 0.1462839\ttotal: 5.45s\tremaining: 1.83s\n",
      "749:\tlearn: 0.1460990\ttotal: 5.46s\tremaining: 1.82s\n",
      "750:\tlearn: 0.1458977\ttotal: 5.47s\tremaining: 1.81s\n",
      "751:\tlearn: 0.1457350\ttotal: 5.47s\tremaining: 1.8s\n",
      "752:\tlearn: 0.1453282\ttotal: 5.48s\tremaining: 1.8s\n",
      "753:\tlearn: 0.1451108\ttotal: 5.49s\tremaining: 1.79s\n",
      "754:\tlearn: 0.1449458\ttotal: 5.5s\tremaining: 1.78s\n",
      "755:\tlearn: 0.1447582\ttotal: 5.51s\tremaining: 1.78s\n",
      "756:\tlearn: 0.1447070\ttotal: 5.51s\tremaining: 1.77s\n",
      "757:\tlearn: 0.1445273\ttotal: 5.52s\tremaining: 1.76s\n",
      "758:\tlearn: 0.1443620\ttotal: 5.53s\tremaining: 1.76s\n",
      "759:\tlearn: 0.1443255\ttotal: 5.54s\tremaining: 1.75s\n",
      "760:\tlearn: 0.1442555\ttotal: 5.55s\tremaining: 1.74s\n",
      "761:\tlearn: 0.1441700\ttotal: 5.55s\tremaining: 1.73s\n",
      "762:\tlearn: 0.1441063\ttotal: 5.56s\tremaining: 1.73s\n",
      "763:\tlearn: 0.1439539\ttotal: 5.57s\tremaining: 1.72s\n",
      "764:\tlearn: 0.1437607\ttotal: 5.57s\tremaining: 1.71s\n",
      "765:\tlearn: 0.1436795\ttotal: 5.58s\tremaining: 1.7s\n",
      "766:\tlearn: 0.1435986\ttotal: 5.59s\tremaining: 1.7s\n",
      "767:\tlearn: 0.1434710\ttotal: 5.59s\tremaining: 1.69s\n",
      "768:\tlearn: 0.1434357\ttotal: 5.6s\tremaining: 1.68s\n",
      "769:\tlearn: 0.1430526\ttotal: 5.61s\tremaining: 1.67s\n",
      "770:\tlearn: 0.1428474\ttotal: 5.61s\tremaining: 1.67s\n",
      "771:\tlearn: 0.1427720\ttotal: 5.62s\tremaining: 1.66s\n",
      "772:\tlearn: 0.1427083\ttotal: 5.62s\tremaining: 1.65s\n",
      "773:\tlearn: 0.1426336\ttotal: 5.63s\tremaining: 1.64s\n",
      "774:\tlearn: 0.1425771\ttotal: 5.63s\tremaining: 1.64s\n",
      "775:\tlearn: 0.1425205\ttotal: 5.64s\tremaining: 1.63s\n",
      "776:\tlearn: 0.1422882\ttotal: 5.64s\tremaining: 1.62s\n",
      "777:\tlearn: 0.1421167\ttotal: 5.65s\tremaining: 1.61s\n",
      "778:\tlearn: 0.1420578\ttotal: 5.65s\tremaining: 1.6s\n",
      "779:\tlearn: 0.1418318\ttotal: 5.66s\tremaining: 1.59s\n",
      "780:\tlearn: 0.1417769\ttotal: 5.66s\tremaining: 1.59s\n",
      "781:\tlearn: 0.1417155\ttotal: 5.67s\tremaining: 1.58s\n",
      "782:\tlearn: 0.1414807\ttotal: 5.68s\tremaining: 1.57s\n",
      "783:\tlearn: 0.1413696\ttotal: 5.68s\tremaining: 1.57s\n",
      "784:\tlearn: 0.1411874\ttotal: 5.69s\tremaining: 1.56s\n",
      "785:\tlearn: 0.1411360\ttotal: 5.7s\tremaining: 1.55s\n",
      "786:\tlearn: 0.1410927\ttotal: 5.7s\tremaining: 1.54s\n",
      "787:\tlearn: 0.1408937\ttotal: 5.71s\tremaining: 1.53s\n",
      "788:\tlearn: 0.1405484\ttotal: 5.71s\tremaining: 1.53s\n",
      "789:\tlearn: 0.1403514\ttotal: 5.72s\tremaining: 1.52s\n",
      "790:\tlearn: 0.1402993\ttotal: 5.73s\tremaining: 1.51s\n",
      "791:\tlearn: 0.1402257\ttotal: 5.74s\tremaining: 1.51s\n",
      "792:\tlearn: 0.1401935\ttotal: 5.75s\tremaining: 1.5s\n",
      "793:\tlearn: 0.1400111\ttotal: 5.76s\tremaining: 1.49s\n",
      "794:\tlearn: 0.1397628\ttotal: 5.76s\tremaining: 1.49s\n",
      "795:\tlearn: 0.1394574\ttotal: 5.77s\tremaining: 1.48s\n",
      "796:\tlearn: 0.1393383\ttotal: 5.77s\tremaining: 1.47s\n",
      "797:\tlearn: 0.1391246\ttotal: 5.78s\tremaining: 1.46s\n",
      "798:\tlearn: 0.1389587\ttotal: 5.79s\tremaining: 1.46s\n",
      "799:\tlearn: 0.1388095\ttotal: 5.79s\tremaining: 1.45s\n",
      "800:\tlearn: 0.1386863\ttotal: 5.8s\tremaining: 1.44s\n",
      "801:\tlearn: 0.1386470\ttotal: 5.81s\tremaining: 1.43s\n",
      "802:\tlearn: 0.1385063\ttotal: 5.81s\tremaining: 1.43s\n",
      "803:\tlearn: 0.1384925\ttotal: 5.82s\tremaining: 1.42s\n",
      "804:\tlearn: 0.1383946\ttotal: 5.83s\tremaining: 1.41s\n",
      "805:\tlearn: 0.1382160\ttotal: 5.84s\tremaining: 1.4s\n",
      "806:\tlearn: 0.1381605\ttotal: 5.84s\tremaining: 1.4s\n",
      "807:\tlearn: 0.1380144\ttotal: 5.85s\tremaining: 1.39s\n",
      "808:\tlearn: 0.1378372\ttotal: 5.86s\tremaining: 1.38s\n",
      "809:\tlearn: 0.1376629\ttotal: 5.86s\tremaining: 1.38s\n",
      "810:\tlearn: 0.1376109\ttotal: 5.87s\tremaining: 1.37s\n",
      "811:\tlearn: 0.1374062\ttotal: 5.88s\tremaining: 1.36s\n",
      "812:\tlearn: 0.1372826\ttotal: 5.88s\tremaining: 1.35s\n",
      "813:\tlearn: 0.1372490\ttotal: 5.89s\tremaining: 1.35s\n",
      "814:\tlearn: 0.1370548\ttotal: 5.9s\tremaining: 1.34s\n",
      "815:\tlearn: 0.1370239\ttotal: 5.91s\tremaining: 1.33s\n",
      "816:\tlearn: 0.1369752\ttotal: 5.92s\tremaining: 1.32s\n",
      "817:\tlearn: 0.1367122\ttotal: 5.92s\tremaining: 1.32s\n",
      "818:\tlearn: 0.1365040\ttotal: 5.93s\tremaining: 1.31s\n",
      "819:\tlearn: 0.1361769\ttotal: 5.94s\tremaining: 1.3s\n",
      "820:\tlearn: 0.1359164\ttotal: 5.95s\tremaining: 1.3s\n",
      "821:\tlearn: 0.1358182\ttotal: 5.95s\tremaining: 1.29s\n",
      "822:\tlearn: 0.1356556\ttotal: 5.96s\tremaining: 1.28s\n",
      "823:\tlearn: 0.1354549\ttotal: 5.96s\tremaining: 1.27s\n",
      "824:\tlearn: 0.1352750\ttotal: 5.97s\tremaining: 1.27s\n",
      "825:\tlearn: 0.1350912\ttotal: 5.97s\tremaining: 1.26s\n",
      "826:\tlearn: 0.1349016\ttotal: 5.98s\tremaining: 1.25s\n",
      "827:\tlearn: 0.1347404\ttotal: 5.99s\tremaining: 1.24s\n",
      "828:\tlearn: 0.1347034\ttotal: 6s\tremaining: 1.24s\n",
      "829:\tlearn: 0.1344864\ttotal: 6s\tremaining: 1.23s\n",
      "830:\tlearn: 0.1343375\ttotal: 6.01s\tremaining: 1.22s\n",
      "831:\tlearn: 0.1342743\ttotal: 6.02s\tremaining: 1.22s\n",
      "832:\tlearn: 0.1341576\ttotal: 6.03s\tremaining: 1.21s\n",
      "833:\tlearn: 0.1340655\ttotal: 6.04s\tremaining: 1.2s\n",
      "834:\tlearn: 0.1339313\ttotal: 6.04s\tremaining: 1.19s\n",
      "835:\tlearn: 0.1338814\ttotal: 6.05s\tremaining: 1.19s\n",
      "836:\tlearn: 0.1338412\ttotal: 6.06s\tremaining: 1.18s\n",
      "837:\tlearn: 0.1337949\ttotal: 6.07s\tremaining: 1.17s\n",
      "838:\tlearn: 0.1337429\ttotal: 6.08s\tremaining: 1.17s\n",
      "839:\tlearn: 0.1335991\ttotal: 6.09s\tremaining: 1.16s\n",
      "840:\tlearn: 0.1335320\ttotal: 6.09s\tremaining: 1.15s\n",
      "841:\tlearn: 0.1333990\ttotal: 6.1s\tremaining: 1.15s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "842:\tlearn: 0.1331218\ttotal: 6.11s\tremaining: 1.14s\n",
      "843:\tlearn: 0.1330541\ttotal: 6.12s\tremaining: 1.13s\n",
      "844:\tlearn: 0.1327228\ttotal: 6.12s\tremaining: 1.12s\n",
      "845:\tlearn: 0.1325996\ttotal: 6.13s\tremaining: 1.12s\n",
      "846:\tlearn: 0.1324440\ttotal: 6.14s\tremaining: 1.11s\n",
      "847:\tlearn: 0.1322306\ttotal: 6.15s\tremaining: 1.1s\n",
      "848:\tlearn: 0.1320845\ttotal: 6.15s\tremaining: 1.09s\n",
      "849:\tlearn: 0.1319614\ttotal: 6.17s\tremaining: 1.09s\n",
      "850:\tlearn: 0.1318586\ttotal: 6.17s\tremaining: 1.08s\n",
      "851:\tlearn: 0.1316085\ttotal: 6.18s\tremaining: 1.07s\n",
      "852:\tlearn: 0.1314392\ttotal: 6.19s\tremaining: 1.07s\n",
      "853:\tlearn: 0.1312692\ttotal: 6.2s\tremaining: 1.06s\n",
      "854:\tlearn: 0.1311027\ttotal: 6.21s\tremaining: 1.05s\n",
      "855:\tlearn: 0.1309931\ttotal: 6.22s\tremaining: 1.04s\n",
      "856:\tlearn: 0.1308696\ttotal: 6.22s\tremaining: 1.04s\n",
      "857:\tlearn: 0.1307465\ttotal: 6.23s\tremaining: 1.03s\n",
      "858:\tlearn: 0.1306015\ttotal: 6.24s\tremaining: 1.02s\n",
      "859:\tlearn: 0.1305644\ttotal: 6.25s\tremaining: 1.02s\n",
      "860:\tlearn: 0.1304414\ttotal: 6.25s\tremaining: 1.01s\n",
      "861:\tlearn: 0.1302773\ttotal: 6.26s\tremaining: 1s\n",
      "862:\tlearn: 0.1302207\ttotal: 6.28s\tremaining: 996ms\n",
      "863:\tlearn: 0.1300263\ttotal: 6.28s\tremaining: 989ms\n",
      "864:\tlearn: 0.1299433\ttotal: 6.29s\tremaining: 982ms\n",
      "865:\tlearn: 0.1297216\ttotal: 6.29s\tremaining: 974ms\n",
      "866:\tlearn: 0.1296224\ttotal: 6.3s\tremaining: 967ms\n",
      "867:\tlearn: 0.1295739\ttotal: 6.31s\tremaining: 960ms\n",
      "868:\tlearn: 0.1294383\ttotal: 6.32s\tremaining: 953ms\n",
      "869:\tlearn: 0.1293732\ttotal: 6.33s\tremaining: 946ms\n",
      "870:\tlearn: 0.1292845\ttotal: 6.34s\tremaining: 939ms\n",
      "871:\tlearn: 0.1292410\ttotal: 6.34s\tremaining: 932ms\n",
      "872:\tlearn: 0.1291082\ttotal: 6.35s\tremaining: 924ms\n",
      "873:\tlearn: 0.1289655\ttotal: 6.36s\tremaining: 917ms\n",
      "874:\tlearn: 0.1288495\ttotal: 6.37s\tremaining: 911ms\n",
      "875:\tlearn: 0.1286329\ttotal: 6.38s\tremaining: 904ms\n",
      "876:\tlearn: 0.1284434\ttotal: 6.4s\tremaining: 897ms\n",
      "877:\tlearn: 0.1282966\ttotal: 6.42s\tremaining: 893ms\n",
      "878:\tlearn: 0.1279383\ttotal: 6.43s\tremaining: 885ms\n",
      "879:\tlearn: 0.1277150\ttotal: 6.44s\tremaining: 878ms\n",
      "880:\tlearn: 0.1275556\ttotal: 6.45s\tremaining: 871ms\n",
      "881:\tlearn: 0.1273416\ttotal: 6.46s\tremaining: 865ms\n",
      "882:\tlearn: 0.1272168\ttotal: 6.47s\tremaining: 858ms\n",
      "883:\tlearn: 0.1271105\ttotal: 6.48s\tremaining: 850ms\n",
      "884:\tlearn: 0.1269808\ttotal: 6.49s\tremaining: 843ms\n",
      "885:\tlearn: 0.1269361\ttotal: 6.49s\tremaining: 835ms\n",
      "886:\tlearn: 0.1269188\ttotal: 6.5s\tremaining: 828ms\n",
      "887:\tlearn: 0.1268162\ttotal: 6.51s\tremaining: 821ms\n",
      "888:\tlearn: 0.1267438\ttotal: 6.51s\tremaining: 813ms\n",
      "889:\tlearn: 0.1266908\ttotal: 6.52s\tremaining: 806ms\n",
      "890:\tlearn: 0.1265717\ttotal: 6.53s\tremaining: 799ms\n",
      "891:\tlearn: 0.1265070\ttotal: 6.53s\tremaining: 791ms\n",
      "892:\tlearn: 0.1263879\ttotal: 6.54s\tremaining: 784ms\n",
      "893:\tlearn: 0.1263220\ttotal: 6.55s\tremaining: 776ms\n",
      "894:\tlearn: 0.1261807\ttotal: 6.55s\tremaining: 769ms\n",
      "895:\tlearn: 0.1260467\ttotal: 6.56s\tremaining: 761ms\n",
      "896:\tlearn: 0.1259181\ttotal: 6.57s\tremaining: 754ms\n",
      "897:\tlearn: 0.1257329\ttotal: 6.57s\tremaining: 747ms\n",
      "898:\tlearn: 0.1256793\ttotal: 6.58s\tremaining: 739ms\n",
      "899:\tlearn: 0.1256385\ttotal: 6.59s\tremaining: 732ms\n",
      "900:\tlearn: 0.1255828\ttotal: 6.59s\tremaining: 724ms\n",
      "901:\tlearn: 0.1254697\ttotal: 6.6s\tremaining: 717ms\n",
      "902:\tlearn: 0.1254084\ttotal: 6.61s\tremaining: 710ms\n",
      "903:\tlearn: 0.1251002\ttotal: 6.62s\tremaining: 703ms\n",
      "904:\tlearn: 0.1249251\ttotal: 6.62s\tremaining: 695ms\n",
      "905:\tlearn: 0.1247786\ttotal: 6.63s\tremaining: 688ms\n",
      "906:\tlearn: 0.1245533\ttotal: 6.64s\tremaining: 681ms\n",
      "907:\tlearn: 0.1245120\ttotal: 6.65s\tremaining: 674ms\n",
      "908:\tlearn: 0.1244553\ttotal: 6.65s\tremaining: 666ms\n",
      "909:\tlearn: 0.1243069\ttotal: 6.66s\tremaining: 659ms\n",
      "910:\tlearn: 0.1241550\ttotal: 6.67s\tremaining: 651ms\n",
      "911:\tlearn: 0.1239764\ttotal: 6.68s\tremaining: 644ms\n",
      "912:\tlearn: 0.1238890\ttotal: 6.68s\tremaining: 637ms\n",
      "913:\tlearn: 0.1237834\ttotal: 6.69s\tremaining: 630ms\n",
      "914:\tlearn: 0.1236413\ttotal: 6.7s\tremaining: 622ms\n",
      "915:\tlearn: 0.1235098\ttotal: 6.7s\tremaining: 615ms\n",
      "916:\tlearn: 0.1234431\ttotal: 6.71s\tremaining: 607ms\n",
      "917:\tlearn: 0.1233385\ttotal: 6.72s\tremaining: 600ms\n",
      "918:\tlearn: 0.1232215\ttotal: 6.72s\tremaining: 593ms\n",
      "919:\tlearn: 0.1230659\ttotal: 6.73s\tremaining: 585ms\n",
      "920:\tlearn: 0.1229311\ttotal: 6.74s\tremaining: 578ms\n",
      "921:\tlearn: 0.1227986\ttotal: 6.74s\tremaining: 571ms\n",
      "922:\tlearn: 0.1226562\ttotal: 6.75s\tremaining: 563ms\n",
      "923:\tlearn: 0.1226076\ttotal: 6.76s\tremaining: 556ms\n",
      "924:\tlearn: 0.1223979\ttotal: 6.77s\tremaining: 549ms\n",
      "925:\tlearn: 0.1222270\ttotal: 6.78s\tremaining: 542ms\n",
      "926:\tlearn: 0.1220352\ttotal: 6.78s\tremaining: 534ms\n",
      "927:\tlearn: 0.1219267\ttotal: 6.79s\tremaining: 527ms\n",
      "928:\tlearn: 0.1218222\ttotal: 6.8s\tremaining: 520ms\n",
      "929:\tlearn: 0.1216964\ttotal: 6.8s\tremaining: 512ms\n",
      "930:\tlearn: 0.1213973\ttotal: 6.81s\tremaining: 505ms\n",
      "931:\tlearn: 0.1212583\ttotal: 6.82s\tremaining: 498ms\n",
      "932:\tlearn: 0.1210623\ttotal: 6.83s\tremaining: 490ms\n",
      "933:\tlearn: 0.1208012\ttotal: 6.83s\tremaining: 483ms\n",
      "934:\tlearn: 0.1207051\ttotal: 6.84s\tremaining: 475ms\n",
      "935:\tlearn: 0.1205626\ttotal: 6.84s\tremaining: 468ms\n",
      "936:\tlearn: 0.1205355\ttotal: 6.85s\tremaining: 461ms\n",
      "937:\tlearn: 0.1204048\ttotal: 6.86s\tremaining: 453ms\n",
      "938:\tlearn: 0.1203123\ttotal: 6.86s\tremaining: 446ms\n",
      "939:\tlearn: 0.1201951\ttotal: 6.87s\tremaining: 439ms\n",
      "940:\tlearn: 0.1200128\ttotal: 6.88s\tremaining: 431ms\n",
      "941:\tlearn: 0.1198591\ttotal: 6.88s\tremaining: 424ms\n",
      "942:\tlearn: 0.1197406\ttotal: 6.89s\tremaining: 417ms\n",
      "943:\tlearn: 0.1196440\ttotal: 6.9s\tremaining: 409ms\n",
      "944:\tlearn: 0.1193754\ttotal: 6.9s\tremaining: 402ms\n",
      "945:\tlearn: 0.1192737\ttotal: 6.91s\tremaining: 394ms\n",
      "946:\tlearn: 0.1190997\ttotal: 6.92s\tremaining: 387ms\n",
      "947:\tlearn: 0.1189743\ttotal: 6.93s\tremaining: 380ms\n",
      "948:\tlearn: 0.1188229\ttotal: 6.94s\tremaining: 373ms\n",
      "949:\tlearn: 0.1187761\ttotal: 6.96s\tremaining: 366ms\n",
      "950:\tlearn: 0.1186529\ttotal: 6.96s\tremaining: 359ms\n",
      "951:\tlearn: 0.1184079\ttotal: 6.97s\tremaining: 351ms\n",
      "952:\tlearn: 0.1180994\ttotal: 6.98s\tremaining: 344ms\n",
      "953:\tlearn: 0.1180072\ttotal: 6.98s\tremaining: 337ms\n",
      "954:\tlearn: 0.1178999\ttotal: 6.99s\tremaining: 330ms\n",
      "955:\tlearn: 0.1178164\ttotal: 7s\tremaining: 322ms\n",
      "956:\tlearn: 0.1177190\ttotal: 7s\tremaining: 315ms\n",
      "957:\tlearn: 0.1175956\ttotal: 7.01s\tremaining: 307ms\n",
      "958:\tlearn: 0.1173960\ttotal: 7.02s\tremaining: 300ms\n",
      "959:\tlearn: 0.1171555\ttotal: 7.02s\tremaining: 293ms\n",
      "960:\tlearn: 0.1170824\ttotal: 7.03s\tremaining: 285ms\n",
      "961:\tlearn: 0.1170427\ttotal: 7.04s\tremaining: 278ms\n",
      "962:\tlearn: 0.1169317\ttotal: 7.05s\tremaining: 271ms\n",
      "963:\tlearn: 0.1168872\ttotal: 7.06s\tremaining: 264ms\n",
      "964:\tlearn: 0.1167672\ttotal: 7.06s\tremaining: 256ms\n",
      "965:\tlearn: 0.1166671\ttotal: 7.07s\tremaining: 249ms\n",
      "966:\tlearn: 0.1165760\ttotal: 7.09s\tremaining: 242ms\n",
      "967:\tlearn: 0.1164481\ttotal: 7.09s\tremaining: 235ms\n",
      "968:\tlearn: 0.1163203\ttotal: 7.1s\tremaining: 227ms\n",
      "969:\tlearn: 0.1162679\ttotal: 7.11s\tremaining: 220ms\n",
      "970:\tlearn: 0.1162219\ttotal: 7.12s\tremaining: 213ms\n",
      "971:\tlearn: 0.1160858\ttotal: 7.12s\tremaining: 205ms\n",
      "972:\tlearn: 0.1159892\ttotal: 7.13s\tremaining: 198ms\n",
      "973:\tlearn: 0.1157758\ttotal: 7.13s\tremaining: 190ms\n",
      "974:\tlearn: 0.1156437\ttotal: 7.14s\tremaining: 183ms\n",
      "975:\tlearn: 0.1155324\ttotal: 7.15s\tremaining: 176ms\n",
      "976:\tlearn: 0.1154896\ttotal: 7.17s\tremaining: 169ms\n",
      "977:\tlearn: 0.1153997\ttotal: 7.17s\tremaining: 161ms\n",
      "978:\tlearn: 0.1153852\ttotal: 7.18s\tremaining: 154ms\n",
      "979:\tlearn: 0.1153583\ttotal: 7.19s\tremaining: 147ms\n",
      "980:\tlearn: 0.1153445\ttotal: 7.2s\tremaining: 139ms\n",
      "981:\tlearn: 0.1153312\ttotal: 7.2s\tremaining: 132ms\n",
      "982:\tlearn: 0.1153059\ttotal: 7.21s\tremaining: 125ms\n",
      "983:\tlearn: 0.1152602\ttotal: 7.22s\tremaining: 117ms\n",
      "984:\tlearn: 0.1152322\ttotal: 7.23s\tremaining: 110ms\n",
      "985:\tlearn: 0.1152212\ttotal: 7.24s\tremaining: 103ms\n",
      "986:\tlearn: 0.1150222\ttotal: 7.25s\tremaining: 95.5ms\n",
      "987:\tlearn: 0.1149101\ttotal: 7.26s\tremaining: 88.2ms\n",
      "988:\tlearn: 0.1148978\ttotal: 7.27s\tremaining: 80.8ms\n",
      "989:\tlearn: 0.1148722\ttotal: 7.28s\tremaining: 73.5ms\n",
      "990:\tlearn: 0.1148513\ttotal: 7.28s\tremaining: 66.2ms\n",
      "991:\tlearn: 0.1147366\ttotal: 7.29s\tremaining: 58.8ms\n",
      "992:\tlearn: 0.1147227\ttotal: 7.3s\tremaining: 51.4ms\n",
      "993:\tlearn: 0.1146336\ttotal: 7.3s\tremaining: 44.1ms\n",
      "994:\tlearn: 0.1146238\ttotal: 7.31s\tremaining: 36.7ms\n",
      "995:\tlearn: 0.1146044\ttotal: 7.32s\tremaining: 29.4ms\n",
      "996:\tlearn: 0.1145684\ttotal: 7.33s\tremaining: 22ms\n",
      "997:\tlearn: 0.1145549\ttotal: 7.33s\tremaining: 14.7ms\n",
      "998:\tlearn: 0.1145369\ttotal: 7.34s\tremaining: 7.35ms\n",
      "999:\tlearn: 0.1145275\ttotal: 7.35s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "              importance_type='split', learning_rate=0.1, max_depth=-1,\n",
       "              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
       "              random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "              subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_std, y_train)\n",
    "cat.fit(X_std, y_train)\n",
    "lgt.fit(X_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_test = rf.predict(std.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_test = cat.predict(std.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgt_test = lgt.predict(std.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring(y_actual, y_predicted):\n",
    "    rmse = sqrt(mean_squared_error(y_actual, y_predicted))\n",
    "    score = 100*max(0, 1-rmse)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75.83270486590388"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoring(y_test, rf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85.41962384713237"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoring(y_test, cat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80.3611667627222"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoring(y_test, lgt_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = cat.predict(test[['enc_nod', 'enc_ucd', 'effectiveness_rating', 'number_of_times_prescribed']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['base_score'] = test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[['patient_id', 'base_score']].to_csv('pred_cat_boost_std.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from torch.autograd import Variable\n",
    "# import torch.nn.functional as F\n",
    "# import torch.utils.data as Data\n",
    "# import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Net(torch.nn.Module):\n",
    "#     def __init__(self, n_feature, n_hidden, n_output):\n",
    "#         super(Net, self).__init__()\n",
    "#         self.hidden = torch.nn.Linear(n_feature, n_hidden)   # hidden layer\n",
    "#         self.predict = torch.nn.Linear(n_hidden, n_output)   # output layer\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = F.relu(self.hidden(x))      # activation function for hidden layer\n",
    "#         x = self.predict(x)             # linear output\n",
    "#         return x\n",
    "\n",
    "# net = Net(n_feature=4, n_hidden=10, n_output=1)     # define the network\n",
    "# # print(net)  # net architecture\n",
    "# optimizer = torch.optim.SGD(net.parameters(), lr=0.05)\n",
    "# loss_func = torch.nn.MSELoss()  # this is for regression mean squared loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(train[['enc_nod', 'enc_ucd', 'effectiveness_rating', 'number_of_times_prescribed']])\n",
    "y = np.array(train['base_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x =  Variable(torch.from_numpy(x))\n",
    "y =  Variable(torch.tensor(target, dtype=torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the network\n",
    "for t in tqdm_notebook(range(200)):\n",
    "  \n",
    "    prediction = net(x.float())     # input x and predict based on x\n",
    "\n",
    "    loss = loss_func(prediction, y)     # must be (1. nn output, 2. target)\n",
    "\n",
    "    optimizer.zero_grad()   # clear gradients for next train\n",
    "    loss.backward()         # backpropagation, compute gradients\n",
    "    optimizer.step()        # apply gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(train[['enc_nod', 'enc_ucd', 'effectiveness_rating', 'number_of_times_prescribed']])\n",
    "y = np.array(train['base_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define base model\n",
    "def baseline_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(4, input_dim=4, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "28948/28948 [==============================] - 1s 20us/step - loss: 11.7419\n",
      "Epoch 2/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 7.0948\n",
      "Epoch 3/100\n",
      "28948/28948 [==============================] - 0s 15us/step - loss: 4.5955\n",
      "Epoch 4/100\n",
      "28948/28948 [==============================] - 0s 15us/step - loss: 3.4176\n",
      "Epoch 5/100\n",
      "28948/28948 [==============================] - 0s 15us/step - loss: 3.1078\n",
      "Epoch 6/100\n",
      "28948/28948 [==============================] - 0s 15us/step - loss: 2.9636\n",
      "Epoch 7/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.8509\n",
      "Epoch 8/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.7391\n",
      "Epoch 9/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.6397\n",
      "Epoch 10/100\n",
      "28948/28948 [==============================] - 0s 15us/step - loss: 2.5565\n",
      "Epoch 11/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.4790\n",
      "Epoch 12/100\n",
      "28948/28948 [==============================] - 1s 24us/step - loss: 2.4026\n",
      "Epoch 13/100\n",
      "28948/28948 [==============================] - 1s 19us/step - loss: 2.3428\n",
      "Epoch 14/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.2941\n",
      "Epoch 15/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.2541\n",
      "Epoch 16/100\n",
      "28948/28948 [==============================] - 1s 19us/step - loss: 2.2110\n",
      "Epoch 17/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.2004\n",
      "Epoch 18/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1818\n",
      "Epoch 19/100\n",
      "28948/28948 [==============================] - 1s 19us/step - loss: 2.1873\n",
      "Epoch 20/100\n",
      "28948/28948 [==============================] - 1s 19us/step - loss: 2.1621\n",
      "Epoch 21/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1496\n",
      "Epoch 22/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1632\n",
      "Epoch 23/100\n",
      "28948/28948 [==============================] - 1s 23us/step - loss: 2.1472\n",
      "Epoch 24/100\n",
      "28948/28948 [==============================] - 1s 24us/step - loss: 2.1484\n",
      "Epoch 25/100\n",
      "28948/28948 [==============================] - 1s 19us/step - loss: 2.1552\n",
      "Epoch 26/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1478\n",
      "Epoch 27/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1458\n",
      "Epoch 28/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1440\n",
      "Epoch 29/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1347\n",
      "Epoch 30/100\n",
      "28948/28948 [==============================] - 1s 18us/step - loss: 2.1663\n",
      "Epoch 31/100\n",
      "28948/28948 [==============================] - 1s 18us/step - loss: 2.1325\n",
      "Epoch 32/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1280\n",
      "Epoch 33/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1416\n",
      "Epoch 34/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1351\n",
      "Epoch 35/100\n",
      "28948/28948 [==============================] - 0s 15us/step - loss: 2.1379\n",
      "Epoch 36/100\n",
      "28948/28948 [==============================] - 1s 19us/step - loss: 2.1417\n",
      "Epoch 37/100\n",
      "28948/28948 [==============================] - 1s 19us/step - loss: 2.1296\n",
      "Epoch 38/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1302\n",
      "Epoch 39/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1305\n",
      "Epoch 40/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1395\n",
      "Epoch 41/100\n",
      "28948/28948 [==============================] - 1s 19us/step - loss: 2.1313\n",
      "Epoch 42/100\n",
      "28948/28948 [==============================] - 1s 18us/step - loss: 2.1305\n",
      "Epoch 43/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1309\n",
      "Epoch 44/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1245\n",
      "Epoch 45/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1213\n",
      "Epoch 46/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1238\n",
      "Epoch 47/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1344\n",
      "Epoch 48/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1241\n",
      "Epoch 49/100\n",
      "28948/28948 [==============================] - 1s 19us/step - loss: 2.1269\n",
      "Epoch 50/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1268\n",
      "Epoch 51/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1278\n",
      "Epoch 52/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1247\n",
      "Epoch 53/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1230\n",
      "Epoch 54/100\n",
      "28948/28948 [==============================] - 1s 17us/step - loss: 2.1214\n",
      "Epoch 55/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1262\n",
      "Epoch 56/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1337\n",
      "Epoch 57/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1254\n",
      "Epoch 58/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1310\n",
      "Epoch 59/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1271\n",
      "Epoch 60/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1239\n",
      "Epoch 61/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1129\n",
      "Epoch 62/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1288\n",
      "Epoch 63/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1231\n",
      "Epoch 64/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1243\n",
      "Epoch 65/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1180\n",
      "Epoch 66/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1123\n",
      "Epoch 67/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1207\n",
      "Epoch 68/100\n",
      "28948/28948 [==============================] - 1s 19us/step - loss: 2.1182\n",
      "Epoch 69/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1141\n",
      "Epoch 70/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1161\n",
      "Epoch 71/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1195\n",
      "Epoch 72/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1157\n",
      "Epoch 73/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1152\n",
      "Epoch 74/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1201\n",
      "Epoch 75/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1182\n",
      "Epoch 76/100\n",
      "28948/28948 [==============================] - 1s 17us/step - loss: 2.1151\n",
      "Epoch 77/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1172\n",
      "Epoch 78/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1191\n",
      "Epoch 79/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1177\n",
      "Epoch 80/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1187\n",
      "Epoch 81/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1130\n",
      "Epoch 82/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1198\n",
      "Epoch 83/100\n",
      "28948/28948 [==============================] - 1s 17us/step - loss: 2.1182\n",
      "Epoch 84/100\n",
      "28948/28948 [==============================] - 1s 18us/step - loss: 2.1193\n",
      "Epoch 85/100\n",
      "28948/28948 [==============================] - 1s 17us/step - loss: 2.1152\n",
      "Epoch 86/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1173\n",
      "Epoch 87/100\n",
      "28948/28948 [==============================] - 1s 20us/step - loss: 2.1154\n",
      "Epoch 88/100\n",
      "28948/28948 [==============================] - 1s 22us/step - loss: 2.1107\n",
      "Epoch 89/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1137\n",
      "Epoch 90/100\n",
      "28948/28948 [==============================] - 1s 18us/step - loss: 2.1217\n",
      "Epoch 91/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1116\n",
      "Epoch 92/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1120\n",
      "Epoch 93/100\n",
      "28948/28948 [==============================] - 1s 18us/step - loss: 2.1149\n",
      "Epoch 94/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1085\n",
      "Epoch 95/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1111\n",
      "Epoch 96/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1125\n",
      "Epoch 97/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1092\n",
      "Epoch 98/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1120\n",
      "Epoch 99/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1119\n",
      "Epoch 100/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1106\n",
      "3217/3217 [==============================] - 0s 26us/step\n",
      "Epoch 1/100\n",
      "28948/28948 [==============================] - 1s 22us/step - loss: 8.5631\n",
      "Epoch 2/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 5.4735\n",
      "Epoch 3/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 3.4963\n",
      "Epoch 4/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 3.0684\n",
      "Epoch 5/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.9312\n",
      "Epoch 6/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.8202\n",
      "Epoch 7/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.7069\n",
      "Epoch 8/100\n",
      "28948/28948 [==============================] - 1s 18us/step - loss: 2.6074\n",
      "Epoch 9/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.5298\n",
      "Epoch 10/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.4405\n",
      "Epoch 11/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.3817\n",
      "Epoch 12/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.3425\n",
      "Epoch 13/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.2842\n",
      "Epoch 14/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.2506\n",
      "Epoch 15/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.2246\n",
      "Epoch 16/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.2231\n",
      "Epoch 17/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1918\n",
      "Epoch 18/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1797\n",
      "Epoch 19/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1728\n",
      "Epoch 20/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1876\n",
      "Epoch 21/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1659\n",
      "Epoch 22/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1645\n",
      "Epoch 23/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1815\n",
      "Epoch 24/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1462\n",
      "Epoch 25/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1453\n",
      "Epoch 26/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1464\n",
      "Epoch 27/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1588\n",
      "Epoch 28/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1635\n",
      "Epoch 29/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1552\n",
      "Epoch 30/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1521\n",
      "Epoch 31/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1619\n",
      "Epoch 32/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1508\n",
      "Epoch 33/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1475\n",
      "Epoch 34/100\n",
      "28948/28948 [==============================] - 1s 22us/step - loss: 2.1478\n",
      "Epoch 35/100\n",
      "28948/28948 [==============================] - 1s 22us/step - loss: 2.1427\n",
      "Epoch 36/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1445\n",
      "Epoch 37/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1503\n",
      "Epoch 38/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1448\n",
      "Epoch 39/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1529\n",
      "Epoch 40/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1328\n",
      "Epoch 41/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1565\n",
      "Epoch 42/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1358\n",
      "Epoch 43/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1447\n",
      "Epoch 44/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1461\n",
      "Epoch 45/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1320\n",
      "Epoch 46/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1378\n",
      "Epoch 47/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1356\n",
      "Epoch 48/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1359\n",
      "Epoch 49/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1263\n",
      "Epoch 50/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1307\n",
      "Epoch 51/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1419\n",
      "Epoch 52/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1292\n",
      "Epoch 53/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1293\n",
      "Epoch 54/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1201\n",
      "Epoch 55/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1337\n",
      "Epoch 56/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1302\n",
      "Epoch 57/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1327\n",
      "Epoch 58/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1273\n",
      "Epoch 59/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1201\n",
      "Epoch 60/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1286\n",
      "Epoch 61/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1236\n",
      "Epoch 62/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1218\n",
      "Epoch 63/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1257\n",
      "Epoch 64/100\n",
      "28948/28948 [==============================] - 1s 17us/step - loss: 2.1193\n",
      "Epoch 65/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1193\n",
      "Epoch 66/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1292\n",
      "Epoch 67/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1137\n",
      "Epoch 68/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1263\n",
      "Epoch 69/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1165\n",
      "Epoch 70/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1184\n",
      "Epoch 71/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1201\n",
      "Epoch 72/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1142\n",
      "Epoch 73/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1151\n",
      "Epoch 74/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1133\n",
      "Epoch 75/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1178\n",
      "Epoch 76/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1201\n",
      "Epoch 77/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1224\n",
      "Epoch 78/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1164\n",
      "Epoch 79/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1183\n",
      "Epoch 80/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1176\n",
      "Epoch 81/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1138\n",
      "Epoch 82/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1151\n",
      "Epoch 83/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1167\n",
      "Epoch 84/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1101\n",
      "Epoch 85/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1120\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1114\n",
      "Epoch 87/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1139\n",
      "Epoch 88/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1112\n",
      "Epoch 89/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1138\n",
      "Epoch 90/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1120\n",
      "Epoch 91/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1110\n",
      "Epoch 92/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1092\n",
      "Epoch 93/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1120\n",
      "Epoch 94/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1152\n",
      "Epoch 95/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1111\n",
      "Epoch 96/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1093\n",
      "Epoch 97/100\n",
      "28948/28948 [==============================] - 1s 23us/step - loss: 2.1219\n",
      "Epoch 98/100\n",
      "28948/28948 [==============================] - 1s 24us/step - loss: 2.1087\n",
      "Epoch 99/100\n",
      "28948/28948 [==============================] - 1s 21us/step - loss: 2.1093\n",
      "Epoch 100/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1122\n",
      "3217/3217 [==============================] - 0s 27us/step\n",
      "Epoch 1/100\n",
      "28948/28948 [==============================] - 1s 24us/step - loss: 8.4630\n",
      "Epoch 2/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 4.9589\n",
      "Epoch 3/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 3.7191\n",
      "Epoch 4/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 3.3366\n",
      "Epoch 5/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 3.0950\n",
      "Epoch 6/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.8561\n",
      "Epoch 7/100\n",
      "28948/28948 [==============================] - 1s 21us/step - loss: 2.6970\n",
      "Epoch 8/100\n",
      "28948/28948 [==============================] - 1s 20us/step - loss: 2.5552\n",
      "Epoch 9/100\n",
      "28948/28948 [==============================] - 1s 17us/step - loss: 2.4340\n",
      "Epoch 10/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.3679\n",
      "Epoch 11/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.2807\n",
      "Epoch 12/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.2458\n",
      "Epoch 13/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.2142\n",
      "Epoch 14/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1972\n",
      "Epoch 15/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1801\n",
      "Epoch 16/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1842\n",
      "Epoch 17/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1785\n",
      "Epoch 18/100\n",
      "28948/28948 [==============================] - 1s 18us/step - loss: 2.1675\n",
      "Epoch 19/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1550\n",
      "Epoch 20/100\n",
      "28948/28948 [==============================] - 1s 18us/step - loss: 2.1718\n",
      "Epoch 21/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1517\n",
      "Epoch 22/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1965\n",
      "Epoch 23/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1529\n",
      "Epoch 24/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1535\n",
      "Epoch 25/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1747\n",
      "Epoch 26/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1576\n",
      "Epoch 27/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1456\n",
      "Epoch 28/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1411\n",
      "Epoch 29/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1672\n",
      "Epoch 30/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1633\n",
      "Epoch 31/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1643\n",
      "Epoch 32/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1641\n",
      "Epoch 33/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1377\n",
      "Epoch 34/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1398\n",
      "Epoch 35/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1314\n",
      "Epoch 36/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1409\n",
      "Epoch 37/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1542\n",
      "Epoch 38/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1314\n",
      "Epoch 39/100\n",
      "28948/28948 [==============================] - 1s 17us/step - loss: 2.1377\n",
      "Epoch 40/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1374\n",
      "Epoch 41/100\n",
      "28948/28948 [==============================] - 1s 18us/step - loss: 2.1685\n",
      "Epoch 42/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1456\n",
      "Epoch 43/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1359\n",
      "Epoch 44/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1170\n",
      "Epoch 45/100\n",
      "28948/28948 [==============================] - 1s 21us/step - loss: 2.1378\n",
      "Epoch 46/100\n",
      "28948/28948 [==============================] - 1s 20us/step - loss: 2.1474\n",
      "Epoch 47/100\n",
      "28948/28948 [==============================] - 1s 19us/step - loss: 2.1262\n",
      "Epoch 48/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1289\n",
      "Epoch 49/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1452\n",
      "Epoch 50/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1229\n",
      "Epoch 51/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1326\n",
      "Epoch 52/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1319\n",
      "Epoch 53/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1454\n",
      "Epoch 54/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1336\n",
      "Epoch 55/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1325\n",
      "Epoch 56/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1260\n",
      "Epoch 57/100\n",
      "28948/28948 [==============================] - 1s 19us/step - loss: 2.1268\n",
      "Epoch 58/100\n",
      "28948/28948 [==============================] - 1s 25us/step - loss: 2.1247\n",
      "Epoch 59/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1240\n",
      "Epoch 60/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1184\n",
      "Epoch 61/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1237\n",
      "Epoch 62/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1246\n",
      "Epoch 63/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1274\n",
      "Epoch 64/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1105\n",
      "Epoch 65/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1146\n",
      "Epoch 66/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1082\n",
      "Epoch 67/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1086\n",
      "Epoch 68/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1162\n",
      "Epoch 69/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1081\n",
      "Epoch 70/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1047\n",
      "Epoch 71/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1087\n",
      "Epoch 72/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1088\n",
      "Epoch 73/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1208\n",
      "Epoch 74/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1064\n",
      "Epoch 75/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1051\n",
      "Epoch 76/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1085\n",
      "Epoch 77/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1035\n",
      "Epoch 78/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1140\n",
      "Epoch 79/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1112\n",
      "Epoch 80/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1132\n",
      "Epoch 81/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1093\n",
      "Epoch 82/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1081\n",
      "Epoch 83/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1066\n",
      "Epoch 84/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1070\n",
      "Epoch 85/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1051\n",
      "Epoch 86/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1011\n",
      "Epoch 87/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1040\n",
      "Epoch 88/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1035\n",
      "Epoch 89/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1105\n",
      "Epoch 90/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1069\n",
      "Epoch 91/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1014\n",
      "Epoch 92/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1061\n",
      "Epoch 93/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1058\n",
      "Epoch 94/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1041\n",
      "Epoch 95/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1073\n",
      "Epoch 96/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1018\n",
      "Epoch 97/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1020\n",
      "Epoch 98/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1014: 0s - loss: \n",
      "Epoch 99/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.0957\n",
      "Epoch 100/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1040\n",
      "3217/3217 [==============================] - 0s 30us/step\n",
      "Epoch 1/100\n",
      "28948/28948 [==============================] - 1s 24us/step - loss: 8.8421\n",
      "Epoch 2/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 6.4740\n",
      "Epoch 3/100\n",
      "28948/28948 [==============================] - 1s 18us/step - loss: 4.0717\n",
      "Epoch 4/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 3.0960\n",
      "Epoch 5/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.8962\n",
      "Epoch 6/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.7840\n",
      "Epoch 7/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.6908\n",
      "Epoch 8/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.5980\n",
      "Epoch 9/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.5270\n",
      "Epoch 10/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.4401\n",
      "Epoch 11/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.3763\n",
      "Epoch 12/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.3149\n",
      "Epoch 13/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.2768\n",
      "Epoch 14/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.2412\n",
      "Epoch 15/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.2059\n",
      "Epoch 16/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1748\n",
      "Epoch 17/100\n",
      "28948/28948 [==============================] - 1s 18us/step - loss: 2.1576\n",
      "Epoch 18/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1531\n",
      "Epoch 19/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1365\n",
      "Epoch 20/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1365\n",
      "Epoch 21/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1244\n",
      "Epoch 22/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1224\n",
      "Epoch 23/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1192\n",
      "Epoch 24/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1104\n",
      "Epoch 25/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1191\n",
      "Epoch 26/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1077\n",
      "Epoch 27/100\n",
      "28948/28948 [==============================] - 1s 17us/step - loss: 2.1167\n",
      "Epoch 28/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.0978\n",
      "Epoch 29/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1159\n",
      "Epoch 30/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1128\n",
      "Epoch 31/100\n",
      "28948/28948 [==============================] - 1s 18us/step - loss: 2.1025\n",
      "Epoch 32/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1077\n",
      "Epoch 33/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1020\n",
      "Epoch 34/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1004\n",
      "Epoch 35/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1144\n",
      "Epoch 36/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.0932\n",
      "Epoch 37/100\n",
      "28948/28948 [==============================] - 1s 18us/step - loss: 2.1065\n",
      "Epoch 38/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.0932\n",
      "Epoch 39/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1010\n",
      "Epoch 40/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1102\n",
      "Epoch 41/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.0968\n",
      "Epoch 42/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1003\n",
      "Epoch 43/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.0988\n",
      "Epoch 44/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.0997\n",
      "Epoch 45/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1022\n",
      "Epoch 46/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1014\n",
      "Epoch 47/100\n",
      "28948/28948 [==============================] - ETA: 0s - loss: 2.094 - 1s 19us/step - loss: 2.1026\n",
      "Epoch 48/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.0966\n",
      "Epoch 49/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.0993\n",
      "Epoch 50/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1043\n",
      "Epoch 51/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.0977\n",
      "Epoch 52/100\n",
      "28948/28948 [==============================] - 1s 18us/step - loss: 2.0962\n",
      "Epoch 53/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.0975\n",
      "Epoch 54/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.0951\n",
      "Epoch 55/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.0984\n",
      "Epoch 56/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.0980\n",
      "Epoch 57/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.0998\n",
      "Epoch 58/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.0983\n",
      "Epoch 59/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.0978\n",
      "Epoch 60/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.0983\n",
      "Epoch 61/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.0913\n",
      "Epoch 62/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1001\n",
      "Epoch 63/100\n",
      "28948/28948 [==============================] - 1s 18us/step - loss: 2.0899\n",
      "Epoch 64/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1008\n",
      "Epoch 65/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.0967\n",
      "Epoch 66/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.0996\n",
      "Epoch 67/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.0926\n",
      "Epoch 68/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.0970\n",
      "Epoch 69/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.0891\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.0911\n",
      "Epoch 71/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.0915\n",
      "Epoch 72/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.0965\n",
      "Epoch 73/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.0911\n",
      "Epoch 74/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.0919\n",
      "Epoch 75/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1025\n",
      "Epoch 76/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.0945\n",
      "Epoch 77/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1036\n",
      "Epoch 78/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.0884\n",
      "Epoch 79/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.0891\n",
      "Epoch 80/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.0873\n",
      "Epoch 81/100\n",
      "28948/28948 [==============================] - 1s 19us/step - loss: 2.0929\n",
      "Epoch 82/100\n",
      "28948/28948 [==============================] - 1s 25us/step - loss: 2.0925\n",
      "Epoch 83/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.0980\n",
      "Epoch 84/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.0913\n",
      "Epoch 85/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.0861\n",
      "Epoch 86/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.0883\n",
      "Epoch 87/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.0927\n",
      "Epoch 88/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.0905\n",
      "Epoch 89/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.0873\n",
      "Epoch 90/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.0919\n",
      "Epoch 91/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.0905\n",
      "Epoch 92/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.0925\n",
      "Epoch 93/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.0886\n",
      "Epoch 94/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.0893\n",
      "Epoch 95/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.0933\n",
      "Epoch 96/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.0930\n",
      "Epoch 97/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.0889\n",
      "Epoch 98/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.0863\n",
      "Epoch 99/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.0847\n",
      "Epoch 100/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.0863\n",
      "3217/3217 [==============================] - 0s 35us/step\n",
      "Epoch 1/100\n",
      "28948/28948 [==============================] - 1s 26us/step - loss: 8.7141\n",
      "Epoch 2/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 4.8157\n",
      "Epoch 3/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 3.2922\n",
      "Epoch 4/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 3.0521\n",
      "Epoch 5/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.9093\n",
      "Epoch 6/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.7626\n",
      "Epoch 7/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.6509\n",
      "Epoch 8/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.5463\n",
      "Epoch 9/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.4596\n",
      "Epoch 10/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.3918\n",
      "Epoch 11/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.3396\n",
      "Epoch 12/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.2884\n",
      "Epoch 13/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.2553\n",
      "Epoch 14/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.2457\n",
      "Epoch 15/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.2183\n",
      "Epoch 16/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.2134\n",
      "Epoch 17/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.2010\n",
      "Epoch 18/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1758\n",
      "Epoch 19/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1726\n",
      "Epoch 20/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1768\n",
      "Epoch 21/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1643\n",
      "Epoch 22/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1774\n",
      "Epoch 23/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1730\n",
      "Epoch 24/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1691\n",
      "Epoch 25/100\n",
      "28948/28948 [==============================] - 1s 22us/step - loss: 2.1605\n",
      "Epoch 26/100\n",
      "28948/28948 [==============================] - 1s 19us/step - loss: 2.1624\n",
      "Epoch 27/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1631\n",
      "Epoch 28/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1723\n",
      "Epoch 29/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1676\n",
      "Epoch 30/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1558\n",
      "Epoch 31/100\n",
      "28948/28948 [==============================] - ETA: 0s - loss: 2.167 - 1s 17us/step - loss: 2.1594\n",
      "Epoch 32/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1472\n",
      "Epoch 33/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1433\n",
      "Epoch 34/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1426\n",
      "Epoch 35/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1363\n",
      "Epoch 36/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1354\n",
      "Epoch 37/100\n",
      "28948/28948 [==============================] - 1s 17us/step - loss: 2.1549\n",
      "Epoch 38/100\n",
      "28948/28948 [==============================] - 1s 17us/step - loss: 2.1460\n",
      "Epoch 39/100\n",
      "28948/28948 [==============================] - 1s 17us/step - loss: 2.1496\n",
      "Epoch 40/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1546\n",
      "Epoch 41/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1475\n",
      "Epoch 42/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1374\n",
      "Epoch 43/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1336\n",
      "Epoch 44/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1380\n",
      "Epoch 45/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1475\n",
      "Epoch 46/100\n",
      "28948/28948 [==============================] - 1s 18us/step - loss: 2.1447\n",
      "Epoch 47/100\n",
      "28948/28948 [==============================] - 1s 18us/step - loss: 2.1346\n",
      "Epoch 48/100\n",
      "28948/28948 [==============================] - 1s 17us/step - loss: 2.1458\n",
      "Epoch 49/100\n",
      "28948/28948 [==============================] - 1s 17us/step - loss: 2.1359\n",
      "Epoch 50/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1259\n",
      "Epoch 51/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1216\n",
      "Epoch 52/100\n",
      "28948/28948 [==============================] - 1s 17us/step - loss: 2.1427\n",
      "Epoch 53/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1327\n",
      "Epoch 54/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1191\n",
      "Epoch 55/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1240\n",
      "Epoch 56/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1264\n",
      "Epoch 57/100\n",
      "28948/28948 [==============================] - 1s 18us/step - loss: 2.1212\n",
      "Epoch 58/100\n",
      "28948/28948 [==============================] - 1s 17us/step - loss: 2.1198\n",
      "Epoch 59/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1288\n",
      "Epoch 60/100\n",
      "28948/28948 [==============================] - 1s 18us/step - loss: 2.1298\n",
      "Epoch 61/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1220\n",
      "Epoch 62/100\n",
      "28948/28948 [==============================] - 1s 18us/step - loss: 2.1244\n",
      "Epoch 63/100\n",
      "28948/28948 [==============================] - 1s 17us/step - loss: 2.1194\n",
      "Epoch 64/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1225\n",
      "Epoch 65/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1258\n",
      "Epoch 66/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1266\n",
      "Epoch 67/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1153\n",
      "Epoch 68/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1166\n",
      "Epoch 69/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1183\n",
      "Epoch 70/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1114\n",
      "Epoch 71/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1169\n",
      "Epoch 72/100\n",
      "28948/28948 [==============================] - 1s 18us/step - loss: 2.1129\n",
      "Epoch 73/100\n",
      "28948/28948 [==============================] - 1s 17us/step - loss: 2.1099\n",
      "Epoch 74/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1216\n",
      "Epoch 75/100\n",
      "28948/28948 [==============================] - 0s 16us/step - loss: 2.1122\n",
      "Epoch 76/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1202\n",
      "Epoch 77/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1073\n",
      "Epoch 78/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1090\n",
      "Epoch 79/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1069\n",
      "Epoch 80/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1126\n",
      "Epoch 81/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1090\n",
      "Epoch 82/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1108\n",
      "Epoch 83/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1104\n",
      "Epoch 84/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1072\n",
      "Epoch 85/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1154\n",
      "Epoch 86/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1064\n",
      "Epoch 87/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1026\n",
      "Epoch 88/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1066\n",
      "Epoch 89/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1096\n",
      "Epoch 90/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1086\n",
      "Epoch 91/100\n",
      "28948/28948 [==============================] - 1s 18us/step - loss: 2.1022\n",
      "Epoch 92/100\n",
      "28948/28948 [==============================] - 1s 17us/step - loss: 2.1095\n",
      "Epoch 93/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1073\n",
      "Epoch 94/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1028\n",
      "Epoch 95/100\n",
      "28948/28948 [==============================] - 1s 17us/step - loss: 2.1079\n",
      "Epoch 96/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1032\n",
      "Epoch 97/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1101\n",
      "Epoch 98/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1070\n",
      "Epoch 99/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.1119\n",
      "Epoch 100/100\n",
      "28948/28948 [==============================] - 0s 17us/step - loss: 2.0998\n",
      "3217/3217 [==============================] - 0s 37us/step\n",
      "Epoch 1/100\n",
      "28949/28949 [==============================] - 1s 28us/step - loss: 8.8994\n",
      "Epoch 2/100\n",
      "28949/28949 [==============================] - 1s 27us/step - loss: 5.4949\n",
      "Epoch 3/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 3.9030\n",
      "Epoch 4/100\n",
      "28949/28949 [==============================] - 1s 17us/step - loss: 3.4658\n",
      "Epoch 5/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 3.2121\n",
      "Epoch 6/100\n",
      "28949/28949 [==============================] - 1s 17us/step - loss: 3.0013\n",
      "Epoch 7/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.8266\n",
      "Epoch 8/100\n",
      "28949/28949 [==============================] - 1s 17us/step - loss: 2.6394\n",
      "Epoch 9/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.5063\n",
      "Epoch 10/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.4318\n",
      "Epoch 11/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.3439\n",
      "Epoch 12/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.2872\n",
      "Epoch 13/100\n",
      "28949/28949 [==============================] - 0s 16us/step - loss: 2.2464\n",
      "Epoch 14/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.2365\n",
      "Epoch 15/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1748\n",
      "Epoch 16/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1887\n",
      "Epoch 17/100\n",
      "28949/28949 [==============================] - 1s 17us/step - loss: 2.1783\n",
      "Epoch 18/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1823\n",
      "Epoch 19/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1769\n",
      "Epoch 20/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1679\n",
      "Epoch 21/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1622\n",
      "Epoch 22/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1503\n",
      "Epoch 23/100\n",
      "28949/28949 [==============================] - 1s 17us/step - loss: 2.1606\n",
      "Epoch 24/100\n",
      "28949/28949 [==============================] - 1s 17us/step - loss: 2.1761\n",
      "Epoch 25/100\n",
      "28949/28949 [==============================] - 1s 19us/step - loss: 2.1593\n",
      "Epoch 26/100\n",
      "28949/28949 [==============================] - 1s 21us/step - loss: 2.2059\n",
      "Epoch 27/100\n",
      "28949/28949 [==============================] - 1s 20us/step - loss: 2.1544\n",
      "Epoch 28/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1782\n",
      "Epoch 29/100\n",
      "28949/28949 [==============================] - 1s 20us/step - loss: 2.1651\n",
      "Epoch 30/100\n",
      "28949/28949 [==============================] - 1s 21us/step - loss: 2.1533\n",
      "Epoch 31/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1466\n",
      "Epoch 32/100\n",
      "28949/28949 [==============================] - 1s 17us/step - loss: 2.1758\n",
      "Epoch 33/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1803\n",
      "Epoch 34/100\n",
      "28949/28949 [==============================] - 1s 17us/step - loss: 2.1643\n",
      "Epoch 35/100\n",
      "28949/28949 [==============================] - 1s 17us/step - loss: 2.1553\n",
      "Epoch 36/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1609\n",
      "Epoch 37/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1541\n",
      "Epoch 38/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1664\n",
      "Epoch 39/100\n",
      "28949/28949 [==============================] - 1s 17us/step - loss: 2.1437\n",
      "Epoch 40/100\n",
      "28949/28949 [==============================] - 1s 17us/step - loss: 2.1719\n",
      "Epoch 41/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1505\n",
      "Epoch 42/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1667\n",
      "Epoch 43/100\n",
      "28949/28949 [==============================] - 1s 20us/step - loss: 2.1641\n",
      "Epoch 44/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1557\n",
      "Epoch 45/100\n",
      "28949/28949 [==============================] - 1s 20us/step - loss: 2.1464\n",
      "Epoch 46/100\n",
      "28949/28949 [==============================] - 1s 20us/step - loss: 2.1500\n",
      "Epoch 47/100\n",
      "28949/28949 [==============================] - 1s 17us/step - loss: 2.1448\n",
      "Epoch 48/100\n",
      "28949/28949 [==============================] - 1s 17us/step - loss: 2.1695\n",
      "Epoch 49/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1815\n",
      "Epoch 50/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1392\n",
      "Epoch 51/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1477\n",
      "Epoch 52/100\n",
      "28949/28949 [==============================] - 1s 17us/step - loss: 2.1681\n",
      "Epoch 53/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1418\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1462\n",
      "Epoch 55/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1428\n",
      "Epoch 56/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1492\n",
      "Epoch 57/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1635\n",
      "Epoch 58/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1352\n",
      "Epoch 59/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1658\n",
      "Epoch 60/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1406\n",
      "Epoch 61/100\n",
      "28949/28949 [==============================] - 1s 17us/step - loss: 2.1621\n",
      "Epoch 62/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1517\n",
      "Epoch 63/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1647\n",
      "Epoch 64/100\n",
      "28949/28949 [==============================] - 1s 17us/step - loss: 2.1583\n",
      "Epoch 65/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1338\n",
      "Epoch 66/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1551\n",
      "Epoch 67/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1416\n",
      "Epoch 68/100\n",
      "28949/28949 [==============================] - 1s 17us/step - loss: 2.1425\n",
      "Epoch 69/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1338\n",
      "Epoch 70/100\n",
      "28949/28949 [==============================] - 1s 17us/step - loss: 2.1464\n",
      "Epoch 71/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1402\n",
      "Epoch 72/100\n",
      "28949/28949 [==============================] - 1s 17us/step - loss: 2.1335\n",
      "Epoch 73/100\n",
      "28949/28949 [==============================] - 1s 17us/step - loss: 2.1361\n",
      "Epoch 74/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1512\n",
      "Epoch 75/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1378\n",
      "Epoch 76/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1326\n",
      "Epoch 77/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1342\n",
      "Epoch 78/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1383\n",
      "Epoch 79/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1382\n",
      "Epoch 80/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1407\n",
      "Epoch 81/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1401\n",
      "Epoch 82/100\n",
      "28949/28949 [==============================] - 1s 17us/step - loss: 2.1422\n",
      "Epoch 83/100\n",
      "28949/28949 [==============================] - 1s 17us/step - loss: 2.1376\n",
      "Epoch 84/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1303\n",
      "Epoch 85/100\n",
      "28949/28949 [==============================] - 1s 17us/step - loss: 2.1415\n",
      "Epoch 86/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1385\n",
      "Epoch 87/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1311\n",
      "Epoch 88/100\n",
      "28949/28949 [==============================] - 1s 17us/step - loss: 2.1253\n",
      "Epoch 89/100\n",
      "28949/28949 [==============================] - 1s 19us/step - loss: 2.1257\n",
      "Epoch 90/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1268\n",
      "Epoch 91/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1357\n",
      "Epoch 92/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1318\n",
      "Epoch 93/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1220\n",
      "Epoch 94/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1216\n",
      "Epoch 95/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1215\n",
      "Epoch 96/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1218\n",
      "Epoch 97/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1253\n",
      "Epoch 98/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1212\n",
      "Epoch 99/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1255\n",
      "Epoch 100/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1227\n",
      "3216/3216 [==============================] - 0s 39us/step\n",
      "Epoch 1/100\n",
      "28949/28949 [==============================] - 1s 28us/step - loss: 8.5970\n",
      "Epoch 2/100\n",
      "28949/28949 [==============================] - 1s 17us/step - loss: 4.1171\n",
      "Epoch 3/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 3.2404\n",
      "Epoch 4/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 3.1243\n",
      "Epoch 5/100\n",
      "28949/28949 [==============================] - 1s 17us/step - loss: 3.0165\n",
      "Epoch 6/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.9040\n",
      "Epoch 7/100\n",
      "28949/28949 [==============================] - 1s 17us/step - loss: 2.7809\n",
      "Epoch 8/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.6668\n",
      "Epoch 9/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.5589\n",
      "Epoch 10/100\n",
      "28949/28949 [==============================] - 1s 17us/step - loss: 2.4549\n",
      "Epoch 11/100\n",
      "28949/28949 [==============================] - 1s 17us/step - loss: 2.3762\n",
      "Epoch 12/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.3007\n",
      "Epoch 13/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.2297\n",
      "Epoch 14/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.2313\n",
      "Epoch 15/100\n",
      "28949/28949 [==============================] - 1s 17us/step - loss: 2.1886\n",
      "Epoch 16/100\n",
      "28949/28949 [==============================] - 1s 17us/step - loss: 2.1934\n",
      "Epoch 17/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1946\n",
      "Epoch 18/100\n",
      "28949/28949 [==============================] - 1s 17us/step - loss: 2.1690\n",
      "Epoch 19/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1638\n",
      "Epoch 20/100\n",
      "28949/28949 [==============================] - 1s 27us/step - loss: 2.1598\n",
      "Epoch 21/100\n",
      "28949/28949 [==============================] - 1s 20us/step - loss: 2.1682\n",
      "Epoch 22/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1470\n",
      "Epoch 23/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1619\n",
      "Epoch 24/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1307\n",
      "Epoch 25/100\n",
      "28949/28949 [==============================] - 1s 17us/step - loss: 2.1366\n",
      "Epoch 26/100\n",
      "28949/28949 [==============================] - 1s 17us/step - loss: 2.1451\n",
      "Epoch 27/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1371\n",
      "Epoch 28/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1548\n",
      "Epoch 29/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1535\n",
      "Epoch 30/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1317\n",
      "Epoch 31/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1317\n",
      "Epoch 32/100\n",
      "28949/28949 [==============================] - 1s 17us/step - loss: 2.1371\n",
      "Epoch 33/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1292\n",
      "Epoch 34/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1338\n",
      "Epoch 35/100\n",
      "28949/28949 [==============================] - 1s 17us/step - loss: 2.1320\n",
      "Epoch 36/100\n",
      "28949/28949 [==============================] - 1s 17us/step - loss: 2.1246\n",
      "Epoch 37/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1400\n",
      "Epoch 38/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1401\n",
      "Epoch 39/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1333\n",
      "Epoch 40/100\n",
      "28949/28949 [==============================] - 1s 20us/step - loss: 2.1313\n",
      "Epoch 41/100\n",
      "28949/28949 [==============================] - 1s 24us/step - loss: 2.1335\n",
      "Epoch 42/100\n",
      "28949/28949 [==============================] - 1s 25us/step - loss: 2.1392\n",
      "Epoch 43/100\n",
      "28949/28949 [==============================] - 1s 19us/step - loss: 2.1298\n",
      "Epoch 44/100\n",
      "28949/28949 [==============================] - 1s 20us/step - loss: 2.1256\n",
      "Epoch 45/100\n",
      "28949/28949 [==============================] - 1s 20us/step - loss: 2.1293\n",
      "Epoch 46/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1309\n",
      "Epoch 47/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1204\n",
      "Epoch 48/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1241\n",
      "Epoch 49/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1288\n",
      "Epoch 50/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1111\n",
      "Epoch 51/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1308\n",
      "Epoch 52/100\n",
      "28949/28949 [==============================] - 1s 17us/step - loss: 2.1079\n",
      "Epoch 53/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1211\n",
      "Epoch 54/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1133\n",
      "Epoch 55/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1129\n",
      "Epoch 56/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1273\n",
      "Epoch 57/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1184\n",
      "Epoch 58/100\n",
      "28949/28949 [==============================] - 1s 17us/step - loss: 2.1155\n",
      "Epoch 59/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1163\n",
      "Epoch 60/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1040\n",
      "Epoch 61/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1121\n",
      "Epoch 62/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1087\n",
      "Epoch 63/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1053\n",
      "Epoch 64/100\n",
      "28949/28949 [==============================] - 1s 17us/step - loss: 2.1167\n",
      "Epoch 65/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1055\n",
      "Epoch 66/100\n",
      "28949/28949 [==============================] - 1s 17us/step - loss: 2.1021\n",
      "Epoch 67/100\n",
      "28949/28949 [==============================] - 1s 17us/step - loss: 2.1086\n",
      "Epoch 68/100\n",
      "28949/28949 [==============================] - 1s 19us/step - loss: 2.1006\n",
      "Epoch 69/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1028\n",
      "Epoch 70/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1111\n",
      "Epoch 71/100\n",
      "28949/28949 [==============================] - 1s 17us/step - loss: 2.1068\n",
      "Epoch 72/100\n",
      "28949/28949 [==============================] - 1s 21us/step - loss: 2.1055\n",
      "Epoch 73/100\n",
      "28949/28949 [==============================] - 1s 27us/step - loss: 2.1066\n",
      "Epoch 74/100\n",
      "28949/28949 [==============================] - 1s 24us/step - loss: 2.1007\n",
      "Epoch 75/100\n",
      "28949/28949 [==============================] - 1s 23us/step - loss: 2.1061\n",
      "Epoch 76/100\n",
      "28949/28949 [==============================] - 1s 24us/step - loss: 2.1019\n",
      "Epoch 77/100\n",
      "28949/28949 [==============================] - 1s 21us/step - loss: 2.0994\n",
      "Epoch 78/100\n",
      "28949/28949 [==============================] - 1s 22us/step - loss: 2.0969\n",
      "Epoch 79/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1056\n",
      "Epoch 80/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1014\n",
      "Epoch 81/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1021\n",
      "Epoch 82/100\n",
      "28949/28949 [==============================] - 1s 19us/step - loss: 2.1043\n",
      "Epoch 83/100\n",
      "28949/28949 [==============================] - 1s 24us/step - loss: 2.0979\n",
      "Epoch 84/100\n",
      "28949/28949 [==============================] - 1s 25us/step - loss: 2.1020\n",
      "Epoch 85/100\n",
      "28949/28949 [==============================] - 1s 21us/step - loss: 2.0971\n",
      "Epoch 86/100\n",
      "28949/28949 [==============================] - 1s 21us/step - loss: 2.0965\n",
      "Epoch 87/100\n",
      "28949/28949 [==============================] - 1s 20us/step - loss: 2.0949\n",
      "Epoch 88/100\n",
      "28949/28949 [==============================] - 1s 20us/step - loss: 2.1035\n",
      "Epoch 89/100\n",
      "28949/28949 [==============================] - 1s 19us/step - loss: 2.0955\n",
      "Epoch 90/100\n",
      "28949/28949 [==============================] - 1s 19us/step - loss: 2.0933\n",
      "Epoch 91/100\n",
      "28949/28949 [==============================] - 1s 21us/step - loss: 2.0942\n",
      "Epoch 92/100\n",
      "28949/28949 [==============================] - 1s 22us/step - loss: 2.0982\n",
      "Epoch 93/100\n",
      "28949/28949 [==============================] - 1s 23us/step - loss: 2.0945\n",
      "Epoch 94/100\n",
      "28949/28949 [==============================] - 1s 21us/step - loss: 2.0932\n",
      "Epoch 95/100\n",
      "28949/28949 [==============================] - 1s 20us/step - loss: 2.0919\n",
      "Epoch 96/100\n",
      "28949/28949 [==============================] - 1s 21us/step - loss: 2.0960\n",
      "Epoch 97/100\n",
      "28949/28949 [==============================] - 1s 20us/step - loss: 2.0915\n",
      "Epoch 98/100\n",
      "28949/28949 [==============================] - 1s 22us/step - loss: 2.0962\n",
      "Epoch 99/100\n",
      "28949/28949 [==============================] - 1s 22us/step - loss: 2.0949\n",
      "Epoch 100/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.0943\n",
      "3216/3216 [==============================] - 0s 50us/step\n",
      "Epoch 1/100\n",
      "28949/28949 [==============================] - 1s 35us/step - loss: 9.3300\n",
      "Epoch 2/100\n",
      "28949/28949 [==============================] - 1s 21us/step - loss: 6.0154\n",
      "Epoch 3/100\n",
      "28949/28949 [==============================] - 1s 21us/step - loss: 3.8305\n",
      "Epoch 4/100\n",
      "28949/28949 [==============================] - 1s 20us/step - loss: 3.3460\n",
      "Epoch 5/100\n",
      "28949/28949 [==============================] - 1s 21us/step - loss: 3.0773\n",
      "Epoch 6/100\n",
      "28949/28949 [==============================] - 1s 23us/step - loss: 2.8792\n",
      "Epoch 7/100\n",
      "28949/28949 [==============================] - 1s 19us/step - loss: 2.7431\n",
      "Epoch 8/100\n",
      "28949/28949 [==============================] - 1s 22us/step - loss: 2.6355\n",
      "Epoch 9/100\n",
      "28949/28949 [==============================] - 1s 20us/step - loss: 2.5311: 0s - lo\n",
      "Epoch 10/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.4542\n",
      "Epoch 11/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.3676\n",
      "Epoch 12/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.3128\n",
      "Epoch 13/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.2652\n",
      "Epoch 14/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.2296\n",
      "Epoch 15/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.2161\n",
      "Epoch 16/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.2005\n",
      "Epoch 17/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1757\n",
      "Epoch 18/100\n",
      "28949/28949 [==============================] - 1s 17us/step - loss: 2.1591\n",
      "Epoch 19/100\n",
      "28949/28949 [==============================] - 1s 21us/step - loss: 2.1448\n",
      "Epoch 20/100\n",
      "28949/28949 [==============================] - ETA: 0s - loss: 2.148 - 1s 19us/step - loss: 2.1510\n",
      "Epoch 21/100\n",
      "28949/28949 [==============================] - 1s 19us/step - loss: 2.1338\n",
      "Epoch 22/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1578\n",
      "Epoch 23/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1524\n",
      "Epoch 24/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1524\n",
      "Epoch 25/100\n",
      "28949/28949 [==============================] - 1s 19us/step - loss: 2.1581\n",
      "Epoch 26/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1234\n",
      "Epoch 27/100\n",
      "28949/28949 [==============================] - 1s 20us/step - loss: 2.1249\n",
      "Epoch 28/100\n",
      "28949/28949 [==============================] - 1s 29us/step - loss: 2.1314\n",
      "Epoch 29/100\n",
      "28949/28949 [==============================] - 1s 26us/step - loss: 2.1434\n",
      "Epoch 30/100\n",
      "28949/28949 [==============================] - 1s 24us/step - loss: 2.1395\n",
      "Epoch 31/100\n",
      "28949/28949 [==============================] - 1s 24us/step - loss: 2.1498\n",
      "Epoch 32/100\n",
      "28949/28949 [==============================] - 1s 19us/step - loss: 2.1258\n",
      "Epoch 33/100\n",
      "28949/28949 [==============================] - 1s 19us/step - loss: 2.1203\n",
      "Epoch 34/100\n",
      "28949/28949 [==============================] - 1s 19us/step - loss: 2.1347\n",
      "Epoch 35/100\n",
      "28949/28949 [==============================] - 1s 19us/step - loss: 2.1314\n",
      "Epoch 36/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1213\n",
      "Epoch 37/100\n",
      "28949/28949 [==============================] - 1s 19us/step - loss: 2.1370\n",
      "Epoch 38/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1271\n",
      "Epoch 39/100\n",
      "28949/28949 [==============================] - 1s 19us/step - loss: 2.1294\n",
      "Epoch 40/100\n",
      "28949/28949 [==============================] - 1s 19us/step - loss: 2.1241\n",
      "Epoch 41/100\n",
      "28949/28949 [==============================] - 1s 22us/step - loss: 2.1154\n",
      "Epoch 42/100\n",
      "28949/28949 [==============================] - 1s 21us/step - loss: 2.1266\n",
      "Epoch 43/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1173\n",
      "Epoch 44/100\n",
      "28949/28949 [==============================] - 1s 20us/step - loss: 2.1387\n",
      "Epoch 45/100\n",
      "28949/28949 [==============================] - 1s 21us/step - loss: 2.1250\n",
      "Epoch 46/100\n",
      "28949/28949 [==============================] - 1s 17us/step - loss: 2.1355\n",
      "Epoch 47/100\n",
      "28949/28949 [==============================] - 1s 17us/step - loss: 2.1105\n",
      "Epoch 48/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1191\n",
      "Epoch 49/100\n",
      "28949/28949 [==============================] - 1s 17us/step - loss: 2.1136\n",
      "Epoch 50/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1203\n",
      "Epoch 51/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1252\n",
      "Epoch 52/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1115\n",
      "Epoch 53/100\n",
      "28949/28949 [==============================] - 1s 21us/step - loss: 2.1133\n",
      "Epoch 54/100\n",
      "28949/28949 [==============================] - 1s 19us/step - loss: 2.1059\n",
      "Epoch 55/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1179\n",
      "Epoch 56/100\n",
      "28949/28949 [==============================] - 1s 17us/step - loss: 2.1208\n",
      "Epoch 57/100\n",
      "28949/28949 [==============================] - 1s 17us/step - loss: 2.1090\n",
      "Epoch 58/100\n",
      "28949/28949 [==============================] - 1s 22us/step - loss: 2.1163\n",
      "Epoch 59/100\n",
      "28949/28949 [==============================] - 1s 19us/step - loss: 2.1103\n",
      "Epoch 60/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1070\n",
      "Epoch 61/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1217\n",
      "Epoch 62/100\n",
      "28949/28949 [==============================] - 1s 17us/step - loss: 2.1126\n",
      "Epoch 63/100\n",
      "28949/28949 [==============================] - 1s 19us/step - loss: 2.1141\n",
      "Epoch 64/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1110\n",
      "Epoch 65/100\n",
      "28949/28949 [==============================] - 1s 19us/step - loss: 2.1038\n",
      "Epoch 66/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1097\n",
      "Epoch 67/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1072\n",
      "Epoch 68/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1142\n",
      "Epoch 69/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1023\n",
      "Epoch 70/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1041\n",
      "Epoch 71/100\n",
      "28949/28949 [==============================] - 1s 20us/step - loss: 2.1077\n",
      "Epoch 72/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1092\n",
      "Epoch 73/100\n",
      "28949/28949 [==============================] - 1s 20us/step - loss: 2.1080\n",
      "Epoch 74/100\n",
      "28949/28949 [==============================] - 1s 20us/step - loss: 2.1065\n",
      "Epoch 75/100\n",
      "28949/28949 [==============================] - 1s 19us/step - loss: 2.0996\n",
      "Epoch 76/100\n",
      "28949/28949 [==============================] - 1s 22us/step - loss: 2.1063\n",
      "Epoch 77/100\n",
      "28949/28949 [==============================] - 1s 21us/step - loss: 2.1070\n",
      "Epoch 78/100\n",
      "28949/28949 [==============================] - 1s 24us/step - loss: 2.0995\n",
      "Epoch 79/100\n",
      "28949/28949 [==============================] - 1s 20us/step - loss: 2.1036\n",
      "Epoch 80/100\n",
      "28949/28949 [==============================] - 1s 19us/step - loss: 2.1021\n",
      "Epoch 81/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1018\n",
      "Epoch 82/100\n",
      "28949/28949 [==============================] - 1s 19us/step - loss: 2.0992\n",
      "Epoch 83/100\n",
      "28949/28949 [==============================] - 1s 21us/step - loss: 2.1061\n",
      "Epoch 84/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1014\n",
      "Epoch 85/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1048\n",
      "Epoch 86/100\n",
      "28949/28949 [==============================] - 1s 19us/step - loss: 2.1002\n",
      "Epoch 87/100\n",
      "28949/28949 [==============================] - 1s 20us/step - loss: 2.1024\n",
      "Epoch 88/100\n",
      "28949/28949 [==============================] - 1s 19us/step - loss: 2.0991\n",
      "Epoch 89/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1052\n",
      "Epoch 90/100\n",
      "28949/28949 [==============================] - 1s 21us/step - loss: 2.1008\n",
      "Epoch 91/100\n",
      "28949/28949 [==============================] - 1s 21us/step - loss: 2.1023\n",
      "Epoch 92/100\n",
      "28949/28949 [==============================] - 1s 19us/step - loss: 2.0964\n",
      "Epoch 93/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.0973\n",
      "Epoch 94/100\n",
      "28949/28949 [==============================] - 1s 19us/step - loss: 2.0957\n",
      "Epoch 95/100\n",
      "28949/28949 [==============================] - 1s 19us/step - loss: 2.0972\n",
      "Epoch 96/100\n",
      "28949/28949 [==============================] - 1s 21us/step - loss: 2.0997\n",
      "Epoch 97/100\n",
      "28949/28949 [==============================] - 1s 19us/step - loss: 2.0944\n",
      "Epoch 98/100\n",
      "28949/28949 [==============================] - 1s 20us/step - loss: 2.0954\n",
      "Epoch 99/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1013\n",
      "Epoch 100/100\n",
      "28949/28949 [==============================] - 1s 19us/step - loss: 2.1068\n",
      "3216/3216 [==============================] - 0s 46us/step\n",
      "Epoch 1/100\n",
      "28949/28949 [==============================] - 1s 40us/step - loss: 13.8493\n",
      "Epoch 2/100\n",
      "28949/28949 [==============================] - 1s 34us/step - loss: 6.3167: 0s - los\n",
      "Epoch 3/100\n",
      "28949/28949 [==============================] - 1s 30us/step - loss: 3.7914\n",
      "Epoch 4/100\n",
      "28949/28949 [==============================] - 1s 23us/step - loss: 3.3306\n",
      "Epoch 5/100\n",
      "28949/28949 [==============================] - 1s 24us/step - loss: 3.1529: 0s - loss: 3.162\n",
      "Epoch 6/100\n",
      "28949/28949 [==============================] - 1s 20us/step - loss: 3.0368\n",
      "Epoch 7/100\n",
      "28949/28949 [==============================] - 1s 19us/step - loss: 2.9192\n",
      "Epoch 8/100\n",
      "28949/28949 [==============================] - 1s 19us/step - loss: 2.8090\n",
      "Epoch 9/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.6866\n",
      "Epoch 10/100\n",
      "28949/28949 [==============================] - 1s 19us/step - loss: 2.5954\n",
      "Epoch 11/100\n",
      "28949/28949 [==============================] - 1s 20us/step - loss: 2.4959\n",
      "Epoch 12/100\n",
      "28949/28949 [==============================] - 1s 20us/step - loss: 2.4012\n",
      "Epoch 13/100\n",
      "28949/28949 [==============================] - 1s 19us/step - loss: 2.3372\n",
      "Epoch 14/100\n",
      "28949/28949 [==============================] - 1s 23us/step - loss: 2.2721\n",
      "Epoch 15/100\n",
      "28949/28949 [==============================] - 1s 20us/step - loss: 2.2347\n",
      "Epoch 16/100\n",
      "28949/28949 [==============================] - 1s 20us/step - loss: 2.2196\n",
      "Epoch 17/100\n",
      "28949/28949 [==============================] - 1s 20us/step - loss: 2.2157\n",
      "Epoch 18/100\n",
      "28949/28949 [==============================] - 1s 19us/step - loss: 2.1802\n",
      "Epoch 19/100\n",
      "28949/28949 [==============================] - 1s 20us/step - loss: 2.1637\n",
      "Epoch 20/100\n",
      "28949/28949 [==============================] - 1s 19us/step - loss: 2.1856\n",
      "Epoch 21/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1586\n",
      "Epoch 22/100\n",
      "28949/28949 [==============================] - 1s 19us/step - loss: 2.1551\n",
      "Epoch 23/100\n",
      "28949/28949 [==============================] - 1s 19us/step - loss: 2.1444\n",
      "Epoch 24/100\n",
      "28949/28949 [==============================] - 1s 19us/step - loss: 2.1599\n",
      "Epoch 25/100\n",
      "28949/28949 [==============================] - 1s 19us/step - loss: 2.1385\n",
      "Epoch 26/100\n",
      "28949/28949 [==============================] - 1s 19us/step - loss: 2.1389\n",
      "Epoch 27/100\n",
      "28949/28949 [==============================] - 1s 19us/step - loss: 2.1576\n",
      "Epoch 28/100\n",
      "28949/28949 [==============================] - 1s 19us/step - loss: 2.1521\n",
      "Epoch 29/100\n",
      "28949/28949 [==============================] - 1s 19us/step - loss: 2.1529\n",
      "Epoch 30/100\n",
      "28949/28949 [==============================] - 1s 19us/step - loss: 2.1459\n",
      "Epoch 31/100\n",
      "28949/28949 [==============================] - 1s 21us/step - loss: 2.1433\n",
      "Epoch 32/100\n",
      "28949/28949 [==============================] - 1s 27us/step - loss: 2.1350\n",
      "Epoch 33/100\n",
      "28949/28949 [==============================] - 1s 32us/step - loss: 2.1398\n",
      "Epoch 34/100\n",
      "28949/28949 [==============================] - 1s 21us/step - loss: 2.1358\n",
      "Epoch 35/100\n",
      "28949/28949 [==============================] - 1s 19us/step - loss: 2.1501\n",
      "Epoch 36/100\n",
      "28949/28949 [==============================] - 1s 19us/step - loss: 2.1457\n",
      "Epoch 37/100\n",
      "28949/28949 [==============================] - 1s 19us/step - loss: 2.1370\n",
      "Epoch 38/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1488\n",
      "Epoch 39/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1450\n",
      "Epoch 40/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1362\n",
      "Epoch 41/100\n",
      "28949/28949 [==============================] - 1s 17us/step - loss: 2.1316\n",
      "Epoch 42/100\n",
      "28949/28949 [==============================] - 1s 17us/step - loss: 2.1375\n",
      "Epoch 43/100\n",
      "28949/28949 [==============================] - 1s 19us/step - loss: 2.1463\n",
      "Epoch 44/100\n",
      "28949/28949 [==============================] - 1s 19us/step - loss: 2.1435\n",
      "Epoch 45/100\n",
      "28949/28949 [==============================] - 1s 19us/step - loss: 2.1328\n",
      "Epoch 46/100\n",
      "28949/28949 [==============================] - 1s 27us/step - loss: 2.1301\n",
      "Epoch 47/100\n",
      "28949/28949 [==============================] - 2s 54us/step - loss: 2.1348\n",
      "Epoch 48/100\n",
      "28949/28949 [==============================] - 1s 24us/step - loss: 2.1435\n",
      "Epoch 49/100\n",
      "28949/28949 [==============================] - 1s 22us/step - loss: 2.1364\n",
      "Epoch 50/100\n",
      "28949/28949 [==============================] - 1s 25us/step - loss: 2.1160\n",
      "Epoch 51/100\n",
      "28949/28949 [==============================] - 1s 25us/step - loss: 2.1228\n",
      "Epoch 52/100\n",
      "28949/28949 [==============================] - 1s 27us/step - loss: 2.1313\n",
      "Epoch 53/100\n",
      "28949/28949 [==============================] - 1s 22us/step - loss: 2.1253\n",
      "Epoch 54/100\n",
      "28949/28949 [==============================] - 1s 24us/step - loss: 2.1333\n",
      "Epoch 55/100\n",
      "28949/28949 [==============================] - 1s 20us/step - loss: 2.1299\n",
      "Epoch 56/100\n",
      "28949/28949 [==============================] - 1s 19us/step - loss: 2.1277\n",
      "Epoch 57/100\n",
      "28949/28949 [==============================] - 1s 19us/step - loss: 2.1295\n",
      "Epoch 58/100\n",
      "28949/28949 [==============================] - 1s 19us/step - loss: 2.1099\n",
      "Epoch 59/100\n",
      "28949/28949 [==============================] - 1s 19us/step - loss: 2.1194\n",
      "Epoch 60/100\n",
      "28949/28949 [==============================] - 1s 20us/step - loss: 2.1269\n",
      "Epoch 61/100\n",
      "28949/28949 [==============================] - 1s 21us/step - loss: 2.1229\n",
      "Epoch 62/100\n",
      "28949/28949 [==============================] - 1s 19us/step - loss: 2.1163\n",
      "Epoch 63/100\n",
      "28949/28949 [==============================] - 1s 19us/step - loss: 2.1180\n",
      "Epoch 64/100\n",
      "28949/28949 [==============================] - 1s 21us/step - loss: 2.1212\n",
      "Epoch 65/100\n",
      "28949/28949 [==============================] - 1s 19us/step - loss: 2.1233\n",
      "Epoch 66/100\n",
      "28949/28949 [==============================] - 1s 21us/step - loss: 2.1288\n",
      "Epoch 67/100\n",
      "28949/28949 [==============================] - 1s 24us/step - loss: 2.1204\n",
      "Epoch 68/100\n",
      "28949/28949 [==============================] - 1s 20us/step - loss: 2.1086\n",
      "Epoch 69/100\n",
      "28949/28949 [==============================] - 1s 19us/step - loss: 2.1154\n",
      "Epoch 70/100\n",
      "28949/28949 [==============================] - 1s 19us/step - loss: 2.1189\n",
      "Epoch 71/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1124\n",
      "Epoch 72/100\n",
      "28949/28949 [==============================] - 1s 19us/step - loss: 2.1228\n",
      "Epoch 73/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1096\n",
      "Epoch 74/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1190\n",
      "Epoch 75/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1172\n",
      "Epoch 76/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1162\n",
      "Epoch 77/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1080\n",
      "Epoch 78/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1156\n",
      "Epoch 79/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1141\n",
      "Epoch 80/100\n",
      "28949/28949 [==============================] - 1s 19us/step - loss: 2.1122\n",
      "Epoch 81/100\n",
      "28949/28949 [==============================] - 1s 20us/step - loss: 2.1182\n",
      "Epoch 82/100\n",
      "28949/28949 [==============================] - 1s 20us/step - loss: 2.1155\n",
      "Epoch 83/100\n",
      "28949/28949 [==============================] - 1s 20us/step - loss: 2.1128\n",
      "Epoch 84/100\n",
      "28949/28949 [==============================] - 1s 19us/step - loss: 2.1123\n",
      "Epoch 85/100\n",
      "28949/28949 [==============================] - 1s 19us/step - loss: 2.1039\n",
      "Epoch 86/100\n",
      "28949/28949 [==============================] - 1s 19us/step - loss: 2.1094\n",
      "Epoch 87/100\n",
      "28949/28949 [==============================] - 1s 19us/step - loss: 2.1089\n",
      "Epoch 88/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1181\n",
      "Epoch 89/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1105\n",
      "Epoch 90/100\n",
      "28949/28949 [==============================] - 1s 19us/step - loss: 2.1108\n",
      "Epoch 91/100\n",
      "28949/28949 [==============================] - 1s 19us/step - loss: 2.1089\n",
      "Epoch 92/100\n",
      "28949/28949 [==============================] - 1s 19us/step - loss: 2.1050\n",
      "Epoch 93/100\n",
      "28949/28949 [==============================] - 1s 20us/step - loss: 2.1114\n",
      "Epoch 94/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1032\n",
      "Epoch 95/100\n",
      "28949/28949 [==============================] - 1s 20us/step - loss: 2.1082\n",
      "Epoch 96/100\n",
      "28949/28949 [==============================] - 1s 19us/step - loss: 2.1037\n",
      "Epoch 97/100\n",
      "28949/28949 [==============================] - 1s 22us/step - loss: 2.1050\n",
      "Epoch 98/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1112\n",
      "Epoch 99/100\n",
      "28949/28949 [==============================] - 1s 19us/step - loss: 2.1077\n",
      "Epoch 100/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1049\n",
      "3216/3216 [==============================] - 0s 50us/step\n",
      "Epoch 1/100\n",
      "28949/28949 [==============================] - 1s 30us/step - loss: 7.7852\n",
      "Epoch 2/100\n",
      "28949/28949 [==============================] - 1s 21us/step - loss: 4.6848\n",
      "Epoch 3/100\n",
      "28949/28949 [==============================] - 1s 19us/step - loss: 3.5235\n",
      "Epoch 4/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 3.1282\n",
      "Epoch 5/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.9346\n",
      "Epoch 6/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.7665\n",
      "Epoch 7/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.6397\n",
      "Epoch 8/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.5238\n",
      "Epoch 9/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.4377\n",
      "Epoch 10/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.3762\n",
      "Epoch 11/100\n",
      "28949/28949 [==============================] - 1s 19us/step - loss: 2.3132\n",
      "Epoch 12/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.2802\n",
      "Epoch 13/100\n",
      "28949/28949 [==============================] - 1s 20us/step - loss: 2.2412\n",
      "Epoch 14/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.2176\n",
      "Epoch 15/100\n",
      "28949/28949 [==============================] - 1s 19us/step - loss: 2.1973\n",
      "Epoch 16/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1749\n",
      "Epoch 17/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1984\n",
      "Epoch 18/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1542\n",
      "Epoch 19/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1886\n",
      "Epoch 20/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1658\n",
      "Epoch 21/100\n",
      "28949/28949 [==============================] - 1s 19us/step - loss: 2.1531\n",
      "Epoch 22/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1611\n",
      "Epoch 23/100\n",
      "28949/28949 [==============================] - 1s 17us/step - loss: 2.1486\n",
      "Epoch 24/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1480\n",
      "Epoch 25/100\n",
      "28949/28949 [==============================] - 1s 17us/step - loss: 2.1877\n",
      "Epoch 26/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1469\n",
      "Epoch 27/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1361\n",
      "Epoch 28/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1495\n",
      "Epoch 29/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1487\n",
      "Epoch 30/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1526\n",
      "Epoch 31/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1432\n",
      "Epoch 32/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1404\n",
      "Epoch 33/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1412\n",
      "Epoch 34/100\n",
      "28949/28949 [==============================] - 1s 17us/step - loss: 2.1395\n",
      "Epoch 35/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1428\n",
      "Epoch 36/100\n",
      "28949/28949 [==============================] - 1s 17us/step - loss: 2.1408\n",
      "Epoch 37/100\n",
      "28949/28949 [==============================] - 1s 17us/step - loss: 2.1411\n",
      "Epoch 38/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1317\n",
      "Epoch 39/100\n",
      "28949/28949 [==============================] - 1s 25us/step - loss: 2.1450\n",
      "Epoch 40/100\n",
      "28949/28949 [==============================] - 1s 21us/step - loss: 2.1545\n",
      "Epoch 41/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1361\n",
      "Epoch 42/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1392\n",
      "Epoch 43/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1297\n",
      "Epoch 44/100\n",
      "28949/28949 [==============================] - 1s 17us/step - loss: 2.1308\n",
      "Epoch 45/100\n",
      "28949/28949 [==============================] - 1s 17us/step - loss: 2.1337\n",
      "Epoch 46/100\n",
      "28949/28949 [==============================] - 1s 17us/step - loss: 2.1370\n",
      "Epoch 47/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1425\n",
      "Epoch 48/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1276\n",
      "Epoch 49/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1228\n",
      "Epoch 50/100\n",
      "28949/28949 [==============================] - 1s 17us/step - loss: 2.1551\n",
      "Epoch 51/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1291\n",
      "Epoch 52/100\n",
      "28949/28949 [==============================] - 1s 17us/step - loss: 2.1354\n",
      "Epoch 53/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1336\n",
      "Epoch 54/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1286\n",
      "Epoch 55/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1269\n",
      "Epoch 56/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1348\n",
      "Epoch 57/100\n",
      "28949/28949 [==============================] - 1s 17us/step - loss: 2.1228\n",
      "Epoch 58/100\n",
      "28949/28949 [==============================] - 1s 17us/step - loss: 2.1262\n",
      "Epoch 59/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1336\n",
      "Epoch 60/100\n",
      "28949/28949 [==============================] - 1s 17us/step - loss: 2.1242\n",
      "Epoch 61/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1279\n",
      "Epoch 62/100\n",
      "28949/28949 [==============================] - 1s 17us/step - loss: 2.1254\n",
      "Epoch 63/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1295\n",
      "Epoch 64/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1304\n",
      "Epoch 65/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1192\n",
      "Epoch 66/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1176\n",
      "Epoch 67/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1173\n",
      "Epoch 68/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1206\n",
      "Epoch 69/100\n",
      "28949/28949 [==============================] - 1s 17us/step - loss: 2.1194\n",
      "Epoch 70/100\n",
      "28949/28949 [==============================] - 1s 17us/step - loss: 2.1189\n",
      "Epoch 71/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1154\n",
      "Epoch 72/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1117\n",
      "Epoch 73/100\n",
      "28949/28949 [==============================] - 0s 16us/step - loss: 2.1209\n",
      "Epoch 74/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1178\n",
      "Epoch 75/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1225\n",
      "Epoch 76/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1147\n",
      "Epoch 77/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1167\n",
      "Epoch 78/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1116\n",
      "Epoch 79/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1119\n",
      "Epoch 80/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1050\n",
      "Epoch 81/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1126\n",
      "Epoch 82/100\n",
      "28949/28949 [==============================] - 1s 17us/step - loss: 2.1121\n",
      "Epoch 83/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1147\n",
      "Epoch 84/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1086: 0s - loss\n",
      "Epoch 85/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1105\n",
      "Epoch 86/100\n",
      "28949/28949 [==============================] - 0s 17us/step - loss: 2.1105\n",
      "Epoch 87/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1054\n",
      "Epoch 88/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1120\n",
      "Epoch 89/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1057\n",
      "Epoch 90/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1038\n",
      "Epoch 91/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1101\n",
      "Epoch 92/100\n",
      "28949/28949 [==============================] - 1s 17us/step - loss: 2.1052\n",
      "Epoch 93/100\n",
      "28949/28949 [==============================] - 1s 17us/step - loss: 2.1074\n",
      "Epoch 94/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1018\n",
      "Epoch 95/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.0971\n",
      "Epoch 96/100\n",
      "28949/28949 [==============================] - 1s 19us/step - loss: 2.1057\n",
      "Epoch 97/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.0986\n",
      "Epoch 98/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1014\n",
      "Epoch 99/100\n",
      "28949/28949 [==============================] - 1s 18us/step - loss: 2.1008\n",
      "Epoch 100/100\n",
      "28949/28949 [==============================] - 1s 19us/step - loss: 2.1058\n",
      "3216/3216 [==============================] - 0s 51us/step\n",
      "Baseline: -2.10 (0.06) MSE\n"
     ]
    }
   ],
   "source": [
    "# evaluate model\n",
    "estimator = KerasRegressor(build_fn=baseline_model, epochs=100, batch_size=64, verbose=1)\n",
    "kfold = KFold(n_splits=10)\n",
    "results = cross_val_score(estimator, x, y, cv=kfold)\n",
    "print(\"Baseline: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'KerasRegressor' object has no attribute 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-a6b94e3bd027>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'enc_nod'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'enc_ucd'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'effectiveness_rating'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'number_of_times_prescribed'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\programs files\\python\\python36\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, **kwargs)\u001b[0m\n\u001b[0;32m    321\u001b[0m         \"\"\"\n\u001b[0;32m    322\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter_sk_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSequential\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 323\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    324\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'KerasRegressor' object has no attribute 'model'"
     ]
    }
   ],
   "source": [
    "estimator.predict(np.array(test[['enc_nod', 'enc_ucd', 'effectiveness_rating', 'number_of_times_prescribed']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.98335777, -2.02825291, -2.11218449, -2.17705051, -2.07638444,\n",
       "       -2.09107011, -2.21061402, -2.11823351, -2.12484077, -2.09302761])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
